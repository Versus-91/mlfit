(function(){var e={51300:function(e,t,s){"use strict";var a=s(66848),i=function(){var e=this,t=e._self._c;return t("div",{staticClass:"container"},[t("b-notification",{directives:[{name:"show",rawName:"v-show",value:this.settings.getDatasizeFlag,expression:"this.settings.getDatasizeFlag"}],staticClass:"mt-2",attrs:{type:"is-warning","has-icon":"","aria-close-label":"Close notification",role:"alert"}},[e._v(" Due to the large size of dataset only 10,000 radom samples from dataset would be used. ")]),t("div",{staticClass:"columns is-multiline",attrs:{id:"app"}},[t("SidebarComponent",{ref:"sidebar",on:{updateFeatures:e.updateFeatureStats}}),t("MainComponent",{ref:"main",attrs:{dataframe:this.settings.df},on:{"check-target":function(t){return e.checkTarget()}}})],1)],1)},n=[],r=function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-2 has-background-info-light",staticStyle:{height:"100%"}},[e._m(0),t("section",[t("upload-component",{on:{uploaded:e.generateTargetDropdown}}),t("div",{staticClass:"column is-12"},[t("b-field",[t("b-button",{attrs:{size:"is-small",type:"is-primary is-light","icon-pack":"fas","icon-left":"cog"},on:{click:function(t){e.configureFeatures=!0}}},[e._v("Select Features "+e._s(e.featureSettings.filter((e=>e.selected)).length))])],1),t("b-field",{attrs:{label:"Seed","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",placeholder:"Seed",type:"number",min:"0"},model:{value:e.seed,callback:function(t){e.seed=t},expression:"seed"}})],1),t("b-field",{attrs:{label:"Target","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small"},on:{input:e.checkmodelTask},model:{value:e.modelTarget,callback:function(t){e.modelTarget=t},expression:"modelTarget"}},e._l(e.columns,(function(s){return t("option",{key:s,domProps:{value:s}},[e._v(" "+e._s(s)+" ")])})),0)],1),t("b-field",{attrs:{label:"Imputation","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:e.imputationOption,callback:function(t){e.imputationOption=t},expression:"imputationOption"}},e._l(e.imputationOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.label)+" ")])})),0)],1),t("b-field",{attrs:{label:"Cross Validation","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:e.crossValidationOption,callback:function(t){e.crossValidationOption=t},expression:"crossValidationOption"}},e._l(e.crossValidationOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.label)+" ")])})),0)],1),t("b-field",{attrs:{label:"Model","label-position":"on-border"}},[t("b-select",{attrs:{disabled:e.tuneModel,expanded:!0,size:"is-small"},model:{value:e.modelOption,callback:function(t){e.modelOption=t},expression:"modelOption"}},e._l(e.modelOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.label)+" ")])})),0),t("b-button",{attrs:{size:"is-small","icon-pack":"fas","icon-left":this.tuneModel?"arrow-left":"cog"},on:{click:e.configureModel}})],1),e.tuneModel?t("section",{staticClass:"mx-1"},e._l(e.modelConfigurations,(function(s,a){return t("b-field",{key:a,attrs:{label:s.label,"label-position":"on-border"}},["select"===s.type?t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:s.value,callback:function(t){e.$set(s,"value",t)},expression:"option.value"}},e._l(s.values,(function(s,a){return t("option",{key:a,domProps:{value:s.value}},[e._v(" "+e._s(s.label)+" ")])})),0):"number"===s.type?t("b-input",{attrs:{size:"is-small",type:"number"},model:{value:s.value,callback:function(t){e.$set(s,"value",t)},expression:"option.value"}}):"text"===s.type?t("b-input",{attrs:{size:"is-small",type:"text"},model:{value:s.value,callback:function(t){e.$set(s,"value",t)},expression:"option.value"}}):e._e()],1)})),1):e._e(),t("b-field",[t("b-checkbox",{attrs:{size:"is-small"},model:{value:e.dataScalingBehavior,callback:function(t){e.dataScalingBehavior=t},expression:"dataScalingBehavior"}},[e._v("Standardize by default")])],1),t("b-field",[t("b-checkbox",{attrs:{size:"is-small"},model:{value:e.explainModel,callback:function(t){e.explainModel=t},expression:"explainModel"}},[e._v("Explain the model")])],1),t("b-field",[t("b-checkbox",{attrs:{size:"is-small"},model:{value:e.usePCAs,callback:function(t){e.usePCAs=t},expression:"usePCAs"}},[e._v("Use PC components")])],1),e.usePCAs?t("b-field",{attrs:{label:"Number of Components","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",type:"number"},model:{value:e.numberOfComponents,callback:function(t){e.numberOfComponents=t},expression:"numberOfComponents"}})],1):e._e(),t("b-field",[t("b-button",{attrs:{size:"is-small","icon-pack":"fas","icon-left":"play",loading:e.training,disabled:!e.dataframe||null==e.modelOption},on:{click:e.train}},[e._v(" train")])],1),t("b-loading",{attrs:{"is-full-page":!1},model:{value:e.training,callback:function(t){e.training=t},expression:"training"}})],1)],1)])},o=[function(){var e=this,t=e._self._c;return t("figure",{staticClass:"image is-96x96"},[t("img",{attrs:{src:"/logo.png"}})])}],l=(s(44114),s(43375),s(39225),s(13972),s(99209),s(25714),s(17561),s(66197),function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-12 has-background-light"},[t("b-field",{staticClass:"file is-success is-fullwidth",class:{"has-name":!!e.file}},[t("b-upload",{staticClass:"file-label",attrs:{accept:".csv,.txt,.xlsx"},model:{value:e.file,callback:function(t){e.file=t},expression:"file"}},[t("a",{staticClass:"button is-success is-small is-fullwidth"},[t("b-icon",{staticClass:"file-icon",attrs:{pack:"fas",icon:"upload"}}),t("span",{staticClass:"file-label"},[e._v(e._s(this.settings.datasetName||"Upload"))])],1)])],1),t("b-field",[t("b-checkbox",{attrs:{size:"is-small"},model:{value:e.header,callback:function(t){e.header=t},expression:"header"}},[e._v("Header")])],1),t("b-field",{attrs:{label:"Separator","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:e.separator,callback:function(t){e.separator=t},expression:"separator"}},e._l(e.separatorOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.label)+" ")])})),0)],1),t("b-field",{attrs:{label:"Decimal","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small","label-position":"on-border"},model:{value:e.decimal,callback:function(t){e.decimal=t},expression:"decimal"}},e._l(e.decimalOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.label)+" ")])})),0)],1),t("b-field",[t("b-select",{attrs:{expanded:!0,size:"is-small"},on:{input:e.handleFileSelect},model:{value:e.sampleDataset,callback:function(t){e.sampleDataset=t},expression:"sampleDataset"}},e._l(e.samplDataOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.name}},[e._v(" "+e._s(s.label)+" ")])})),0)],1)],1)}),c=[];class d{parse(e){throw new Error("Not implemented.")}}var m=s(8344),p=s.n(m);class u extends d{constructor(e){super(),this.separators={0:",",1:".",2:",",3:" "},this.separator=e.separator,this.delimiter=e.delimiter,this.has_header=e.header}parse(e){return new Promise((t=>{p().parse(e,{worker:!1,header:this.has_header,delimiter:this.separators[this.separator],transform:e=>"?"===e||"NA"===e?NaN:e,skipEmptyLines:!0,dynamicTyping:!0,complete:async function(e){t(e.data)}})}))}}s(16573),s(78100),s(77936),s(37467),s(44732),s(79577);class h extends d{parse(e){return new Promise((t=>{var s=new FileReader;s.onload=function(){var e=this.result,s=new Uint8Array(e),a=String.fromCharCode.apply(null,s),i=XLSX.read(a,{type:"binary"}),n=i.SheetNames[0],r=i.Sheets[n];t(XLSX.utils.sheet_to_json(r,{raw:!0}))},s.readAsArrayBuffer(e)}))}}class _ extends d{constructor(e){super(),this.separators={0:",",1:".",2:",",3:" "},this.separator=e.separator,this.delimiter=e.delimiter,this.has_header=e.header}parse(e){return new Promise((t=>{p().parse(e,{worker:!1,header:this.has_header,delimiter:this.separators[this.separator],transform:e=>"?"===e||"NA"===e?NaN:e,skipEmptyLines:!0,dynamicTyping:!0,complete:async function(e){if(1==this.delimiter)for(let t=0;t<e.data.length;t++){const s=e.data[t];for(let a=0;a<s.length;a++)e.data[t][a]=parseFloat(e.data[t][a].replace(/\./g,"").replace(",","."))}t(e.data)}})}))}}class f{static createParser(e,t){switch(e.toLowerCase()){case"csv":return new u(t);case"txt":{let e=new _(t);return e}case"xlsx":return new h;default:throw new Error(`Unsupported file type: ${e}`)}}}var g=s(40084),y=s(69005);const b=(0,y.nY)({id:"cart",state:()=>({counter:0,df:{},rawData:{},features:[],transformations:[],classTransformations:[],results:[],messages:[],datasetName:"",activeTab:0,dataSizeFlag:!1,resultActiveTab:"",datasetShape:{count:0,columns:0},target:null,isClassification:!0,seed:123}),getters:{items:e=>e.features,getDatasizeFlag:e=>e.dataSizeFlag,getCounter:e=>e.counter,getMessages:e=>e.messages.reverse(),getDatasetName:e=>e.datasetName,getDatasetShape:e=>e.datasetShape,getDataset:e=>e.df,getRawData:e=>e.rawData,currentTab:e=>e.activeTab,mergedClasses:e=>e.classTransformations,getSeed:e=>e.seed,getMethodResults:e=>e.results,getResultTab:e=>e.resultActiveTab,outputs:e=>e.results,transformationsList:e=>e.transformations,modelTarget:e=>e.target,classificationTask:e=>e.isClassification},actions:{setSeed(e){this.seed=e},setDatasetName(e){this.datasetName=e},setDatasetShape(e){this.datasetShape=e},resetFeatures(){this.features=[],this.transformations=[],this.classTransformations=[]},resetTransformations(){this.transformations=[]},setDatasizeFlag(e){this.dataSizeFlag=e},resetDataset(){this.datasetName="",this.datasetShape={count:0,columns:0}},increaseCounter(){this.counter++},setDataframe(e){this.df=e},setRawData(e){this.rawData=e},addFeature(e){e.scaler=0;let t=this.features.findIndex((t=>t.name===e.name));-1===t?this.features.push(e):this.features[t]=e},setClassTransformation(e){this.classTransformations=e},addTransformation(e){let t=this.transformations.findIndex((t=>t.name===e.name));-1===t?this.transformations.push(e):this.transformations[t]=e},addResult(e){this.results.push(e)},addMessage(e){var t=new Date;e["date"]=t.toLocaleString(),this.messages.push(e)},removeResult(e){const t=this.results.findIndex((t=>t.id===e));t>-1&&this.results.splice(t,1)},getResultVisualizations(e){const t=this.results.findIndex((t=>t.id===e));if(t>-1){let e=this.results[t].tables,s=this.results[t].plots;return[e,s]}},resetDF(){this.df={}},updateFeature(e){let t=this.features.findIndex((t=>t.name===e.name));-1!==t&&(this.features[t]=e)},removeItem(e){const t=this.features.lastIndexOf(e);t>-1&&this.features.splice(t,1)},setTarget(e){this.target=e},setmodelTask(e){this.isClassification=e},setActiveTab(e){this.activeTab=e},setResultActiveTab(e){this.resultActiveTab=e}}}),v=1e4;var x={setup(){const e=b();return{settings:e}},name:"UploadComponent",props:{msg:String},data(){return{sampleDataset:"none",file:null,separator:2,header:!0,decimal:1,decimalOptions:[{id:1,label:"."},{id:2,label:","}],separatorOptions:[{id:1,label:"."},{id:2,label:","},{id:3,label:"space"}],samplDataOptions:[{id:0,name:"none",label:"Select toy dataset"},{id:1,name:"iris",label:"iris"},{id:2,name:"wine",label:"wine"},{id:3,name:"diabetes",label:"diabetes"},{id:4,name:"housing",label:"California Housing"},{id:5,name:"Titanic",label:"Titanic"}]}},watch:{file:async function(e){try{let t=await this.process_file(e,e.name.split(".")[1]);this.initDataframe(t,e.name.split(".")[0])}catch(t){this.$buefy.toast.open("Failed to parse the dataset.")}}},methods:{shuffle(e,t){var s,a,i=e.length;while(i)a=Math.floor(this.random(t)*i--),s=e[i],e[i]=e[a],e[a]=s,++t},random(e){var t=1e4*Math.sin(e++);return t-Math.floor(t)},async initDataframe(e,t){this.settings.resetFeatures(),this.settings.setDatasetName(t),this.settings.setDatasetShape({count:e.$data.length,columns:e.columns.length});let s=await e.sample(e.$data.length,{seed:this.settings.getSeed});this.settings.setDataframe(s),this.$emit("uploaded",!0)},async process_file(e,t){let s={separator:this.separator,delimiter:this.decimal,header:this.header},a=await f.createParser(t,s).parse(e);a.length>v?(this.settings.setDatasizeFlag(!0),this.shuffle(a,this.settings.getSeed),a=a.slice(0,v)):this.settings.setDatasizeFlag(!1);let i=new g.DataFrame(a);return this.settings.setRawData(a),i},async handleFileSelect(e){if("none"==e)return;e+=".csv";let t,s=this;fetch("/"+e).then((e=>e.blob())).then((async a=>{t=new File([a],e);let i=await this.process_file(t,"csv");s.initDataframe(i,e.split(".")[0])})).catch((e=>{console.error("Error fetching the file:",e)}))}}},w=x,C=s(81656),k=(0,C.A)(w,l,c,!1,null,null,null),S=k.exports;const z={Numerical:{id:1,name:"Numerical"},Nominal:{id:2,name:"Nominal"},Ordinal:{id:3,name:"Ordinal"}},A={SPLIT:1,NO:2,KFOLD:3},P={No:{id:0,name:"No"},Scale:{id:1,name:"Scale"},"x^2":{id:2,name:"x^2"},"ln(x)":{id:3,name:"ln(x)"},Standardize:{id:4,name:"Standardize"}},E={classification:{logistic_regression:{id:1,label:"Logistic Regression",value:1,options:{regularization:{label:"regulrization",type:"select",default:"no",value:"no",values:[{label:"No",value:"no"},{label:"adaptive lasso",value:"Lasso"},{label:"ridge",value:"ridge"}]}}},discriminant_analysis:{id:2,label:"Discriminant Analysis",value:2,options:{type:{label:"type",type:"select",default:"linear",values:[{label:"linear",value:"linear"},{label:"quadratic",value:"quadratic"}]},priors:{label:"priors",type:"text",placeholder:"comma separated priors"}}},k_nearest_neighbour:{id:3,label:"k nearest neighbour",value:3,options:{min:{label:"min",type:"number",default:3},max:{label:"max",type:"number",default:9},metric:{label:"metrics",type:"select",default:"manhattan",values:[{label:"euclidean",value:"euclidean"},{label:"manhattan",value:"manhattan"}]}}},support_vector_machine:{id:4,label:"Support vector machine",value:4,options:{kernel:{label:"kernel",type:"select",default:"rbf",values:[{label:"RBF",value:"rbf"},{label:"Linear",value:"linear"},{label:"Polynomial",value:"poly"},{label:"Sigmoid",value:"sigmoid"}]},bias:{label:"bias",type:"number",for:["Sigmoid","Sigmoid"],default:0},c:{label:"Regularization parameter",type:"number",default:1},degree:{label:"degree",type:"number",for:["Polynomial"],default:3}}},random_forest:{id:5,label:"Random forest",value:5,options:{estimators:{label:"estimators",type:"number",default:100},features:{label:"features",type:"number",default:"sqrt"},depth:{label:"depth",type:"number",default:5},criteria:{label:"criteria",type:"select",default:"gini",values:[{label:"gini",value:"gini"},{label:"log loss",value:"log_loss"},{label:"entropy",value:"entropy"}]}}},boosting:{id:6,label:"Boosting",value:6,options:{booster:{type:"select",label:"booster",default:"gbtree",values:[{label:"gbtree",value:"gbtree"},{label:"gblinear",value:"gblinear"},{label:"dart",value:"dart"}]},eta:{label:"learning rate",type:"number",default:.3},estimators:{label:"estimators",type:"number",default:200},depth:{label:"depth",type:"number",default:5}}},naive_bayes:{label:"Naive Bayes",value:7,id:7,options:{laplace:{label:"laplace smoothing",type:"number",default:.05},priors:{label:"priors",type:"text",placeholder:"comma separated priors"},type:{label:"type",type:"select",default:"Gaussian",values:[{label:"Gaussian",value:"Gaussian"},{label:"Multinomial",value:"Multinomial"},{label:"Bernoulli",value:"Bernoulli"}]}}}},regression:{linear_regression:{label:"Linear Regression",value:9,id:9,feature_selection:["no","Lasso","ridge"],criteria:["AIC","BIC","AR2"],options:{regularization:{label:"regularization",type:"select",default:"Lasso",values:[{label:"adaptive lasso",value:"Lasso"},{label:"Ridge",value:"Ridge"}]}}},polynomial_regression:{label:"Polynomial Regression",value:14,id:14,feature_selection:["no","Lasso","ridge"],criteria:["AIC","BIC","AR2"],options:{regularization:{label:"regularization",type:"select",default:"Lasso",values:[{label:"Lasso",value:"Lasso"},{label:"Ridge",value:"Ridge"}]},degree:{label:"Degree",type:"number",default:2}}},k_nearest_neighbour:{label:"k nearest neighbour Regression",value:10,id:10,options:{min:{label:"min",type:"number",default:3},max:{label:"max",type:"number",default:9}}},boosting:{label:"Boosting Regression",value:11,id:11,options:{booster:{label:"booster",type:"select",default:"gbtree",values:[{label:"gbtree",value:"gbtree"},{label:"gblinear",value:"gblinear"},{label:"dart",value:"dart"}]},eta:{label:"learning rate",type:"number",default:.3},estimators:{label:"estimators",type:"number",default:200},depth:{label:"depth",type:"number",default:5}}},support_vector_machine:{label:"Support vector machine Regression",value:12,id:12,options:{kernel:{label:"kernel",type:"select",default:"rbf",values:[{label:"RBF",value:"rbf"},{label:"Linear",value:"linear"},{label:"Polynomial",value:"poly"},{label:"Sigmoid",value:"sigmoid"}]},gamma:{label:"gamma",type:"number",for:["RBF","Sigmoid","Polynomial"],default:1},bias:{label:"bias",type:"number",for:["Sigmoid","Sigmoid"],default:0},degree:{label:"degree polynomial",type:"number",for:["Polynomial"],default:3}}},random_forest:{label:"Random forest Regression",value:13,id:13,options:{estimators:{label:"num of estimators",type:"number",default:100},features:{label:"features length",type:"number",default:"sqrt"},depth:{label:"depth",type:"number",default:5},criteria:{type:"select",label:"criteria",default:"squared_error",values:[{label:"squared_error",value:"squared_error"},{label:"absolute_error",value:"absolute_error"},{label:"friedman_mse",value:"friedman_mse"},{label:"poisson",value:"poisson"}]}}},kernel_regression:{label:"Kernel Regression",value:15,id:15,options:{estimators:{type:"number",default:100}}},bspline_regression:{label:"Bspline Regression",value:16,id:16,options:{knots:{label:"knots",type:"number",default:5},degree:{label:"degree",type:"number",default:3}}}}};s(14603),s(47566),s(98721);const F=new Worker(new URL(s.p+s.u(221),s.b)),T={};F.onmessage=e=>{const{id:t,...s}=e.data,a=T[t];delete T[t],a(s)};const N=(()=>{let e=0;return(t,s)=>(e=(e+1)%Number.MAX_SAFE_INTEGER,new Promise((a=>{T[e]=a,F.postMessage({...s,python:t,id:e})})))})();class q{constructor(){}async predict(e,t,s=[]){this.context={x_train:e,x_test:s,has_test_set:s.length>0,n:+t};const a="\n        import matplotlib.pyplot as plt\n        import numpy as np\n        from sklearn.decomposition import PCA\n        from js import x_train,n,x_test,has_test_set\n        from sklearn.preprocessing import StandardScaler\n        x_train = np.array(x_train)\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(x_train) \n        pca_x = PCA(n_components=n,random_state = 42)\n        pca = pca_x.fit_transform(np.array(X_scaled))\n        pca_test=[]\n        if has_test_set:\n            x_test = np.array(x_test)\n            x_test_scaled= scaler.transform(x_test) \n            pca_test = pca_x.fit_transform(np.array(x_test_scaled))\n        ccircle = []\n        eucl_dist = []\n        for i,j in enumerate(x_train.T):\n            corr1 = np.corrcoef(j,pca[:,0])[0,1]\n            corr2 = np.corrcoef(j,pca[:,1])[0,1]\n            ccircle.append((corr1, corr2))\n            eucl_dist.append(np.sqrt(corr1**2 + corr2**2))\n        (pca,np.arange(1, len(pca_x.explained_variance_ratio_) + 1), pca_x.explained_variance_ratio_,ccircle,eucl_dist,pca_test)\n    ";try{const{results:e,error:t}=await N(a,this.context);if(e)return e;if(t)throw Error("Faced errot fitting PCA")}catch(i){throw Error("Failed to fit PCA")}}}var D=s(8964),M=s.n(D),O=s(91114);function I(e,t){return null==t&&(t=.5),tf.util.assert(t>=0&&t<=1,`Expected threshold to be >=0 and <=1, but got ${t}`),tf.tidy((()=>{const s=e.greater(tf.scalar(t));return tf.where(s,tf.onesLike(e),tf.zerosLike(e))}))}function R(e){let t=e.replace(/\s/g,"").replace(/[^\w-]/g,"_");return t}async function L(e,t,s){const a={y:e,y_pred:t,labels:s},i="\n        from sklearn.metrics import precision_recall_fscore_support, classification_report, f1_score,accuracy_score\n        from js import y_pred,y,labels       \n        from sklearn.metrics import recall_score,precision_score\n\n        precision = precision_score(y, y_pred, average=None,labels=labels)\n        recall = recall_score(y, y_pred, average=None,labels=labels)\n        f1_micro = f1_score(y, y_pred, average='micro')\n        f1_macro = f1_score(y, y_pred, average='macro')\n        accuracy = accuracy_score(y, y_pred)\n        (precision,recall,f1_micro,f1_macro,accuracy)\n    ";try{const{results:e,error:t}=await N(i,a);if(e)return{precision:e[0],recall:e[1],f1_micro:e[2],f1_macro:e[3],accuracy:e[4]};if(t)throw t}catch(n){throw n}}function X(e,t){const s=B(e),a=e.reduce(((e,t)=>e+Math.pow(t-s,2)),0),i=e.reduce(((e,s,a)=>e+Math.pow(s-t[a],2)),0);return 1-i/a}function j(e,t){if(e.length!==t.length)throw new Error("The lengths of actual values and predicted values must be the same.");const s=e.length;let a=0;for(let n=0;n<s;n++){const s=Math.pow(e[n]-t[n],2);a+=s}const i=a/s;return i}function B(e){return e.reduce(((e,t)=>e+t),0)/e.length}function G(e,t,s){try{switch(s){case"0":break;case"1":{let s=new g.MinMaxScaler;s.fit(e[t]),e.addColumn(t,s.transform(e[t]),{inplace:!0});break}case"2":e.addColumn(t,e[t].apply((e=>e*e)),{inplace:!0});break;case"3":e.addColumn(t,e[t].apply((e=>{let t=Math.log(e);if(isNaN(t))throw new Error("falied at data transformation.");return Math.log(e)})),{inplace:!0});break;case"4":{let s=new g.StandardScaler;s.fit(e[t]),e.addColumn(t,s.transform(e[t]),{inplace:!0});break}default:break}}catch(a){throw new Error("falied at data transformation.")}}function J(e,t,s){for(let a=0;a<t.length;a++){const i=t[a];let n=s.find((e=>e.name===i));n&&G(e,i,n.scaler.toString())}return e}function W(e,t=!1){if(t){let t=[],s=[],a=[],i=[];e.columns.forEach((a=>{"string"===e.column(a)?.dtype?t.push(a):s.push(a)})),t.forEach((t=>{let s=U(e.column(t).values).mode;a.push(s)})),s.forEach((t=>{let s=e.column(t).mean();i.push(s)})),e=e.fillNa(a,{columns:t}),e=e.fillNa(i,{columns:s})}else e.dropNa({axis:1,inplace:!0});return e}function U(e){if(0===e.length)return null;const t={total:0,mode:""};for(let i=0;i<e.length;i++){const s=e[i];null!==s&&void 0!==s&&(t["total"]++,s in t?t[s]++:t[s]=1)}let s=null,a=0;for(const i in t)"total"!==i&&t[i]>a&&(s=i,a=t[i]);return t["mode"]=s,t}function V(e,t){let s=e.copy(),a=t.filter((e=>e.type===z.Nominal.id||e.type===z.Ordinal.id)),i=[];return a.forEach((e=>{if(e.type===z.Ordinal.id){let t=new g.LabelEncoder;t.fit(s[e.name]);let a=t.transform(s[e.name]);s.addColumn(e.name,a.values,{inplace:!0}),i.push(e.name)}else s=(0,g.getDummies)(s,{columns:[e.name]}),s.drop({columns:[s.columns.find((t=>t.includes(e.name+"_")))],inplace:!0}),i.push(...s.columns.filter((t=>t.includes(e.name+"_"))))})),[s,i]}var H=s(79811),Q=s(96021),K=s(65599),Y=s(97271);const Z={toImageButtonOptions:{format:"png",height:null,width:null,scale:2}};class ee{constructor(){(0,O.A)(this,"kernelFunctions",{gaussian:function(e){return Math.exp(-.5*e*e)/Math.sqrt(2*Math.PI)},uniform:function(e){return Math.abs(e)<=1?.5:0},triangular:function(e){return Math.abs(e)<=1?1-Math.abs(e):0},biweight:function(e){return Math.abs(e)<=1?15/16*Math.pow(1-e*e,2):0},triweight:function(e){return Math.abs(e)<=1?35/32*Math.pow(1-e*e,3):0},Epanechnikov:function(e){return Math.abs(e)<=1?.75*(1-e*e):0}}),this.color_scheme=Q.A,this.color_scheme_sequential=K.Ay}classification_target_chart(e,t,s,a,i=""){var n=[...new Set(t)],r=t.map((e=>this.indexToColor(n.indexOf(e)))),o=[];o.push({name:"Count",data:e.map(((e,t)=>({y:e,color:r[t]})))}),Highcharts.chart(a,{credits:{enabled:!1},title:{text:""},chart:{type:"column"},xAxis:{categories:n},yAxis:{min:0},plotOptions:{column:{pointPadding:.1,borderWidth:0}},colors:r,series:o})}regression_target_chart(e,t,s){let a=[],i=[],n=e;var r=H.Wj(n,100);let o=H.JL(e,"gaussian","nrd");r.forEach((e=>{i.push(o(e,"nrd")),a.push([e,i[i.length-1]])})),Highcharts.chart(t,{credits:{enabled:!1},legend:{enabled:!1,verticalAlign:"top"},chart:{height:"300",type:"spline",animation:!0},title:{text:s},yAxis:{title:{text:null}},tooltip:{valueDecimals:3},plotOptions:{series:{marker:{enabled:!1},dashStyle:"shortdot",area:!0}},series:[{type:"area",dashStyle:"solid",lineWidth:2,data:a}]})}draw_categorical_barplot(e,t,s){const a=s+"- barplot";$("#categories_barplots").append(`<div class="column is-4" style="height:40vh;" id="${a}"></div>`);const i=e.reduce(((e,t)=>(e[t]=(e[t]||0)+1,e)),{}),n=Object.entries(i).map((([e,t])=>({value:e,count:t})));n.sort(((e,t)=>t.count-e.count));const r=n.slice(0,5);new Highcharts.Chart({chart:{renderTo:a,type:"column"},xAxis:{categories:r.map((e=>e.value))},title:{text:s},yAxis:{min:0,labels:{overflow:"justify"}},credits:{enabled:!1},plotOptions:{bar:{dataLabels:{enabled:!0}}},series:[{showInLegend:!1,name:s,data:r.map((e=>e.count))}]})}roc_chart(e,t,s){var a={x:s,y:t,type:"scatter",mode:"lines",name:"ROC Curve"},i={x:[0,1],y:[0,1],type:"scatter",name:"diagonal"},n={showlegend:!1,title:"ROC Curve",xaxis:{title:"False Positive Rate"},yaxis:{title:"True Positive Rate"}},r=[a,i];M().newPlot(e,r,n)}falsePositives(e,t){return tf.tidy((()=>{const s=tf.scalar(1),a=tf.scalar(0);return tf.logicalAnd(e.equal(a),t.equal(s)).sum().cast("float32")}))}indexToColor(e,t){return this.color_scheme_sequential((e+1)/t)}indexToColorSequential(e,t,s){let a=(e-t)/(s-t);return this.color_scheme_sequential(a)}reshape(e,t){if(0===t.length)return e[0];const[s,...a]=t,i=[],n=a.reduce(((e,t)=>e*t),1);console.log(n);for(let r=0;r<s;r++)i.push(this.reshape(e.slice(r*n,(r+1)*n),a));return i}async plot_tsne(e,t,s,a){document.getElementById("dimensionality_reduction_panel_tsne").style.display="block",console.assert(Array.isArray(e));const i=tsne.tsne(g.tensorflow.tensor2d(e));await i.compute(a);const n=i.coordinates(),r=n.dataSync(),o=this.reshape(r,n.shape);let l=[],c=[];if(t.length>0){t=t.flat();var d=[...new Set(t)];let e=o.map((function(e,s){return{label:t[s],x:e[0],y:e[1]}}));d.forEach(((t,s)=>{var a=e.filter((e=>e.label===t));c.push({x:a.map((e=>e.x)),y:a.map((e=>e.y)),mode:"markers",type:"scatter",name:t,marker:{size:4,color:this.indexToColor(s,d.length)}})}))}else{let e=o.map((function(e,t){return l.push(s[t][0]),{x:e[0],y:e[1]}})),t=Math.min(...l),a=Math.max(...l);c.push({x:l,y:e.map((e=>e.y)),mode:"markers+text",type:"scatter",marker:{size:4,color:l.map((e=>this.indexToColorSequential(e,t,a)))}})}var m={showlegend:t.length>0,margin:{l:50,r:40,b:50,t:40,pad:20},xaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1},yaxis:{linecolor:"black",linewidth:1,zeroline:!1,mirror:!0},legend:{x:1,xanchor:"right",y:1}};M().newPlot("tsne",c,m,{responsive:!0,modeBarButtonsToRemove:["resetScale2d","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]})}trueNegatives(e,t){return tf.tidy((()=>{const s=tf.scalar(0);return tf.logicalAnd(e.equal(s),t.equal(s)).sum().cast("float32")}))}falsePositiveRate(e,t){return tf.tidy((()=>{const s=this.falsePositives(e,t),a=this.trueNegatives(e,t);return s.div(s.add(a))}))}drawROC(e,t){return tf.tidy((()=>{const s=[0,.05,.1,.15,.2,.25,.3,.35,.4,.45,.5,.55,.6,.65,.7,.75,.8,.85,.9,.92,.94,.96,.98,1],a=[],i=[];let n=0;for(let r=0;r<s.length;++r){const o=s[r],l=I(t,o).as1D(),c=this.falsePositiveRate(e,l).dataSync()[0],d=tf.metrics.recall(e,l).dataSync()[0];i.push(c),a.push(d),r>0&&(n+=(a[r]+a[r-1])*(i[r-1]-i[r])/2)}return[n,i,a]}))}nrd(e){let t=H.Fx(e);const s=H.Z0(e);return"number"===typeof s&&(t=Math.min(t,s/1.34)),1.06*t*Math.pow(e.length,-.2)}hexToRgb(e){var t=/^#?([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})$/i.exec(e);return t?{r:parseInt(t[1],16),g:parseInt(t[2],16),b:parseInt(t[3],16),a:.5}:null}draw_kde(e,t,s,a="nrd",i=!1,n=!1){try{let m=e.column(t).values,p=this.nrd(m).toFixed(2),u=e.loc({columns:[t,s]}),h=[...new Set(u.column(s).values)];2===h.length&&h.sort();let _=u.values,f=[];var r=h.map((e=>this.indexToColor(h.indexOf(e),h.legend)));if(i)for(let e=0;e<h.length;e++){const t=h[e];let s=[];for(let e=0;e<_.length;e++){const a=_[e];a[1]===t&&s.push(a[0])}f.push(s)}else f.push(e[t].values);document.getElementById("kde_panel").style.display="block";var o=document.createElement("div");if(o.className="column is-3",o.setAttribute("id",t+"-kde-plot"),!n){let s=R(t);$("#container").append(`<div class="column is-4 is-size-6-tablet my-1">\n                <div class="columns is-multiline">\n                <div class="column is-12" >\n                    <div id="${s+"-kde-plot"}"> </div>\n                    <div id="${s+"-boxplot"}" style="height:20vh;width: 100%">\n                    </div>\n                    <div class="field has-addons has-addons-centered my-1">\n                    <div class="control">\n                    <span class="select is-small">\n                      <select id="${s+"-kernel_type"}">\n                      <option value="gaussian">gaussian</option>\n                        <option value="uniform">uniform</option>\n                        <option value="triangular">triangular</option>\n                        <option value="biweight">biweight</option>\n                        <option value="triweight">triweight</option>\n                        <option value="Epanechnikov">Epanechnikov</option>\n                      </select>\n                    </span>\n                    <p class="help is-success">Kernel</p>\n                  </div>\n                  <div class="control">\n                        <div class="select is-small">\n                            <select id="${s+"--normal"}">\n                                <option value="0">No</option>\n                                <option value="1">Scale</option>\n                                <option value="2">x^2</option>\n                                <option value="3">ln(x)</option>\n                                <option value="4">Standardize </option>\n                            </select>\n                        </div>\n                    <p class="help is-success">Normalization</p>\n                    </div>\n                        <div class="control">\n                            <input class="input is-small" type="number"  min="0" id="${s+"-kde"}" value="${p}">\n                            <p class="help is-success">Bandwidth</p>\n                        </div>\n                        <p class="control">\n                            <a class="button is-success is-small" id="${s+"-kde-button"}">\n                                Apply\n                            </a>\n                        </div>\n                    </div>\n                  </div>\n                </div>`),document.getElementById(s+"--normal").addEventListener("change",(function(){const a=document.getElementById("target").value;let i=document.getElementById(a).value!==z.Numerical,n=e.loc({columns:[t,a]}),r=document.getElementById(s+"--normal").value;G(n,t,r),n.dropNa({axis:1,inplace:!0});var o=parseFloat(document.getElementById(s+"-kde").value);l.draw_kde(n,t,a,o,i,!0)}))}var l=this;let g=R(t);document.getElementById(g+"-kde-button").addEventListener("click",(function(){const s=document.getElementById("target").value;let a=document.getElementById(s).value!==z.Numerical,i=e.loc({columns:[t,s]}),n=document.getElementById(g+"--normal").value;G(i,t,n);var r=parseFloat(document.getElementById(g+"-kde").value);i.dropNa({axis:1,inplace:!0}),l.draw_kde(i,t,s,r,a,!0)}));let y=g+"-kde-plot",b=[...u.column(t).values];var c=H.Wj(b,100);let v,x=[],w=document.getElementById(g+"-kernel_type")?.value??"gaussian",C=[];if(i)for(let e=0;e<f.length;e++){if(f[e].length>2){let t=[];v=H.JL(f[e],this.kernelFunctions[w],a);let s=[];c.forEach((e=>{t.push(v(e,a)),s.push([e,t[t.length-1]])})),x.push(s)}else x.push([]);C.push({name:h[e],x:f[e],marker:{color:r[e]},type:"box"})}else{for(let e=0;e<f.length;e++)if(f[e].length>2){let t=[];v=H.JL(f[e],this.kernelFunctions[w],a);let s=[];c.forEach((e=>{t.push(v(e,a)),s.push([e,t[t.length-1]])})),x.push(s)}else x.push([]);C.push({name:t,x:m,type:"box"})}let k=4e3;var d={yaxis:{visible:!1},showlegend:!1,margin:{l:20,r:10,b:60,t:10},legend:{x:1,xanchor:"right",y:1}};M().newPlot(g+"-boxplot",C,d,{autosize:!0,responsive:!0,modeBarButtonsToRemove:["pan","resetScale2d","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]}),Highcharts.chart(y,{credits:{enabled:!1},legend:{enabled:!!i,align:"right",verticalAlign:"top"},chart:{height:"300",type:"spline",animation:!0},title:{text:t},yAxis:{title:{text:null}},tooltip:{valueDecimals:3},plotOptions:{series:{marker:{enabled:!1},dashStyle:"shortdot",color:r,animation:{duration:k},area:!0}},series:x.map(((e,t)=>({type:"area",name:h[t],dashStyle:"solid",lineWidth:2,color:r[t],data:e})))}),window.dispatchEvent(new Event("resize"))}catch(m){throw new Error("falied at plotting kde.")}}async classificationPCA(e,t,s,a,i,n){const r=new q;var o=t.map((e=>this.indexToColor(a.indexOf(e),a.length)));const l=await r.predict(e,n);let c=[],d=[],m=[],p=[],u=[],h=[],_=[],f=[];l[0].forEach(((a,i)=>{if(s["indexes"].includes(i)){let n=s["indexes"].findIndex((e=>e==i));u.push(e[i].join()),h.push([t[i],s["mispredictions"][n]]),m.push(a[0]),p.push(a[1]),_.push(o[i])}else c.push(a[0]),d.push(a[1]),f.push(o[i])}));var g={x:c,y:d,name:"Predictions",text:t,mode:"markers",type:"scatter",marker:{size:4,color:f,symbol:"circle"}},y={name:"Missclassifications",x:m,y:p,text:u,customdata:h,mode:"markers",type:"scatter",marker:{size:7,color:_,symbol:"cross"},hovertemplate:"Features : %{text}<br>True class: %{customdata[0]}<br>Predited class: %{customdata[1]}<extra></extra>"},b=[g,y];M().newPlot("pca_results_"+i,b,{title:{text:"Principle Component Analysis of Predictions"},hovermode:"closest",hoverlabel:{bgcolor:"#FFF"},showlegend:!0,legend:{x:1,xanchor:"right",y:1,bgcolor:"rgba(0,0,0,0)"},xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:"PC1"},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:"PC2"}},{...Z,staticPlot:!1,responsive:!0,modeBarButtonsToRemove:["resetScale2d","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]})}purge_charts(e){M().purge(e)}async draw_pca(e,t,s,a,i,n,r=!1){const o=new q;t=t.flat();var l=[...new Set(t)];const[c,d,m,p,u]=await o.predict(e,a);let h=[];for(let k=0;k<i.length;k++){let e=[],a=i[k];c.forEach(((i,n)=>{e.push({x:i[a[0]-1],y:i[a[1]-1],label:t[n]}),h.push(s[n][0])}));let n=[];if(0!==l.length)l.forEach(((t,s)=>{var a=e.filter((e=>e.label===t));n.push({x:a.map((e=>e.x)),y:a.map((e=>e.y)),mode:"markers",type:"scatter",name:t,marker:{size:4,color:this.indexToColor(s,l.length)}})}));else{let t=e.map((e=>e.x)),s=e.map((e=>e.y)),a=Math.max(...t),i=Math.min(...t);n.push({x:t,y:s,mode:"markers",type:"scatter",marker:{color:t.map((e=>this.indexToColorSequential(e,i,a))),size:2}})}M().newPlot("pca_"+k,n,{showlegend:0!=l.length,margin:{l:40,r:40,b:40,t:40,pad:10},legend:{x:1,xanchor:"right",y:1,bgcolor:"rgba(0,0,0,0)"},xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:"PC"+a[0]},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:"PC"+a[1]}},{...Z,responsive:!0,staticPlot:!0})}let _=[],f=[];u.forEach(((e,t)=>{_.push({axref:"x",x:0,ayref:"y",y:0,arrowside:"start",arrowcolor:this.indexToColor(t,u.length),font:{color:"black",size:8},xanchor:"left",yanchor:"top",arrowwidth:1.2,arrowhead:5,text:n[t],hovertext:n[t]+`(${p[t][0].toFixed(2)},${p[t][1].toFixed(2)})`,ax:p[t][0],ay:p[t][1]})})),f=[{type:"circle",xref:"x",yref:"y",x0:-1,y0:-1,x1:1,y1:1,line:{color:"rgba(50, 171, 96, 1)"}}],M().newPlot("correlation_circle",[],{annotations:_,shapes:f,showlegend:!0,height:300,width:300,margin:{l:40,r:40,b:40,t:40,pad:10},legend:{x:1,xanchor:"right",y:1,bgcolor:"rgba(0,0,0,0)"},xaxis:{range:[-1.2,1.2],linecolor:"black",linewidth:1,mirror:!0,title:"PC1"},yaxis:{range:[-1.2,1.2],linecolor:"black",linewidth:1,mirror:!0,title:"PC2"}},{...Z,responsive:!0});let g=[],y=0,b=[];m.forEach(((e,t)=>{y+=e,b.push(t+1),g.push(y)}));var v={name:"Propotional",x:b,y:m,type:"scatter"},x={name:"Cumulative",x:b,y:g,type:"scatter"},w={showlegend:!1,x:[1.1,1.1],y:[.92,.82],text:["0.9","0.8"],mode:"text"},C=[v,x,w];r&&M().newPlot("scree_plot",C,{legend:{x:.1,y:.2,traceorder:"normal",orientation:"h",font:{size:8},bgcolor:"rgba(0,0,0,0)"},shapes:[{type:"line",x0:1,y0:.9,x1:Math.max(...b),y1:.9,line:{color:"rgb(250, 0, 0)",width:1.5,dash:"dashdot"}},{type:"line",x0:1,y0:.8,x1:Math.max(...b),y1:.8,line:{color:"rgb(50, 171, 96)",width:1.5,dash:"dashdot"}}],margin:{l:60,r:60,b:40,t:40,pad:10},xaxis:{linecolor:"black",linewidth:1,tickmode:"linear",dtick:1,mirror:!0,zeroline:!1,title:"Number of PCs"},yaxis:{linecolor:"black",linewidth:1,rang:[0,1],zeroline:!1,mirror:!0,title:"Explained variance"}},{...Z,responsive:!0})}drawStackedHorizontalChart(e,t){var s={x:[20,14,23],y:["giraffes","orangutans","monkeys"],name:"SF Zoo",orientation:"h",marker:{color:"rgba(55,128,191,0.6)",width:1},type:"bar"},a={x:[12,18,29],y:["giraffes","orangutans","monkeys"],name:"LA Zoo",orientation:"h",type:"bar",marker:{color:"rgba(255,153,51,0.6)",width:1}},i=[s,a],n={title:"Colored Bar Chart",barmode:"stack"};M().newPlot("myDiv",i,n)}regularization_plot(e,t,s){const a=[];s.forEach(((s,i)=>{a.push({x:e,y:t.map((e=>e[i])),type:"scatter",name:s,mode:"line"})}));var i={colorway:["#f3cec9","#e7a4b6","#cd7eaf","#a262a9","#6f4d96","#3d3b72","#182844"],title:"Lasso Coefficients as Alpha varies",xaxis:{type:"log",title:"Alpha (Regularization Strength)"},yaxis:{title:"Coefficient Value"}};M().newPlot("lasso_plot",a,i)}argmax(e){return e.reduce(((e,t,s,a)=>t>a[e]?s:e),0)}probabilities_boxplot(e,t,s,a){let i=[],n=[],r={};t.forEach(((t,s)=>{t in r||(r[t]=[]),r[t].push(e[s])}));for(const c in r){const e=r[c];e.forEach((e=>{const t=Math.max(...e);n.push({trueClass:c,predicted:e.findIndex((e=>e==t)),probablity:e})}))}let o=0,l=n.map((e=>e.predicted));for(let c in r){let e=s.findIndex((e=>e==c));i.push({type:"box",name:c,marker:{color:this.indexToColor(e,s.length),size:2,line:{outlierwidth:.3}},line:{width:.5},y:n.map((e=>e.probablity[o])),x:l}),o++}M().newPlot("proba_plot_"+a,i,{xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:"class"},yaxis:{title:"Predicted Probability",linecolor:"black",zeroline:!1,linewidth:1,mirror:!0},legend:{x:1,xanchor:"right",y:1,bgcolor:"rgba(0,0,0,0)"},boxmode:"group"},{responsive:!0})}async plotConfusionMatrix(e,t,s,a,i){const n=await Y.metrics.confusionMatrix(e,t,a.length);let r=await L(e.arraySync(),t.arraySync(),a),o=r.accuracy.toFixed(2),l=r.f1_micro.toFixed(2),c=r.f1_macro.toFixed(2),d=n[0].length,m=[],p=[];for(let f=0;f<d;f++)m.push(parseFloat(r.precision[f].toFixed(2)));for(let f=0;f<d;f++)p.push(parseFloat(r.recall[f].toFixed(2)));g.tensorflow.dispose(e),g.tensorflow.dispose(t);const u=["Precession","Recall","F1 score","Support"];s.push("Precession"),p.push(0),n.push(m);let h=s.filter((e=>!u.includes(e))),_=[];for(let f=0;f<n.length;f++){const e=n[f];f<n.length-1&&e.push(p[f]);for(let t=0;t<e.length;t++){const s=e[t];_.push([t,f,s])}}return h.push("Recall"),Highcharts.chart("confusion_matrix_"+i,{credits:{enabled:!1},exporting:{enabled:!0},chart:{type:"heatmap",plotBorderWidth:1},title:{text:"",style:{fontSize:"0.75em"}},xAxis:[{categories:h,title:{text:"Predicted Class"}},{linkedTo:0,opposite:!0,tickLength:0,labels:{formatter:function(){var e=this.chart,t=(Highcharts.each,e.series[0]),s=0,i=this.value;return t.options.data.forEach((function(e,t){e[0]===i&&e[1]<a.length&&(s+=e[2])})),+s.toFixed(2)}}}],yAxis:[{categories:s,title:{text:"Actual Class"},reversed:!0,endOnTick:!1},{linkedTo:0,opposite:!0,tickLength:0,labels:{formatter:function(){var e=this.chart,t=(Highcharts.each,e.series[0]),s=0,i=this.value;return t.options.data.forEach((function(e,t){e[1]<a.length&&e[1]===i&&e[0]<a.length&&(s+=e[2])})),+s.toFixed(2)}},title:null}],colorAxis:{min:0,minColor:"#FFFFFF",maxColor:Highcharts.getOptions().colors[0]},legend:{enabled:!1,align:"center",layout:"horizontal",margin:0,verticalAlign:"top",y:5,symbolHeight:10},series:[{name:"",borderWidth:1,data:_,dataLabels:{enabled:!0,useHTML:!0,color:"#000000",formatter:function(){var e=this.series.data.reduce((function(e,t,s){return(s+1)%(a.length+1)===0?e:+(e+t?.value).toFixed(2)}),0),t=this.point.value,s=this.point.index>=this.series.data.length-1*(a.length+1);if(s||(this.point.index+1)%(a.length+1)===0)return'<p style="margin:auto; text-align:center;">'+ +t.toFixed(2)+"</p>";var i=+(t/e*100).toFixed(2);return'<p style="margin:auto; text-align:center;">'+ +t.toFixed(2)+"<br/>("+(+i).toFixed(2)+"%)</p> "}}}],responsive:{rules:[{condition:{maxWidth:200},chartOptions:{yAxis:{labels:{format:"{substr value 0 1}",padding:0,style:{fontSize:"6px"}}}}}]}}),[o,l,c]}plot_regularization(e,t,s,a){let i=`\n                    <div class="column is-6" id="regularization_${a}" style="height: 40vh;">\n                    </div>\n    `;$("#tabs_info li[data-index='"+a+"'] #results_"+a).append(i);let n=[];for(let o=0;o<s.length;o++)n.push({name:s[o],data:e.map((e=>e[o]))});const r=[];for(let o=0;o<t.length;o++)r.push(t[o].toFixed(2));Highcharts.chart("regularization_"+a,{title:{text:""},yAxis:{title:{text:"Coefficients"}},xAxis:{title:{text:"penalty weight"},categories:r},legend:{layout:"vertical",align:"right",verticalAlign:"middle"},plotOptions:{series:{label:{connectorAllowed:!1}}},series:n,responsive:{rules:[{condition:{maxWidth:500},chartOptions:{legend:{layout:"horizontal",align:"center",verticalAlign:"bottom"}}}]}})}yhat_plot(e,t,s,a=""){M().newPlot(s,[{x:e,y:t,type:"scatter",name:"y",mode:"markers"},{x:e,y:e,mode:"lines",type:"scatter",line:{color:"red",dash:"dash"},name:"y = x line"}],{title:{text:a,font:{family:"sans-serif",size:10},xref:"paper",x:.05},showlegend:!1,xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"y",font:{family:"sans-serif",size:14,color:"#7f7f7f"}}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"predictions",font:{family:"sans-serif",size:14,color:"#7f7f7f"}}},margin:{l:40,r:10,b:40,t:20,pad:0}},{responsive:!0})}residual_plot(e,t,s,a=""){M().newPlot(s,[{x:e,y:t,type:"scatter",name:"y",mode:"markers",marker:{color:"rgb(17, 157, 255)",size:7}}],{title:{text:a,font:{family:"sans-serif",size:10},xref:"paper",x:.05},showlegend:!1,xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"y",font:{family:"sans-serif",size:14,color:"#7f7f7f"}}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"residuals",font:{family:"sans-serif",size:14,color:"#7f7f7f"}}},margin:{l:40,r:10,b:40,t:20,pad:0}},{responsive:!0})}ScatterplotMatrix(e,t,s,a,i=!0,n,r,o){return new Promise(((n,o)=>{setTimeout((()=>{let o=[...new Set(s)];2===o.length&&o.sort();var l=s.map((e=>this.indexToColor(o.indexOf(e),o.length)));let c=[],d=1;for(let n=0;n<t.length;n++)for(let m=0;m<t.length;m++){if(n===m){let s,l=[],m=[],p=[];if(i)if(n>=t.length-a)if(n===t.length-1){for(let t=0;t<o.length;t++)l.push(e.filter((s=>s[e[0].length-1]===o[t])).map((e=>e[n])));c.push({x:o,y:l.map((e=>e.length)),type:"bar",xaxis:"x"+d,yaxis:"y"+d,marker:{color:o.map(((e,t)=>this.indexToColor(t,o.length))),opacity:.7}})}else{let t=[...new Set(e.map((e=>e[n])))];for(let s=0;s<o.length;s++){let a=e.filter((t=>t[e[0].length-1]===o[s])),i=[];t.forEach((e=>i.push(a.filter((t=>t[n]===e)).length))),l.push({items:a,counts:i})}o.forEach(((e,s)=>{c.push({x:t,y:l[s].counts,type:"bar",xaxis:"x"+d,yaxis:"y"+d,marker:{color:this.indexToColor(s,o.length),opacity:.7}})}))}else{for(let t=0;t<o.length;t++)l.push(e.filter((s=>s[e[0].length-1]===o[t])).map((e=>e[n])));for(let e=0;e<l.length;e++)if(l[e].length>2){let t=this.nrd(l[e]).toFixed(2);m=H.Wj(l[e],100);let a=[];s=H.JL(l[e],"gaussian","nrd");let i=[];m.forEach((e=>{a.push(s(e,t)),i.push([e,a[a.length-1]])})),p.push(i)}else p.push([]);for(let e=0;e<p.length;e++)c.push({type:"scatter",x:p[e].map((e=>e[0])),y:p[e].map((e=>e[1])),xaxis:"x"+d,yaxis:"y"+d,mode:"lines",name:"Red",fill:"tozeroy",line:{color:this.indexToColor(e,p.length),opacity:.7,width:3}})}else if(r.includes(t[n])){let t=e.map((e=>e[n])),s=[...new Set(t)],a=[];for(let e=0;e<s.length;e++){const i=s[e];a.push(t.filter((e=>e===i)).length)}c.push({x:s,y:a,type:"bar",name:"Trace 1",xaxis:"x"+d,yaxis:"y"+d})}else{l.push(e.map((e=>e[n])));for(let e=0;e<l.length;e++)if(l[e].length>2){let t=[],a=this.nrd(l[e]).toFixed(2);m=H.Wj(l[e],100),s=H.JL(l[e],"gaussian","nrd");let i=[];m.forEach((e=>{t.push(s(e,a)),i.push([e,t[t.length-1]])})),p.push(i)}else p.push([]);c.push({type:"scatter",x:p[0].map((e=>e[0])),y:p[0].map((e=>e[1])),mode:"lines",fill:"tozeroy",xaxis:"x"+d,yaxis:"y"+d,name:"Red",line:{color:"rgb(219, 64, 82)",opacity:.7,width:3}})}}else if(n===t.length-1)c.push({y:e.map((e=>e[n])),x:e.map((e=>e[m])),color:l,marker:{colorscale:"Portland",color:i?l:s,opacity:.7,size:2},type:"scattergl",mode:"markers",xaxis:"x"+d,yaxis:"y"+d});else if(m>=t.length-a)if(i){let s=[...new Set(e.map((e=>e[m])))].sort(((e,t)=>e-t)),a=[];for(let i=0;i<o.length;i++)for(let r=0;r<s.length;r++){let l=e.filter((e=>e[m]===s[r]&&e[t.length-1]===o[i]));l&&a.push({y:l.map((e=>e[n])),marker:{color:this.indexToColor(i,o.length),size:2,line:{outlierwidth:.3}},type:"box",xaxis:"x"+d,yaxis:"y"+d,line:{width:.5}})}if(m<t.length-1){for(let e=0;e<a.length/2;e++)a[e]["x"]=Array(a[e]["y"].length).fill(e),a[a.length/2+e]&&(a[a.length/2+e]["x"]=Array(a[e]["y"].length).fill(e+.5));c=c.concat(a)}else c=c.concat(a)}else c.push({x:[],y:[],mode:"lines",name:"Trace 1"});else if(m>n){let t=e.map((e=>e[n])),s=e.map((e=>e[m]));c.push({x:[1.5],y:[1.5],text:[jStat.corrcoeff(t,s).toFixed(2)],mode:"text",textfont:{size:12,color:"black"},xaxis:"x"+d,yaxis:"y"+d,type:"scatter"})}else c.push({y:e.map((e=>e[n])),x:e.map((e=>e[m])),color:l,type:"scattergl",mode:"markers",marker:{colorscale:"Portland",color:i?l:s,size:2},xaxis:"x"+d,yaxis:"y"+d});d++}for(var m={width:100*t.length,height:100*t.length,spacing:0,showlegend:!1,boxmode:"overlay",grid:{rows:t.length,xgap:0,ygap:0,columns:t.length,pattern:"independent"},margin:{t:20,r:20}},p=0;p<t.length;p++)for(var u=0;u<t.length;u++){var h="xaxis"+(p*t.length+u+1),_="yaxis"+(p*t.length+u+1);let e=10;m[h]={linecolor:"black",linewidth:1,mirror:!0,showgrid:!1,showticklabels:!1,tickfont:{size:e}},m[_]={linecolor:"black",linewidth:1,mirror:!0,showgrid:!1,showticklabels:!1,tickfont:{size:e}},p===t.length-1&&(m[h]={linecolor:"black",linewidth:1,mirror:!0,tickfont:{size:e},title:{text:t[u],font:{size:e}}}),0===u&&(m[_]={linecolor:"black",linewidth:1,mirror:!0,tickfont:{size:e},title:{text:t[p],font:{size:e}}})}M().react("scatterplot_mtx",c,m,{...Z,staticPlot:!0,modeBarButtonsToRemove:["resetScale2d","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]}),n()}),1e3)}))}KNNPerformancePlot(e,t,s,a="Accuracy"){let i=[];i.push({x:e.map((e=>e[1])),y:e.filter((e=>"manhattan"===e[0])).map((e=>Number(e[2]))),mode:"lines",name:"manhattan test set",line:{color:"rgb(55, 128, 191)",width:2}}),i.push({x:e.map((e=>e[1])),y:e.filter((e=>"euclidean"===e[0])).map((e=>Number(e[2]))),mode:"lines",name:"euclidean test set",line:{color:"rgb(219, 64, 82)",width:2}});var n={showlegend:!0,legend:{orientation:"h",font:{family:"sans-serif",size:8,color:"#000"}},xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"K"}},yaxis:{range:[0,1],linecolor:"black",linewidth:1,mirror:!0,title:{text:a}},shapes:[{type:"line",x0:t,y0:0,x1:t,y1:1,line:{dash:"dot",color:"rgb(55, 128, 191)",width:1}}]};M().newPlot("knn_table_"+s,i,n,{responsive:!0})}KNNPerformancePlotRegression(e,t,s,a){let i=[];i.push({x:e.map((e=>e.k)),y:e.filter((e=>"manhattan"===e.metric)).map((e=>Number(e.evaluation.toFixed(2)))),mode:"lines",name:"manhattan test set",line:{color:"rgb(55, 128, 191)",width:2}}),i.push({x:e.map((e=>e.k)),y:e.filter((e=>"euclidean"===e.metric)).map((e=>Number(e.evaluation.toFixed(2)))),mode:"lines",name:"euclidean test set",line:{color:"rgb(219, 64, 82)",width:2}}),i.push({x:e.map((e=>e.k)),y:e.filter((e=>"manhattan"===e.metric)).map((e=>Number(e.evaluation_train.toFixed(2)))),mode:"lines",name:"manhattan train set",line:{color:"rgb(55, 128, 191)",width:1}}),i.push({x:e.map((e=>e.k)),y:e.filter((e=>"euclidean"===e.metric)).map((e=>Number(e.evaluation_train.toFixed(2)))),mode:"lines",name:"euclidean train set",line:{color:"rgb(219, 64, 82)",width:1}});var n=Number.POSITIVE_INFINITY,r=Number.NEGATIVE_INFINITY;i.forEach((e=>{let t=Math.min(...e.y),s=Math.max(...e.y);t<n&&(n=t),s>r&&(r=s)}));var o={showlegend:!0,legend:{orientation:"h",font:{family:"sans-serif",size:8,color:"#000"}},xaxis:{title:{text:"K"}},yaxis:{title:{text:"MSE"}},shapes:[{type:"line",x0:t.k,y0:n,x1:t.k,y1:r,line:{color:"rgb(55, 128, 191)",width:1}},{type:"line",x0:s.k,y0:n,x1:s.k,y1:r,line:{color:"rgb(55, 128, 191)",width:1}}]};M().newPlot("knn_table_"+a,i,o)}correaltoinMatrixColorscale(e){let t=e[0].length,s=[];for(let r=0;r<t;r++)s.push(...e[r]);s.sort();let a=0;for(let r=0;r<s.length;r++){if(!(s[r]<0))break;a+=1}let i=Math.round((a-1)/s.length*100)/100,n=[[0,"rgb(0, 0, 100)"],[i,"rgb(161, 161, 255)"],[i+.001,"rgb(253, 237, 237)"],[1,"rgb(255, 0, 0)"]];return n}async correlationHeatmap(e,t,s){for(var a=[{z:t,x:s,y:s,type:"heatmap",zmin:-1,zmax:1,hoverongaps:!1,colorscale:[[0,"rgb(74,141,255)"],[.1,"rgb(102,151,255)"],[.2,"rgb(121,170,255)"],[.3,"rgb(137,187,255)"],[.4,"rgb(205,221,255)"],[.5,"rgb(255,255,255)"],[.51,"rgb(253, 237, 237)"],[.6,"rgb(255,169,169)"],[.75,"rgb(249,100,100)"],[.95,"rgb(225,0,0)"],[1,"rgb(165,0,0)"]],showscale:!1}],i={annotations:[],font:{size:10},xaxis:{ticks:"",side:"bottom",tickangle:-90},yaxis:{autorange:"reversed",tickangle:-45,ticks:"",ticksuffix:" "},autosize:!0},n=0;n<s.length;n++)for(var r=s.length-1;r>=0;r--){var o=t[n][r];let e;e="black";var l={xref:"x1",yref:"y1",x:s[n],y:s[r],text:o.toFixed(2),font:{family:"Arial",size:8,color:e},showarrow:!1};i.annotations.push(l)}await M().newPlot(e,a,i,{...Z,responsive:!0})}async dendogramPlot(e,t,s,a,i){var n={x:a,y:a,z:t,type:"heatmap",zmin:-1,zmax:1,hoverongaps:!1,colorscale:[[0,"rgb(74,141,255)"],[.1,"rgb(102,151,255)"],[.2,"rgb(121,170,255)"],[.3,"rgb(137,187,255)"],[.4,"rgb(205,221,255)"],[.5,"rgb(255,255,255)"],[.51,"rgb(253, 237, 237)"],[.6,"rgb(255,169,169)"],[.75,"rgb(249,100,100)"],[.95,"rgb(225,0,0)"],[1,"rgb(165,0,0)"]],xaxis:"x",yaxis:"y",colorbar:{thickness:10,len:.5}};let r=[],o=s.length+1,l=0,c=0,d=0,m=0;for(let v=0;v<i.length;v++)r.push(a.findIndex((e=>e==i[v])));let p=[];for(let v=0;v<o;v++)p.push(10*(v+1));let u={data:[],layout:{width:"100%",showlegend:!1,xaxis:{showticklabels:!0,tickmode:"array",ticks:"outside",showgrid:!1,mirror:"allticks",zeroline:!1,showline:!0,rangemode:"tozero",type:"linear"},yaxis:{showticklabels:!0,ticks:"outside",showgrid:!1,mirror:"allticks",zeroline:!1,showline:!0,rangemode:"tozero",type:"linear"},hovermode:"closest",autosize:!1,height:"100%"}},h={data:[],layout:{width:"100%",showlegend:!1,xaxis:{showticklabels:!0,ticks:"outside",showgrid:!1,mirror:"allticks",zeroline:!1,showline:!0,rangemode:"tozero",type:"linear"},yaxis:{showticklabels:!0,tickmode:"array",ticks:"outside",showgrid:!1,mirror:"allticks",zeroline:!1,showline:!0,rangemode:"tozero",type:"linear"},hovermode:"closest",autosize:!1,height:"100%"}},_={};s.forEach(((e,t)=>{let s,a;if(r[e[0]]+1&&(s=r[e[0]]+1??e[0]+1),r[e[1]]+1&&(a=r[e[1]]+1??e[1]+1),0==l&&(l=parseFloat(t+1)/o),s<=o&&a<=o)m=(s*(Math.max(...p)/o)+a*(Math.max(...p)/o))/2,u.data.push({yaxis:"y2",x:[10*s,10*s,10*a,10*a],mode:"lines",xaxis:"x",marker:{color:`${this.indexToColor(t)}`},y:[c,l,l,c],type:"scatter"});else{c=s<=o?l:_[e[0]]?.y_current,l=parseFloat(t+1)/o;let i=[s<=o?10*s:_[e[0]]?.x,s<=o?10*s:_[e[0]]?.x,a<=o?10*a:_[e[1]]?.x,a<=o?10*a:_[e[1]]?.x],n=[_[e[0]]?.y_current??0,l,l,_[e[1]]?.y_current??0];u.data.push({yaxis:"y2",x:i,mode:"lines",xaxis:"x",marker:{color:`${this.indexToColor(t)}`},y:n,type:"scatter"}),m=i.reduce(((e,t)=>e+t),0)/4}_[o+t]={x:m,y_current:l}}));let f=0,g=0;_=[],s.forEach(((e,t)=>{let s=r[e[0]]+1,a=r[e[1]]+1;if(0==f&&(f=parseFloat(t+1)/o),s<=o&&a<=o)d=(-10*s+-10*a)/2-2,h.data.push({yaxis:"y",y:[-10*s,-10*s,-10*a,-10*a],mode:"lines",xaxis:"x2",marker:{color:`${this.indexToColor(t)}`},x:[g,f,f,g],type:"scatter"});else{g=s<=o?f:_[e[0]].x,f=parseFloat(t+1)/o;let i=[s<=o?-10*s:_[e[0]]?.y,s<=o?-10*s:_[e[0]]?.y,a<=o?-10*a:_[e[1]]?.y,a<=o?-10*a:_[e[1]]?.y];h.data.push({yaxis:"y",y:i,mode:"lines",xaxis:"x2",marker:{color:`${this.indexToColor(t)}`},x:[_[e[0]]?.x??0,f,f,_[e[1]]?.x??0],type:"scatter"}),d=i.reduce(((e,t)=>e+t),0)/4}_[o+t]={y:d,x:f}}));var y={annotations:[],font:{size:10},autosize:!0,yaxis:{domain:[0,.75],mirror:!1,showgrid:!1,showline:!1,zeroline:!1,showticklabels:!0,ticks:"",tickvals:p.map((e=>-e)),ticktext:a,tickangle:-45},xaxis:{domain:[0,.75],mirror:!1,showgrid:!1,showline:!1,zeroline:!1,showticklabels:!0,ticks:"",tickvals:p,ticktext:a,tickangle:-90},xaxis2:{domain:[.75,1],mirror:!1,showgrid:!1,showline:!1,zeroline:!1,showticklabels:!1,ticks:"",ticktext:a},yaxis2:{domain:[.75,1],mirror:!1,showgrid:!1,showline:!1,zeroline:!1,showticklabels:!1,ticktext:a},showlegend:!1,coloraxis:{colorscale:"YlGnBu",showscale:!0,cmin:-1,cmax:1},margin:{l:60,r:30,b:60,t:30}};let b=u["data"];b=b.concat(h["data"]),n["x"]=p,n["y"]=p.map((e=>-e)),b=b.concat(n),M().newPlot(e,b,y,{...Z,responsive:!0})}PFIBoxplot(e,t,s){let a=[],i=[];t.forEach((e=>{const t=e.reduce(((e,t)=>e+t),0);i.push(t/e.length)}));let n=Math.max(...i),r=Math.min(...i);t.forEach(((e,t)=>{a.push({x:Array.from(e),type:"box",name:s[t],marker:{color:this.indexToColorSequential(i[t]+.1,r,n)}})}));var o={title:{text:"Permutation Feature Importance",font:{size:14},xref:"paper",x:.05},showlegend:!1,xaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1},yaxis:{linecolor:"black",linewidth:1,mirror:!0,automargin:!0,zeroline:!1}};M().newPlot("pfi_boxplot_"+e,a,o,{responsive:!0})}plotPDP(e,t,s,a,i,n){let r="pdp_containers_"+e;e="pdp_plot_"+e,s.forEach(((s,o)=>{let l=document.getElementById(r),c=document.createElement("div");c.classList.add("column","is-6");let d=e+"_"+o;c.id=d,c.style.height="400px",l.after(c);let m=[];const p=n.includes(i[o]);t[o].forEach(((e,i)=>{p?m.push({x:s,y:Array.from(e),type:"bar",name:a[i],marker:{color:this.indexToColor(i,t[o].length)}}):m.push({x:s,y:Array.from(e),mode:"line",name:a[i],marker:{color:this.indexToColor(i,t[o].length)}})}));var u={title:{text:"Partial Dependence Plot - "+i[o],font:{size:14},xref:"paper",x:.05},legend:{orientation:"h"},font:{size:10},autosize:!0,xaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1},yaxis:{linecolor:"black",zeroline:!1,linewidth:1,mirror:!0,title:{text:"Prediction"}}};M().newPlot(d,m,u,{...Z,responsive:!0})}))}plotPDPRegression(e,t,s,a,i,n){let r="pfi_boxplot_"+e,o=document.getElementById(r),l=document.createElement("div");l.classList.add("column","is-6");const c=e+"_number";l.id=c,l.style.height="400px",o.after(l),o=document.getElementById(c),l=document.createElement("div"),l.classList.add("column","is-6");const d=e+"_class";l.id=d,l.style.height="400px",o.after(l);let m=[],p=[];s.forEach(((e,s)=>{n.includes(i[s])?t[s].forEach(((a,n)=>{p.push({x:e,y:Array.from(a),type:"bar",name:i[s],marker:{color:this.indexToColor(s,t.length),opacity:.7}})})):t[s].forEach(((a,n)=>{let r=new g.MinMaxScaler;r.fit(e);let o=e;m.push({x:o,y:Array.from(a),mode:"line",name:i[s],marker:{color:this.indexToColor(s,t.length)}})}))}));var u={title:{text:"Partial Dependence Plot",font:{size:14},xref:"paper",x:.05},legend:{x:.1,y:1,orientation:"h",font:{size:8},bgcolor:"rgba(0,0,0,0)"},font:{size:10},autosize:!0,xaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1,title:{text:"Feature"}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1,title:{text:"Prediction"}}};M().newPlot(c,m,u,{...Z,responsive:!0});var h={title:{text:"Partial Dependence Plot",font:{size:14},xref:"paper",x:.05},barmode:"group",font:{size:10},autosize:!0,xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"Feature"}},bargap:.05,yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"Prediction"}}};M().newPlot(d,p,h)}drawAutoencoder(e,t=1,s=0,a,i){a=a.map((e=>e[0]));let n=[];if(i){var r=[...new Set(a)];n=e.map(((e,t)=>this.indexToColor(r.indexOf(a[t]),r.length)))}else{let e=Math.min(...a),t=Math.max(...a);n=a.map((s=>this.indexToColorSequential(s,e,t)))}var o={x:e.map((e=>e[t])),y:e.map((e=>e[s])),mode:"markers",type:"scatter",name:"Team A",marker:{size:3,color:n}},l=[o],c={legend:{y:.5,yref:"paper",font:{family:"Arial, sans-serif",size:20,color:"grey"}},xaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1},yaxis:{linecolor:"black",linewidth:1,zeroline:!1,mirror:!0},margin:{l:50,r:40,b:50,t:40,pad:20}};M().newPlot("autoencoder",l,c)}plotROC(e,t,s,a,i){let n=[];t.forEach(((e,t)=>{n.push({x:e,y:s[t],mode:"line",name:a[t],marker:{color:this.indexToColor(t,a.length)}})})),n.push({x:[0,1],y:[0,1],mode:"line",name:"Chance Line",marker:{color:"black"},line:{dash:"dot",width:1}});var r={title:{text:(a.length>2?" One-vs-Rest Strategy ROC Curve":"ROC Curve")+" AUC: "+(+i).toFixed(2),font:{size:14}},margin:{b:40},legend:{x:1,xanchor:"right",y:.1,bgcolor:"rgba(0,0,0,0)"},showlegend:!0,xaxis:{linecolor:"black",linewidth:1,range:[-.1,1.1],mirror:!0,title:{text:"False positive rate"}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,range:[-.1,1.1],title:{text:"True positive rate"}}};M().newPlot("roc_plot_"+e,n,r,{responsive:!0})}uniformSplist(e){let t=[];for(let s=0;s<e;s++)t.push(s/(e-1));return t}parallelCoordinatePlot(e,t,s,a){let i=new g.LabelEncoder;a&&(i.fit(t),t=i.transform(t));var n=[...new Set(t)].sort(((e,t)=>e-t));let r=this.uniformSplist(n.length),o=n.map(((e,t)=>[r[t],this.indexToColor(e,n.length)]));var l=[{type:"parcoords",pad:[20,20,20,20],line:{color:t,colorscale:a?o:"jet"},dimensions:[]}];s.forEach(((t,s)=>{l[0].dimensions.push({label:t,values:e.map((e=>e[s]))})}));var c={xaxis:{linecolor:"black",linewidth:1,mirror:!0},yaxis:{linecolor:"black",linewidth:1,mirror:!0}};M().newPlot("parallel_coordinate_plot",l,c,{...Z,responsive:!0,modeBarButtonsToRemove:["resetScale2d","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]})}}class te{constructor(e,t){this.data_parser=e,this.chart_controller=t}get_model_settings(){let e={},t=parseInt(document.getElementById("model_name").value);const s=document.getElementById("target").value;let a=document.getElementById(s).value!==z.Numerical;var i;if(a){for(const n in E.classification)if(E.classification[n].value===t){t=n,e.name=E.classification[n].label,i=E.classification[t];break}}else for(const n in E.regression)if(E.regression[n].value===t){t=n,e.name=E.regression[n].label,i=E.regression[t];break}t=parseInt(document.getElementById("model_name").value);for(const n in i?.options)if("select"===i.options[n].type){let s=document.getElementById(n+"_"+t)?.value;e[n]=s??i.options[n].default}else if("number"===i.options[n].type){let s=document.getElementById(n+"_"+t)?.value;e[n]=s?parseFloat(s):i.options[n].default}else{let s=document.getElementById(n+"_"+t)?.value;e[n]=s??i.options[n].default}return e}scale_data(e,t,s){switch(s){case"1":{let s=new g.MinMaxScaler;s.fit(e[t]),e.addColumn(t,s.transform(e[t]),{inplace:!0});break}case"2":e.addColumn(t,e[t].apply((e=>e*e)),{inplace:!0});break;case"3":e.addColumn(t,e[t].apply((e=>Math.log(e))),{inplace:!0});break;case"4":{let s=new g.StandardScaler;s.fit(e[t]),e.addColumn(t,s.transform(e[t]),{inplace:!0});break}default:break}}createAlgorithmsSelect(e){let t='<div id="algorithm" class="column is-9"><div class="select is-small mb-1"> <select id="model_name" class="select">';const s=1==e?"regression":"classification";for(const a in E[s])if(E.hasOwnProperty.call(E[s],a)){const e=E[s][a];t+=`<option value="${e.value}">${e.label}</option>`}return t+="</select></div></div>",t}updateAlgorithmsSelect(e){let t='<div class="select is-small mb-1"> <select id="model_name" class="select">';const s=1==e?"regression":"classification";for(const a in E[s])if(E.hasOwnProperty.call(E[s],a)){const e=E[s][a];t+=`<option value="${e.value}">${e.label}</option>`}return t+="</select></div>",t}find_selected_columns(e,t=!1){const s=[];return e.forEach((e=>{let a=R(e);(document.getElementById(a+"-checkbox").checked||t)&&s.push(e)})),s}find_selected_columns_types(e,t=!0){if(!1===t){const t=document.getElementById("target").value;e=e.filter((e=>e!==t))}const s=[];return e.forEach((e=>{let t=R(e);s.push({name:e,type:document.getElementById(t).value})})),s}createTargetDropdown(e){let t='<div  class="column is-12"><div class="label is-size-7">Target</div><div class="select is-fullwidth is-small mb-1"> <select id="target">';return e.columns.forEach((e=>{let s=R(e);t+=`<option value="${s}">${s}</option>`})),t+="</select></div></div>",t}createFeaturesDropdown(e){let t='<div  class="column is-4"><h4>Target</h4><div class="select mb-1"> <select class="select" id="kde_feature">';for(const s in e)t+=`<option value="${s}">${s}</option>`;return t+="</select></div></div>",t}insertSpaces(e){return e=e.replace(/([a-z])([A-Z])/g,"$1 $2"),e=e.replace(/([A-Z])([A-Z][a-z])/g,"$1 $2"),e}renderDatasetStats(e,t,s){let a=[],i=[];const n=[{field:"name",label:"#"},{field:"min",label:"Min"},{field:"max",label:"Max"},{field:"mean",label:"Mean"},{field:"median",label:"Median"},{field:"std",label:"std"},{field:"missingVlauesCount",label:"# NAs"},{field:"type",label:"type"}],r=[{field:"name",label:"#"},{field:"shape",label:"Shape"},{field:"mode",label:"Mode"},{field:"percentage",label:"Mode Percentage"},{field:"missingVlauesCount",label:"# NAs"}];for(let o=0;o<t.length;o++){const s=t[o].name;a.push({name:s,min:e.column(s).min().toFixed(2),max:e.column(s).max().toFixed(2),median:e.column(s).median().toFixed(2),mean:e.column(s).mean().toFixed(2),std:e.column(s).std().toFixed(2),missingValuesCount:e.column(s).isNa().sum(),type:1,selected:t[o].selected})}return s.forEach(((t,s)=>{let a=t.name;const n=[...new Set(e.column(a).values)],r=this.getCategoricalMode(e.column(a).values);i.push({name:a,shape:n.length,mode:r["mode"],percentage:(r[r["mode"]]/r["total"]).toFixed(2),missingValuesCount:e.column(a).isNa().sum(),type:2,selected:t.selected})})),[n,a,r,i]}getCategoricalMode(e){if(0===e.length)return null;const t={total:0,mode:""};for(let i=0;i<e.length;i++){const s=e[i];null!==s&&void 0!==s&&(t["total"]++,s in t?t[s]++:t[s]=1)}let s=null,a=0;for(const i in t)"total"!==i&&t[i]>a&&(s=i,a=t[i]);return t["mode"]=s,t}get_numeric_columns(e,t){let s=this.find_selected_columns(e.columns,!t),a=this.find_selected_columns_types(s);s=s.filter((e=>{let t=a.findIndex((t=>t.name===e));return a[t]?.type===z.Numerical}));let i=[];return e.columns.forEach((t=>{"string"!==e.column(t).dtype&&"Id"!==t&&s.includes(t)&&i.push(t)})),i}get_categorical_columns(e,t){let s=this.find_selected_columns(e.columns,!t),a=this.find_selected_columns_types(s);s=s.filter((e=>{let t=a.findIndex((t=>t.name===e));return-1!==t&&a[t]?.type!==z.Numerical}));let i=[];return e.columns.forEach((e=>{"Id"!==e&&s.includes(e)&&i.push(e)})),i}column_types(e){let t=this.find_selected_columns(e,!1);return this.find_selected_columns_types(t)}async visualize(e,t,s){this.renderDatasetStats(e);let a=this.get_numeric_columns(e,!0),i=this.get_categorical_columns(e,!0);const n=document.getElementById("target").value;let r=[...new Set(a.concat(i))];const o=e.loc({columns:r});o.dropNa({axis:1,inplace:!0}),a=a.filter((e=>e!==n));let l=document.getElementById(n).value!==z.Numerical,c=0;if(a.length>0&&c<10&&(document.getElementById("container").innerHTML="",a.forEach((e=>{e!==n&&this.chart_controller.draw_kde(o,e,n,"nrd",l)})),c++),c=0,i.length>0&&c<10&&(document.getElementById("categories_barplots").innerHTML="",i.forEach((e=>{e!==n&&this.chart_controller.draw_categorical_barplot(o.loc({columns:[e]}).values,n,e)})),c++),l){let t=e.column(n).values,a=[...new Set(t)],i=[];for(let e=0;e<a.length;e++)i.push(t.filter((t=>t===a[e])).length);this.chart_controller.classification_target_chart(i,a,s,"target_chart",n)}else this.chart_controller.regression_target_chart(e.column(n).values,"target_chart",n);a=this.get_numeric_columns(e,!0),i=this.get_categorical_columns(e,!0),e=this.data_parser.handle_missing_values(e)}toggle_loading_progress(e=!1){let t=document.getElementById("progress");t.style.display=e?"none":"block"}init_tooltips(e){e("#kde_help",{interactive:!0,popperOptions:{positionFixed:!0},content:"Default bandwidth method :Silverman’s rule of thumb"}),e("#normalization_help",{interactive:!0,popperOptions:{positionFixed:!0},content:"<p>not functional yet</p><p>standard scaler uses z = (x - u) / s</p><p>Transform features by scaling each feature to a given range</p>",allowHTML:!0}),e("#imputation_help",{interactive:!0,popperOptions:{positionFixed:!0},content:"currently we are just deleting rows with missing values",allowHTML:!0}),e("#cv_help",{interactive:!0,popperOptions:{positionFixed:!0},content:"option 1 and 2 are working",allowHTML:!0})}predictions_table_regression(e,t,s,a){let i=[];e.addColumn("residuals: ",t.map(((e,t)=>e-s[t])),{inplace:!0}),e.addColumn("predictions: ",s,{inplace:!0}),e.addColumn("y",t,{inplace:!0}),e.columns.forEach((e=>{i.push({title:e})}));let n=e.columns.slice().reverse();new DataTable("#predictions_table_"+a,{pageLength:5,responsive:!1,paging:!0,columnDefs:[{render:function(e,t,s){return e.toFixed(2)},targets:"_all"}],bPaginate:!0,columns:i.reverse(),data:e.loc({columns:n}).values,bDestroy:!0})}removeTable(e){$(e).DataTable().destroy()}predictions_table(e,t,s,a=null,i=0){let n=[];null!==a&&e.addColumn("probs",a,{inplace:!0}),e.addColumn("y",t,{inplace:!0}),e.addColumn("predictions",s,{inplace:!0}),e.columns.forEach((e=>{n.push({title:e})}));let r=e.columns.slice().reverse();new DataTable("#predictions_table_"+i,{pageLength:10,responsive:!1,paging:!0,bPaginate:!0,columns:n.reverse(),data:e.loc({columns:r}).values,bDestroy:!0,columnDefs:[{},{render:function(e,t,s){return e.toFixed(2)},targets:[...Array(n.length).keys()].filter((e=>e>=2))}],rowCallback:function(e,t,s){var a=t[0],i=t[1];a!==i&&$(e).addClass("is-danger")}})}yhat_plot(e,t,s,a=""){M().newPlot(s,[{x:e,y:t,type:"scatter",name:"y",mode:"markers",marker:{color:"black",size:2}},{x:e,y:e,mode:"lines",type:"scatter",line:{color:"red",dash:"dash"},name:"y = x line"}],{height:300,width:300,title:{text:a,font:{size:10},xref:"paper",x:.05},showlegend:!1,xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"y",font:{size:14}}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"predictions",font:{size:14}}},margin:{l:40,r:10,b:40,t:20,pad:0}},{responsive:!0,staticPlot:!0})}residual_plot(e,t,s,a=""){M().newPlot(s,[{x:e,y:t,type:"scatter",name:"y",mode:"markers",marker:{color:"black",size:2}}],{title:{text:a,font:{size:10},xref:"paper",x:.05},showlegend:!1,xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"y",font:{size:14}}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"residuals",font:{size:14}}},margin:{l:40,r:10,b:40,t:20,pad:0}},{responsive:!0,staticPlot:!0})}}class se{constructor(){this.chartController=new ee,this.ui=new te(null,null),this.task=null,this.predictions=[],this.hasProbability=!1,this.plots=[],this.tables=[],this.seed=1,this.hasExplaination=!0,this.id=null,this.helpSectionId="help"}async train(e,t,s,a){throw new Error("Not implemented",e,t,s,a)}async evaluateModel(e,t,s){return await L(e,t,s)}generatePythonCode(e,t){return`\nfrom sklearn.datasets import load_iris\n${e}\nfrom sklearn.inspection import partial_dependence, PartialDependenceDisplay, permutation_importance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Load the Iris dataset\niris = load_iris()\nX, y = iris.data, iris.target\nfeature_names = iris.feature_names\nclass_names = iris.target_names\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the model\n${t}\nmodel.fit(X_train,y_train)\n# Confusion Matrix\ny_pred = model.predict(X_test)\nconf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(y))\ndisp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\ndisp.plot(cmap=plt.cm.Blues, values_format="d")\nplt.title("Confusion Matrix")\nplt.show()\n\n# PCA of Results\npca = PCA(n_components=2)\nX_test_pca = pca.fit_transform(X_test)\n\n# Plot PCA results with true labels and predicted labels\nplt.figure(figsize=(12, 6))\n\n# Subplot 1: PCA with True Labels\nplt.subplot(1, 2, 1)\nscatter = plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test, cmap='viridis', s=50)\nplt.colorbar(scatter, ticks=np.arange(len(class_names)), label="True Labels")\nplt.title("PCA of Test Set (True Labels)")\nplt.xlabel("Principal Component 1")\nplt.ylabel("Principal Component 2")\n\n\nplt.tight_layout()\nplt.show()\n# Compute and plot Partial Dependence Plot (PDP)\nfig, ax = plt.subplots(figsize=(12, 8))\nPartialDependenceDisplay.from_estimator(\n    model, X_train, [0, 1,2,3], feature_names=feature_names, ax=ax,target=0\n)\nplt.show()\n\n# Compute and plot Permutation Feature Importance (PFI)\npfi = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n# Convert PFI results to a DataFrame for easier manipulation\npfi_df = pd.DataFrame({\n    "Feature": np.repeat(feature_names, repeats=pfi.importances.shape[1]),\n    "Importance": pfi.importances.ravel()\n})\n\n# Create boxplots for Permutation Feature Importance\nplt.figure(figsize=(10, 6))\npfi_df.boxplot(by="Feature", column="Importance", grid=False, vert=False, showmeans=False)\nplt.xlabel("Permutation Importance")\nplt.ylabel("Feature")\nplt.title("Permutation Feature Importance (PFI)")\nplt.suptitle("")  # Remove automatic suptitle from boxplot\nplt.show()\n        `.trim()}async visualize(e,t,s,a,i){const n=Object.keys(i.$labels);await this.chartController.plotConfusionMatrix(g.tensorflow.tensor(a),g.tensorflow.tensor(t),n,Object.values(i.$labels),this.id),this.ui.predictions_table(e,i.inverseTransform(t),i.inverseTransform(a),null,this.id),this.plots.push("pca_results_"+this.id),this.tables.push("#predictions_table_"+this.id)}}class ae extends se{constructor(e){super(),this.options=e,this.model=null,this.summary=null,this.model_stats_matrix=null}async train(e,t,s,a,i,n){this.context={X_train:e,y_train:t,y_test:a,X_test:s,seed:this.seed,regularization_type:"Lasso"===this.options.regularization.value?1:0,labels:i};const r=window.webr;await r.init(),await r.installPackages(["jsonlite","ggplot2","plotly","nnet","purrr","dplyr","ggrepel","glmnet","modelsummary","broom"],{quiet:!0}),await r.objs.globalEnv.bind("xx",e),await r.objs.globalEnv.bind("random_seed",this.seed),await r.objs.globalEnv.bind("x_test",s),await r.objs.globalEnv.bind("y",t),await r.objs.globalEnv.bind("names",i),await r.objs.globalEnv.bind("categorical_columns",0===n?.length?["empty"]:n),await r.objs.globalEnv.bind("is_lasso",this.context.regularization_type);const o=await r.evalR('\n                    library(plotly)\n                    library(ggplot2)\n                    library(purrr)\n                    library(dplyr)\n                    library(ggrepel)\n                    library(modelsummary)\n                    library(jsonlite)\n                    library(glmnet)\n                    library(broom)\n                    set.seed(random_seed)\n                    # Select all columns except the first as predictors. \n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n                    scale_df <- as.data.frame(x)\n                    cols_to_scale <- setdiff(names, categorical_columns)\n                    scale_df[cols_to_scale] <- scale(scale_df[cols_to_scale])\n                    if(is_lasso){\n                        cvfit = cv.glmnet(as.matrix(scale_df), y, alpha = 1, family = "multinomial", type.measure = "class")\n                    }else{\n                       cvfit = cv.glmnet(as.matrix(scale_df), y, alpha = 0, family = "multinomial", type.measure = "class")\n                    }\n                    betas = as.matrix(cvfit$glmnet.fit$beta)\n                    lambdas = cvfit$lambda\n                    names(lambdas) = colnames(betas)\n                    \n                    df  <- data.frame(\n                        log_lambda = log(cvfit$lambda),       \n                        mean_cv_error = cvfit$cvm,                \n                        lower_error = cvfit$cvup,    \n                        upper_error = cvfit$cvlo    \n                        )\n                    lambda_min <- log(cvfit$lambda.min) \n                    lambda_1se <- log(cvfit$lambda.1se)  \n            \n                    p <-ggplot(df,aes(x=log_lambda,y=mean_cv_error)) + \n                    geom_point(col="#f05454") + \n                    geom_errorbar(aes(ymin = lower_error,ymax=upper_error),col="#30475e") + \n                    geom_vline(xintercept=c(lambda_1se,lambda_min),\n                                linetype="dashed")+\n                    annotate("text", x = lambda_min, y = max(df$mean_cv_error), \n                            label = "Min", color = "black", hjust = -0.1) +\n                    annotate("text", x = lambda_1se, y = max(df$mean_cv_error) - 0.02, \n                            label = "1-SE", color = "black", hjust = -0.1) +\n                    xlab("log lambda") +\n                    ylab("Error")+\n                    theme_bw()\n\n\n                    colnames(x_test) <- names\n                    model <- nnet::multinom(y ~ . , data = as.data.frame(x))\n                    s <- summary(model)\n                    coefs <- s$coefficients\n                    stds <- s$standard.errors\n                    z_scores <- coefs / stds\n                    p_values <- 2 * (1 - pnorm(abs(z_scores)))\n                    preds <- predict(model,newdata=as.data.frame(x_test))\n                    preds_probs <- predict(model,type = \'probs\',newdata=as.data.frame(x_test))\n                    # confidence interval\n                    z <- 1.96  \n                    conf_int <- list()\n\n                    for (class in rownames(coef(model))) {\n                    conf_int[[class]] <- cbind(\n                        class = class,\n                        Estimate = coefs[class, ],\n                        Lower = coefs[class, ] - z * stds[class, ],\n                        Upper = coefs[class, ] + z * stds[class, ]\n                    )\n                    }\n                    conf_int_df <- do.call(rbind, conf_int)\n                    best_model <- glmnet(x, y, alpha =is_lasso,family = "multinomial", type.measure = "class", lambda = cvfit$lambda.min)\n                    coefficients <- coef(best_model)\n\n                    non_zero_features <- list()\n                    for (class_name in names(coefficients)) {\n                    class_coefficients <- coefficients[[class_name]]\n                    dense_coefficients <- as.matrix(class_coefficients)\n                    non_zero_indices <- which(dense_coefficients != 0, arr.ind = TRUE)\n                    non_zero_features <- c(non_zero_features,rownames(dense_coefficients)[non_zero_indices[, 1]])\n                    }\n                    non_zero_features <- unique(non_zero_features)\n                    non_zero_features <- unlist(Filter(function(x) x != "", non_zero_features))\n                    x_filterd <- x[,unlist(non_zero_features)]\n                    x_test_filterd <- x_test[,unlist(non_zero_features)]\n\n\n                    model_lambda_min <- nnet::multinom(y ~ . , data = as.data.frame(x_filterd))\n                    s <- summary(model_lambda_min)\n                    coefs_lambda_min <- s$coefficients\n                    stds_lambda_min <- s$standard.errors\n                    z_scores_lambda_min <- coefs_lambda_min / stds_lambda_min\n                    p_values_lambda_min <- 2 * (1 - pnorm(abs(z_scores_lambda_min)))\n                    preds_lambda_min <- predict(model_lambda_min,newdata=as.data.frame(x_test_filterd))\n                    preds_probs_lambda_min <- predict(model_lambda_min,type = \'probs\',newdata=as.data.frame(x_test_filterd))\n                    # confidence interval\n                    z <- 1.96  \n                    conf_int <- list()\n\n                    for (class in rownames(coef(model_lambda_min))) {\n                    conf_int[[class]] <- cbind(\n                        class = class,\n                        Estimate = coefs_lambda_min[class, ],\n                        Lower = coefs_lambda_min[class, ] - z * stds_lambda_min[class, ],\n                        Upper = coefs_lambda_min[class, ] + z * stds_lambda_min[class, ]\n                    )\n                    }\n\n\n                    \n                    conf_int_lambda_min_df <- do.call(rbind, conf_int)\n\n                    best_model <- glmnet(x, y, alpha =is_lasso,family = "multinomial", type.measure = "class", lambda = cvfit$lambda.1se)\n                    coefficients <- coef(best_model)\n                    print("got here")\n                    non_zero_features <- list()\n                    for (class_name in names(coefficients)) {\n                    class_coefficients <- coefficients[[class_name]]\n                    dense_coefficients <- as.matrix(class_coefficients)\n                    non_zero_indices <- which(dense_coefficients != 0, arr.ind = TRUE)\n                    non_zero_features <- c(non_zero_features,rownames(dense_coefficients)[non_zero_indices[, 1]])\n                    }\n                    non_zero_features <- unique(non_zero_features)\n                    non_zero_features <- unlist(Filter(function(x) x != "", non_zero_features))\n\n                    x_filterd <- x[,unlist(non_zero_features)]\n                    x_test_filterd <- x_test[,unlist(non_zero_features)]\n                    model_lambda_1se <- nnet::multinom(y ~ . , data = as.data.frame(x_filterd))\n                    s <- summary(model_lambda_1se)\n                    coefs_lambda_1se <- s$coefficients\n                    stds_lambda_1se <- s$standard.errors\n                    z_scores_lambda_1se <- coefs_lambda_1se / stds_lambda_1se\n                    p_values_lambda_1se <- 2 * (1 - pnorm(abs(z_scores_lambda_1se)))\n                    preds_lambda_1se <- predict(model_lambda_1se,newdata=as.data.frame(x_test_filterd))\n                    preds_probs_lambda_1se <- predict(model_lambda_1se,type = \'probs\',newdata=as.data.frame(x_test_filterd))\n                    # confidence interval\n                    z <- 1.96  \n                    conf_int <- list()\n\n                    for (class in rownames(coef(model_lambda_1se))) {\n                    conf_int[[class]] <- cbind(\n                        class = class,\n                        Estimate = coefs_lambda_1se[class, ],\n                        Lower = coefs_lambda_1se[class, ] - z * stds_lambda_1se[class, ],\n                        Upper = coefs_lambda_1se[class, ] + z * stds_lambda_1se[class, ]\n                    )\n                    }\n                    conf_int_lambda_1se_df <- do.call(rbind, conf_int)\n\n                    lambda_values <- cvfit$glmnet.fit$lambda\n\n                    coef_list <- coef(cvfit$glmnet.fit)\n\n                    cv_summary <- map_df(names(coef_list), function(class) {\n                    coef_matrix <- as.matrix(coef_list[[class]])[-1, ]  # Remove intercept\n                    data.frame(\n                        lambda = rep(lambda_values, each = nrow(coef_matrix)),\n                        predictor = rep(rownames(coef_matrix), length(lambda_values)),\n                        coefficient = as.vector(coef_matrix),\n                        class = class\n                    )\n                    })\n\n                    list(\n                    plotly_json(p, pretty = FALSE)\n                    ,rownames(coefs)\n                    ,toJSON(coefs,pretty = TRUE)\n                    ,toJSON(stds,pretty = TRUE)\n                    ,toJSON(z_scores,pretty = TRUE)\n                    ,toJSON(p_values,pretty = TRUE)\n                    ,preds_probs\n                    ,preds \n                    ,toJSON(conf_int_df)\n                    ,rownames(conf_int_df)\n\n                    ,rownames(conf_int_lambda_min_df)\n                    ,toJSON(coefs_lambda_min,pretty = TRUE)\n                    ,toJSON(stds_lambda_min,pretty = TRUE)\n                    ,toJSON(p_values_lambda_min,pretty = TRUE)\n\n                    ,rownames(conf_int_lambda_1se_df)\n                    ,toJSON(coefs_lambda_1se,pretty = TRUE)\n                    ,toJSON(stds_lambda_1se,pretty = TRUE)\n                    ,toJSON(p_values_lambda_1se,pretty = TRUE)\n                    ,model[["AIC"]]\n                    ,model_lambda_min[["AIC"]]\n                    ,model_lambda_1se[["AIC"]]\n                    ,toJSON(cv_summary)\n                    ,toJSON(conf_int_lambda_min_df)\n                    ,toJSON(conf_int_lambda_1se_df)\n                    ,lambda_min\n                    ,lambda_1se\n                    )\n\n                    ');let l=await o.toArray();this.summary={regularization_plot:JSON.parse(await l[0].toString()),classes:await l[1].toArray(),coefs:JSON.parse(await l[2].toArray()),stds:JSON.parse(await l[3].toArray()),z_scores:JSON.parse(await l[4].toArray()),p_values:JSON.parse(await l[5].toArray()),probabities:await l[6].toArray(),predictions:(await l[7].toArray()).map((e=>e-1)),confidence_intervals:JSON.parse(await l[8].toString()),confidence_intervals_row_names:await l[9].toArray(),aic:await l[18].toNumber(),best_fit_min:{names:await l[10].toArray(),confidence_intervals:JSON.parse(await l[22].toString()),coefs:JSON.parse(await l[11].toArray()),stds:JSON.parse(await l[12].toArray()),p_values:JSON.parse(await l[13].toArray()),aic:await l[19].toNumber()},best_fit_1se:{names:await l[14].toArray(),confidence_intervals:JSON.parse(await l[23].toString()),coefs:JSON.parse(await l[15].toArray()),stds:JSON.parse(await l[16].toArray()),p_values:JSON.parse(await l[17].toArray()),aic:await l[20].toNumber()},fit:JSON.parse(await l[21].toArray()),lambda_min:await l[24].toNumber(),lambda_1se:await l[25].toNumber()},this.model_stats_matrix=[];let c=[...i];c.unshift("(Intercept)");let d=[...new Set(this.summary["best_fit_min"].names)].map((e=>e.replace(/^`|`$/g,""))),m=[...new Set(this.summary["best_fit_1se"].names)].map((e=>e.replace(/^`|`$/g,"")));this.summary.regularization_plot.layout["showlegend"]=!1,this.summary.regularization_plot.layout["autosize"]=!0,this.summary.regularization_plot.layout.legend={font:{size:8,color:"#000"}};for(let p=0;p<this.summary.classes.length;p++){for(let e=0;e<c.length;e++){let t=[];t.push(c[e]),t.push(isNaN(this.summary["coefs"][p][e])?" ":this.summary["coefs"][p][e].toFixed(2)),t.push(isNaN(this.summary["stds"][p][e])?" ":this.summary["stds"][p][e].toFixed(2)),t.push(isNaN(this.summary["p_values"][p][e])?" ":this.summary["p_values"][p][e].toFixed(2));let s=d.findIndex((t=>t===c[e]));if(-1!==s){let e=this.summary["best_fit_min"]["coefs"][p][s],a=this.summary["best_fit_min"]["stds"][p][s],i=this.summary["best_fit_min"]["p_values"][p][s];t.push(isNaN(e)?0:e.toFixed(2)),t.push(isNaN(a)?0:a.toFixed(2)),t.push(isNaN(i)?0:i.toFixed(2))}else t.push(" "),t.push(" "),t.push(" ");if(s=m.findIndex((t=>t===c[e])),-1!==s){let e=this.summary["best_fit_1se"]["coefs"][p][s],a=this.summary["best_fit_1se"]["stds"][p][s],i=this.summary["best_fit_1se"]["p_values"][p][s];t.push(isNaN(e)?0:e.toFixed(2)),t.push(isNaN(a)?0:a.toFixed(2)),t.push(isNaN(i)?0:i.toFixed(2))}else t.push(" "),t.push(" "),t.push(" ");this.model_stats_matrix.push(t)}if(p<this.summary.classes.length-1){let e=this.model_stats_matrix[0].map((e=>""));this.model_stats_matrix.push(e)}}return this.summary["predictions"]}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),setTimeout((async()=>{let e=this;new DataTable("#metrics_table_"+e.id,{responsive:!1,footerCallback:function(t,s,a,i,n){var r=this.api();$(r.column(2).footer()).html("AIC : "+e.summary.aic.toFixed(2)),$(r.column(5).footer()).html("AIC : "+e.summary["best_fit_min"].aic.toFixed(2)),$(r.column(8).footer()).html("AIC : "+e.summary["best_fit_1se"].aic.toFixed(2))},data:e.model_stats_matrix,info:!1,search:!1,ordering:!1,searching:!1,paging:!1,bDestroy:!0}),await M().newPlot("regularization_"+e.id,e.summary.regularization_plot,{autosize:!0});let t=this.summary.confidence_intervals_row_names.map(((e,t)=>e+"_"+this.summary.confidence_intervals[t][0])).reverse(),s=this.summary.confidence_intervals.reverse(),a=[],i=t.map(((e,t)=>t));a.push({name:"OLS",x:s.map((e=>e[1])),y:i,error_x:{type:"data",array:s.map((e=>Math.abs(e[3]-e[1])))},type:"scatter",mode:"markers",showlegend:!0});let n=this.summary.best_fit_min.names.map(((e,t)=>e+"_"+this.summary.best_fit_min.confidence_intervals[t][0])).reverse(),r=this.summary.best_fit_min.confidence_intervals.reverse(),o=n.map(((e,t)=>t+.2));a.push({name:"lasso min",x:r.map((e=>e[1])),y:o,error_x:{type:"data",array:r.map((e=>Math.abs(e[3]-e[1])))},type:"scatter",mode:"markers",showlegend:!0});let l=n.map(((e,t)=>t+.4)),c=this.summary.best_fit_1se.names.map(((e,t)=>e+"_"+this.summary.best_fit_1se.confidence_intervals[t][0])).reverse(),d=this.summary.best_fit_1se.confidence_intervals.reverse();a.push({name:"lasso 1se",x:d.map((e=>e[1])),y:l,error_x:{type:"data",array:d.map((e=>Math.abs(e[3]-e[1])))},type:"scatter",mode:"markers",showlegend:!0}),await M().newPlot("parameters_plot_"+e.id,{data:a,layout:{margin:{l:80,r:40,b:40,t:40,pad:10},showlegend:!0,legend:{xanchor:"left",yanchor:"top",x:.02,y:.98,font:{size:8,color:"black"},bgcolor:"rgba(0,0,0,0)"},xaxis:{linecolor:"black",linewidth:1,zeroline:!0,mirror:!0,title:"Confidence interval"},yaxis:{linecolor:"black",linewidth:1,zeroline:!1,mirror:!0,tickvals:o,ticktext:c,tickfont:{size:10}}}}),this.summary.fit.sort(((e,t)=>e.lambda-t.lambda));let m=this.summary.fit.filter((e=>"1"==e.class)),p=new Set(...[m.filter((e=>!!e.predictor)).map((e=>e.predictor))]),u=[],h=[];p.forEach((e=>{let t=m.filter((t=>t.predictor==e)).map((e=>e.coefficient)),s=m.filter((t=>t.predictor==e)).map((e=>Math.log(e.lambda)));u.push({name:e,y:t,x:s,mode:"lines"}),h.push({xref:"paper",x:.01,y:t[0],xanchor:"left",yanchor:"middle",text:e,font:{family:"Arial",size:8,color:"black"},showarrow:!1}),h=h.concat([{x:this.summary.lambda_min,y:.5,xref:"x",yref:"paper",text:"Lambda min",showarrow:!1,font:{size:8,color:"black"},textangle:-90,align:"center"},{x:this.summary.lambda_1se,y:.5,xref:"x",yref:"paper",text:"Lambda 1se",showarrow:!1,font:{size:8,color:"black"},textangle:-90,align:"center"}])})),await M().newPlot("errors_"+e.id,{data:u,layout:{shapes:[{type:"line",x0:this.summary.lambda_min,x1:this.summary.lambda_min,y0:0,y1:1,xref:"x",yref:"paper",line:{color:"black",dash:"dashdot",width:1}},{type:"line",x0:this.summary.lambda_1se,x1:this.summary.lambda_1se,y0:0,y1:1,xref:"x",yref:"paper",line:{color:"black",dash:"dashdot",width:1}}],annotations:h,showlegend:!1,margin:{l:40,r:40,b:40,t:40,pad:10},autosize:!0,xaxis:{linecolor:"black",linewidth:1,zeroline:!1,mirror:!0,title:"log lambda"},yaxis:{linecolor:"black",linewidth:1,zeroline:!1,mirror:!0,title:"coefficient"}}}),window.dispatchEvent(new Event("resize"))}),500)}}class ie{constructor(){this.chartController=new ee,this.ui=new te(null,null),this.task=null,this.predictions=[],this.id=null,this.plots=[],this.tables=[],this.helpSectionId="help",this.hasExplaination=!0,this.seed=123}async train(e,t,s,a){throw new Error("Not implemented",e,t,s,a)}async evaluateModel(e,t){return{mse:j(e,t),rsquared:X(e,t)}}async visualize(e,t,s,a){let i=this;return new Promise((s=>{setTimeout((()=>{let n=t,r=[];a.forEach(((e,t)=>{r.push(n[t]-e)})),i.ui.yhat_plot(n,a,"regression_y_yhat_"+i.id,"Predictions"),i.ui.residual_plot(a,r,"errors_"+i.id,"Residuals"),this.ui.predictions_table_regression(e,t,a,this.id),this.plots.push("regression_y_yhat_"+i.id),this.plots.push("errors_"+i.id),this.tables.push("#predictions_table_"+this.id),s("resolved")}),500)}))}}class ne extends ie{constructor(e){super(),this.options=e,this.model=null,this.summary=null,this.model_stats_matrix=null,this.hasExplaination=!1}async train(e,t,s,a,i,n){this.context={X_train:e,y_train:t,y_test:a,X_test:s,regularization_type:"Lasso"===this.options.regularization.value?1:0,labels:i};const r=window.webr;await r.init(),await r.installPackages(["jsonlite","iml","ggplot2","plotly","tidyr","dplyr","ggrepel","glmnet","modelsummary"],{quiet:!0}),await r.objs.globalEnv.bind("xx",e),await r.objs.globalEnv.bind("x_test",s),await r.objs.globalEnv.bind("random_seed",this.seed),await r.objs.globalEnv.bind("y",t),await r.objs.globalEnv.bind("names",i),await r.objs.globalEnv.bind("categorical_columns",0===n?.length?["empty"]:n),await r.objs.globalEnv.bind("is_lasso",this.context.regularization_type);const o=await r.evalR('\n                    library(plotly)\n                    library(ggplot2)\n                    library(tidyr)\n                    library(iml)\n                    library(dplyr)\n                    library(ggrepel)\n                    library(modelsummary)\n                    library(glmnet)\n                    set.seed(random_seed)\n\n                    # Select all columns except the first as predictors. \n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n                    scale_df <- as.data.frame(x)\n\n                    cols_to_scale <- setdiff(names, categorical_columns)\n                    scale_df[cols_to_scale] <- scale(scale_df[cols_to_scale])\n                    scaled_y <- scale(y)\n                    base_model = cv.glmnet(as.matrix(scale_df), scaled_y)\n                    weights <- 1 / abs(coef(base_model)[-1])\n                    if(is_lasso){\n                        cvfit = cv.glmnet(as.matrix(scale_df), scaled_y, alpha = 1,penalty.factor = weights)\n                    }else{\n                       cvfit = cv.glmnet(as.matrix(scale_df), scaled_y, alpha = 0)\n                    }\n                    betas = as.matrix(cvfit$glmnet.fit$beta)\n                    lambdas = cvfit$lambda\n                    names(lambdas) = colnames(betas)\n                    \n                    \n                    p <- as.data.frame(betas) %>% \n                      tibble::rownames_to_column("variable") %>% \n                      pivot_longer(-variable) %>% \n                      mutate(lambda=lambdas[name]) %>% \n                    ggplot(aes(x=lambda,y=value,col=variable)) + \n                      geom_line() + \n                      geom_label_repel(data=~subset(.x,lambda==min(lambda)),\n                                       aes(label=variable),nudge_x=-0.5) +\n                      geom_vline(xintercept=c(cvfit$lambda.1se,cvfit$lambda.min),\n                                linetype="dashed")+\n                      scale_x_log10()+ labs(y = "Coefficients") + theme_bw()\n                    df = with(cvfit,\n                            data.frame(lambda = lambdas,MSE = cvm,MSEhi=cvup,MSElow=cvlo))\n\n                    p2<-ggplot(df,aes(x=lambda,y=MSE)) + \n                    geom_point(col="#f05454") + \n                    scale_x_log10("lambda") + \n                    geom_errorbar(aes(ymin = MSElow,ymax=MSEhi),col="#30475e") + \n                    geom_vline(xintercept=c(cvfit$lambda.1se,cvfit$lambda.min),\n                                linetype="dashed")+\n                    theme_bw()\n\n                    # Get lambda.min and lambda.1se\n                    lambda_min = cvfit$lambda.min\n                    lambda_1se = cvfit$lambda.1se\n\n                    # Get the coefficients at lambda.min and lambda.1se\n                    coef_lambda_min = coef(cvfit, s = "lambda.min")\n                    coef_lambda_1se = coef(cvfit, s = "lambda.1se")\n\n                    # Convert the sparse matrix to a regular matrix to make indexing easier\n                    coef_lambda_min_matrix = as.matrix(coef_lambda_min)\n                    coef_lambda_1se_matrix = as.matrix(coef_lambda_1se)\n                    coef_lambda_min_matrix = coef_lambda_min_matrix[-1, , drop = FALSE]\n                    coef_lambda_1se_matrix = coef_lambda_1se_matrix[-1, , drop = FALSE]\n                    # Find the non-zero features at lambda.min and lambda.1se\n                    non_zero_features_min = rownames(coef_lambda_min_matrix)[coef_lambda_min_matrix != 0]\n                    non_zero_features_1se = rownames(coef_lambda_1se_matrix)[coef_lambda_1se_matrix != 0]\n\n                    print(non_zero_features_min)\n                    print(non_zero_features_1se)\n\n                    model <- lm(y ~ ., data = as.data.frame(x))\n                    x <- as.matrix(x_test)  \n                    colnames(x) <- names\n                    predictions <- predict(model, newdata = as.data.frame(x))\n                    # Get coefficients, p-values, and standard errors\n                    coefs <- coef(model)\n                    pvals <- summary(model)$coefficients[,4]\n                    std_error <- summary(model)$coefficients[,2]\n                    aic_value <- AIC(model)\n                    bic_value <- BIC(model)\n                    rsquared <- summary(model)$r.squared\n                    residuals_ols <- resid(model)\n                    fitted_values_ols <- fitted(model)\n\n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n                    X_reduced <- x[, non_zero_features_min]\n                    linear_model_min_features <- non_zero_features_min\n\n                    # Fit a linear regression model using the non-zero features\n                    linear_model_min <- lm(y ~ ., data = as.data.frame(X_reduced))\n                    coefs_min <- coef(linear_model_min)\n                    pvals_min <- summary(linear_model_min)$coefficients[,4]\n                    std_error_min <- summary(linear_model_min)$coefficients[,2]\n                    aic_min <- AIC(linear_model_min)\n                    rsquared_min <- summary(linear_model_min)$r.squared\n                    best_lambda <- cvfit$lambda.1se\n                    best_model <- glmnet(x, y, alpha =is_lasso, lambda = best_lambda)\n                    coefficients <- as.matrix(coef(best_model))\n                    residuals_min <- resid(linear_model_min)\n                    fitted_values_min <- fitted(linear_model_min)\n\n\n                    x <- as.matrix(x_test)  \n                    colnames(x) <- names\n                    x <- x[, non_zero_features_min]\n                    predictions_min <- predict(linear_model_min, newdata = as.data.frame(x))\n\n\n\n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n\n                    X_reduced <- x[, non_zero_features_1se]\n                    linear_model_1se_features <- non_zero_features_1se\n                    linear_model_1se <- lm(y ~ ., data = as.data.frame(X_reduced))\n                    coefs_1se <- coef(linear_model_1se)\n                    print(coefs_1se)\n                    pvals_1se <- summary(linear_model_1se)$coefficients[,4]\n                    aic_1se<- AIC(linear_model_1se)\n                    rsquared_1se <- summary(linear_model_1se)$r.squared\n                    std_error_1se <- summary(linear_model_1se)$coefficients[,2]\n                    residuals_1se <- resid(linear_model_1se)\n                    fitted_values_1se <- fitted(linear_model_1se)\n                    \n                    x <- as.matrix(x_test)  \n                    colnames(x) <- names\n                    x <- x[, non_zero_features_1se]\n                    predictions_1se <- predict(linear_model_1se, newdata = as.data.frame(x))\n\n\n                    models <- list(\n                        "OLS" = model,\n                        "Lasso Min " = linear_model_min,\n                        "Lasso 1se " = linear_model_1se\n                        )\n                    z <- modelplot(models =models,coef_omit = \'Interc\')\n                    qqplot_ols <-ggplot(data.frame(residuals = residuals_ols), aes(sample = residuals_ols)) +\n                        stat_qq() +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    qqplot_1se <-ggplot(data.frame(residuals = residuals_1se), aes(sample = residuals_1se)) +\n                        stat_qq() +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    qqplot_min <-ggplot(data.frame(residuals = residuals_min), aes(sample = residuals_min)) +\n                        stat_qq() +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                        \n\n\n\n                    list(plotly_json(p, pretty = FALSE),plotly_json(p2, pretty = FALSE),coefs,\n                    pvals,std_error,predictions,aic_value,bic_value,rsquared\n                    ,coefs_min,pvals_min,std_error_min\n                    ,coefs_1se,pvals_1se,std_error_1se,plotly_json(z, pretty = FALSE),linear_model_min_features,linear_model_1se_features\n                    ,residuals_ols,residuals_1se,residuals_min,predictions_1se,predictions_min,rsquared_1se,aic_1se,rsquared_min,aic_min\n                    ,plotly_json(qqplot_ols, pretty = FALSE)\n                    ,plotly_json(qqplot_1se, pretty = FALSE)\n                    ,plotly_json(qqplot_min, pretty = FALSE)\n                    \n                    )\n                    ');let l=await o.toArray();this.summary={params:await l[2].toArray(),bse:await l[4].toArray(),pvalues:await l[3].toArray(),predictions:await l[5].toArray(),predictions1se:await l[21].toArray(),predictionsmin:await l[22].toArray(),residuals_ols:await l[18].toArray(),residuals_1se:await l[19].toArray(),residuals_min:await l[20].toArray(),aic:await l[6].toNumber(),bic:await l[7].toNumber(),r2:await l[8].toNumber(),best_fit_min:{r2:await l[25].toNumber(),aic:await l[26].toNumber(),names:await l[16].toArray(),coefs:await l[9].toArray(),bse:await l[11].toArray(),pvalues:await l[10].toArray()},best_fit_1se:{r2:await l[23].toNumber(),aic:await l[24].toNumber(),names:await l[17].toArray(),coefs:await l[12].toArray(),bse:await l[14].toArray(),pvalues:await l[13].toArray()}},this.model_stats_matrix=[];let c=[...i];c.unshift("intercept");let d=this.summary["best_fit_min"].names;d.unshift("intercept");let m=this.summary["best_fit_1se"].names;m.unshift("intercept");for(let h=0;h<c.length;h++){let e=[];e.push(c[h]),e.push(this.summary["params"][h]?.toFixed(2)??" "),e.push(this.summary["bse"][h]?.toFixed(2)??" "),e.push(this.summary["pvalues"][h]?.toFixed(2)??" ");let t=d.findIndex((e=>e===c[h]));-1!==t?(e.push(this.summary["best_fit_min"]["coefs"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_min"]["bse"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_min"]["pvalues"][t]?.toFixed(2)??" ")):(e.push(" "),e.push(" "),e.push(" ")),t=m.findIndex((e=>e===c[h])),-1!==t?(e.push(this.summary["best_fit_1se"]["coefs"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_1se"]["bse"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_1se"]["pvalues"][t]?.toFixed(2)??" ")):(e.push(" "),e.push(" "),e.push(" ")),this.model_stats_matrix.push(e)}this.model_stats_matrix.reverse();let p=JSON.parse(await l[0].toString());p.layout["showlegend"]=!1,p.layout.legend={font:{size:8,color:"#000"}};let u=JSON.parse(await l[15].toString());return u.layout.legend={x:0,y:1,traceorder:"normal",font:{size:8,color:"#000"},bgcolor:"rgba(0,0,0,0)"},u.layout.xaxis.title.font={size:10},u.layout.xaxis.linecolor="rgba(235, 235, 235, 1)",u.layout.xaxis.linewidth=2,u.layout.xaxis.mirror=!0,u.layout.xaxis.zeroline=!0,u.layout.yaxis.linecolor="rgba(235, 235, 235, 1)",u.layout.yaxis.linewidth=2,u.layout.yaxis.mirror=!0,u.layout.yaxis.zeroline=!0,this.summary.coefs_plot=u,this.summary.regularization_plot=p,this.summary.errors_plot=JSON.parse(await l[1].toString()),this.summary.qqplot_ols_plot=JSON.parse(await l[27].toString()),this.summary.qqplot_1se_plot=JSON.parse(await l[28].toString()),this.summary.qqplot_min_plot=JSON.parse(await l[29].toString()),this.summary.qqplot_ols_plot.layout.title.font={size:10},this.summary.qqplot_ols_plot.data[0].marker.size=2,this.summary.qqplot_ols_plot.layout.height=300,this.summary.qqplot_ols_plot.layout.width=300,this.summary.qqplot_ols_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_ols_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_1se_plot.layout.height=300,this.summary.qqplot_1se_plot.layout.width=300,this.summary.qqplot_1se_plot.layout.title.font={size:10},this.summary.qqplot_1se_plot.data[0].marker.size=2,this.summary.qqplot_1se_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_1se_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_min_plot.layout.height=300,this.summary.qqplot_min_plot.layout.width=300,this.summary.qqplot_min_plot.layout.title.font={size:10},this.summary.qqplot_min_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_min_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_min_plot.data[0].marker.size=2,this.summary["predictions"]}async visualize(e,t,s,a,i){await super.visualize(e,t,s,a);let n=this;new DataTable("#metrics_table_"+n.id,{responsive:!1,footerCallback:function(e,t,s,a,i){var r=this.api();$(r.column(2).footer()).html("R2 : "+n.summary.r2.toFixed(2)+" AIC: "+n.summary.aic.toFixed(2)),$(r.column(5).footer()).html("R2 : "+n.summary["best_fit_min"].r2.toFixed(2)+" AIC: "+n.summary["best_fit_min"].aic.toFixed(2)),$(r.column(8).footer()).html("R2 : "+n.summary["best_fit_1se"].r2.toFixed(2)+" AIC: "+n.summary["best_fit_1se"].aic.toFixed(2))},data:n.model_stats_matrix,info:!1,search:!1,ordering:!1,searching:!1,paging:!1,bDestroy:!0,columnDefs:[{targets:3,createdCell:function(e,t,s,a,i){s[3]<=.05&&($(e).css("color","red"),$(e).css("font-weight","700"))}},{targets:6,createdCell:function(e,t,s,a,i){s[6]<=.05&&($(e).css("color","red"),$(e).css("font-weight","700"))}},{targets:9,createdCell:function(e,t,s,a,i){s[9]<=.05&&($(e).css("color","red"),$(e).css("font-weight","700"))}}]}),await M().newPlot("parameters_plot_"+n.id,n.summary.coefs_plot,{autosize:!0,responsive:!0}),await M().newPlot("regularization_"+n.id,n.summary.regularization_plot,{autosize:!0,responsive:!0}),await M().newPlot("errors_"+n.id,n.summary.errors_plot,{autosize:!0,responsive:!0}),await M().newPlot("qqplot_ols_"+n.id,n.summary.qqplot_ols_plot,{autosize:!0,staticPlot:!0}),await M().newPlot("qqplot_min_"+n.id,n.summary.qqplot_min_plot,{autosize:!0,staticPlot:!0}),await M().newPlot("qqplot_1se_"+n.id,n.summary.qqplot_1se_plot,{autosize:!0,staticPlot:!0}),n.ui.yhat_plot(t,this.summary["predictions"],"regression_y_yhat_"+n.id,"OLS predictions"),n.ui.yhat_plot(t,this.summary["predictionsmin"],"regression_y_yhat_min_"+n.id,"lasso min predictions"),n.ui.yhat_plot(t,this.summary["predictions1se"],"regression_y_yhat_1se_"+n.id,"lasso 1se predictions"),n.ui.residual_plot(t,this.summary["residuals_ols"],"regression_residual_"+n.id,"OLS residuals"),n.ui.residual_plot(t,this.summary["residuals_min"],"regression_residual_min_"+n.id,"lasso min residuals"),n.ui.residual_plot(t,this.summary["residuals_1se"],"regression_residual_1se_"+n.id,"lasso 1se residuals"),this.ui.predictions_table_regression(e,t,a,this.id),window.dispatchEvent(new Event("resize"))}}class re extends ie{constructor(e){super(),this.options=e,this.model=null,this.hasExplaination=!1}async train(e,t,s,a,i){this.context={X_train:e,y_train:t,X_test:s,y_test:a,knots:+this.options.knots.value,explain:this.hasExplaination,degree:+this.options.degree.value,features:[...Array(i.length).keys()]};const n="\n        from sklearn.preprocessing import SplineTransformer\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.ensemble import GradientBoostingRegressor\n        import pandas as pd\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from sklearn import linear_model\n        from sklearn.metrics import mean_squared_error\n        from sklearn.pipeline import make_pipeline\n        from js import X_train,y_train,X_test,knots,degree,y_test,features,explain\n\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        \n        model = make_pipeline(\n            SplineTransformer(n_knots=knots, degree=degree), \n            linear_model.LinearRegression()\n            )\n        model.fit(X_train, y_train)\n        pred_train = model.predict(X_train)\n        rmse_train = mean_squared_error(y_train, pred_train, squared=True)\n        y_pred = model.predict(X_test)\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance\n\n        ";try{const{results:e,error:t}=await N(n,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(r){throw Error(`Error in pyodideWorker at ${r.filename}, Line: ${r.lineno}, ${r.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class oe extends se{constructor(e){super(),this.options={kernel:e.kernel.value.toLowerCase(),coef:e.bias.value,degree:e.degree.value,c:e.c.value,quiet:!0},this.helpSectionId="svm_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,pdpIndex:r,explain:this.hasExplaination,kernel:this.options.kernel,coef:this.options.coef,c:+this.options.c,degree:this.options.degree,seed:this.seed,features:[...Array(i.length).keys()]};const o="\n        from sklearn import svm\n        from js import X_train,y_train,X_test,y_test,kernel,coef,degree,features,seed,c\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n\n        model = svm.SVC(kernel=kernel,random_state = seed,C=c,degree=degree)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids,features_importance\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}generatePythonCode(){let e="from sklearn import svm",t=`\nmodel = model = svm.SVC(kernel="${this.options.kernel}",random_state = ${this.seed})`;return super.generatePythonCode(e,t)}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class le extends ie{constructor(e,t){super(t);let s={kernel:e.kernel.value??"linear",gamma:e.gamma.value,degree:e.degree.value};this.options=s,this.helpSectionId="svm_help"}async train(e,t,s,a,i){this.context={X_train:e,y_train:t,X_test:s,y_test:a,kernel:this.options.kernel,gamma:this.options.gamma,degree:this.options.degree,explain:this.hasExplaination,seed:this.seed,features:[...Array(i.length).keys()]};const n="\n        from sklearn import svm\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from js import X_train,y_train,X_test,y_test,kernel,gamma,degree,seed,features,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n\n        \n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        model = svm.SVR(kernel=kernel)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features)\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance\n    ";try{const{results:e,error:t}=await N(n,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(r){throw Error(`Error in pyodideWorker at ${r.filename}, Line: ${r.lineno}, ${r.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class ce extends se{constructor(e){super(),this.options=e,this.model=null,this.helpSectionId="knn_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,min:+this.options.min.value,max:+this.options.max.value,explain:this.hasExplaination,features:[...Array(i.length).keys()]};const o="\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from js import X_train,y_train,X_test,y_test,features,min,max,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.neighbors import KNeighborsClassifier\n        from sklearn.metrics import accuracy_score\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n\n        k_neighbor_results=[]\n        best_model = None\n        best_accuracy = 0\n        best_preds = []\n        for i,metric in enumerate(['manhattan','euclidean']):\n            for n in range(min,max+1):\n                model = KNeighborsClassifier(n_neighbors=n,metric=metric)\n                model.fit(X_train, y_train)\n                preds = model.predict(X_test)\n                accuracy = accuracy_score(y_test,preds)\n                k_neighbor_results.append([metric,n,accuracy])\n                if accuracy > best_accuracy:\n                    best_accuracy = accuracy\n                    best_model = model\n                    best_n = n\n                    best_preds = preds\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(best_model, X_train, features,target=0,method ='brute')\n            fi = permutation_importance(best_model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        best_preds,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance,k_neighbor_results,best_n\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.k_neighbor_results=Array.from(e[4]),this.best_n=e[5],Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}generatePythonCode(){let e="\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score".trim(),t=`\nbest_model = None\nbest_accuracy = 0\nbest_preds = []\nfor i,metric in enumerate(['manhattan','euclidean']):\n    for n in range(${+this.options.min.value},${+this.options.max.value+1}):\n        model = KNeighborsClassifier(n_neighbors=n,metric=metric)\n        model.fit(X_train, y_train)\n        preds = model.predict(X_test)\n        accuracy = accuracy_score(y_test,preds)\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            best_model = model\n            best_n = n\n            best_preds = preds\nmodel = best_model\n`.trim();return super.generatePythonCode(e,t)}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.chartController.KNNPerformancePlot(this.k_neighbor_results,this.best_n,this.id),this.plots.push("knn_table_"+this.id),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class de extends ie{constructor(e){super(),this.options=e,this.model=null,this.helpSectionId="knn_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,min:+this.options.min.value,max:+this.options.max.value,explain:this.hasExplaination,features:[...Array(i.length).keys()]};const o="\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from js import X_train,y_train,X_test,y_test,features,min,max,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.neighbors import KNeighborsRegressor\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        k_neighbor_results=[]\n        best_model = None\n        best_r2 = 0\n        best_preds = []\n\n        for i,metric in enumerate(['manhattan','euclidean']):\n            for n in range(min,max+1):\n                model = KNeighborsRegressor(n_neighbors=n,metric=metric)\n                model.fit(X_train, y_train)\n                preds = model.predict(X_test)\n                r2 = model.score(X_test,y_test)\n                k_neighbor_results.append([metric,n,r2])\n                if r2 > best_r2:\n                    best_r2 = r2\n                    best_model = model\n                    best_n = n\n                    best_preds = preds\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(best_model, X_train, features)\n            fi = permutation_importance(best_model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        best_preds,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance,k_neighbor_results,best_n\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.k_neighbor_results=Array.from(e[4]),this.best_n=e[5],Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.chartController.KNNPerformancePlot(this.k_neighbor_results,this.best_n,this.id,"MSE"),this.plots.push("knn_table_"+this.id),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class me extends se{constructor(e,t){super(t),this.helpSectionId="cart_help",this.options=e,this.model=null,this.predictions=[],this.hasProbability=!0}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,pdpIndex:r,explain:this.hasExplaination,rf_type:this.options.criteria.value,max_features:this.options.features.value,num_estimators:this.options.estimators.value<=0||!this.options.estimators.value?100:+this.options.estimators.value,max_depth:this.options.depth.value<=0?5:+this.options.depth.value,seed:this.seed,features:[...Array(i.length).keys()],num_classes:[...new Set(t)].length};const o="\n            from sklearn.model_selection import train_test_split\n            from sklearn.ensemble import RandomForestClassifier\n            from sklearn.metrics import accuracy_score\n            import matplotlib\n            matplotlib.use(\"AGG\")\n            from sklearn.inspection import PartialDependenceDisplay\n            from sklearn.inspection import permutation_importance\n            from js import seed,X_train,y_train,X_test,y_test,rf_type,max_features,num_estimators,max_depth, features,explain,num_classes\n            from sklearn.metrics import roc_auc_score\n            from sklearn.metrics import roc_curve\n            from sklearn.preprocessing import LabelBinarizer\n\n\n            features_importance = []\n            partial_dependence_plot_grids = []\n            partial_dependence_plot_avgs = []\n            model = RandomForestClassifier(criterion=rf_type,max_features = max_features,n_estimators=num_estimators,max_depth = max_depth, random_state=seed)\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n            \n            probas = model.predict_proba(X_test)\n            tprs=[]\n            fprs=[]\n            aucs=[]\n            label_binrize = LabelBinarizer().fit(y_train)\n            y_test_one_hot = label_binrize.transform(y_test)\n            \n            try:\n                fpr,tpr,_  = roc_curve(y_test,probas[:,1])\n                fprs.append(fpr)\n                tprs.append(tpr)\n                auc = roc_auc_score(y_test,probas[:,1])\n                aucs.append(auc)\n            except Exception as e:\n                auc = roc_auc_score(y_test,probas,multi_class = 'ovr')\n                aucs.append(auc)\n                for i in range(num_classes):\n                    fpr,tpr,_ = roc_curve(y_test_one_hot[:,i],probas[:,i])\n                    fprs.append(fpr)\n                    tprs.append(tpr)\n\n            if explain:\n                pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n                fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n                partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n                grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n                features_importance = list(fi.importances)\n                partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n            y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids,features_importance,fprs,tprs,aucs,probas\n        ";try{const{results:e,error:t}=await N(o,this.context);if(e)this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.fpr=Array.from(e[4]),this.tpr=Array.from(e[5]),this.auc=Array.from(e[6]),this.probas=Array.from(e[7]);else if(t)throw Error("Faced errot fitting Random Forest")}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}return this.predictions}generatePythonCode(){let e="from sklearn.ensemble import RandomForestClassifier",t=`\nmodel = RandomForestClassifier(criterion="${this.options.criteria.value}",max_features = ${this.options.features.value},n_estimators=${this.options.estimators.value},max_depth = ${this.options.depth.value}, random_state=${this.seed})`;return super.generatePythonCode(e,t)}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r)),this.chartController.plotROC(this.id,this.fpr,this.tpr,s,this.auc),this.chartController.probabilities_boxplot(this.probas,i.inverseTransform(a),s,this.id)}predict(){return this.predictions}}class pe extends ie{constructor(e){super(),this.options=e,this.model=null,this.helpSectionId="cart_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,rf_type:this.options.criteria.value,max_features:this.options.features.value,num_estimators:this.options.estimators.value<=0||!this.options.estimators.value?100:+this.options.estimators.value,max_depth:this.options.depth.value<=0?5:+this.options.depth.value,seed:this.seed,explain:this.hasExplaination,features:[...Array(i.length).keys()]};const o="\n            from sklearn.model_selection import train_test_split\n            from sklearn.ensemble import RandomForestRegressor\n            import matplotlib\n            matplotlib.use(\"AGG\")\n            from sklearn.metrics import accuracy_score\n            from js import X_train,y_train,X_test,y_test,rf_type,max_features,num_estimators,max_depth,seed,features,explain\n            from sklearn.inspection import PartialDependenceDisplay\n            from sklearn.inspection import permutation_importance\n\n            features_importance = []\n            partial_dependence_plot_grids = []\n            partial_dependence_plot_avgs = []\n            model = RandomForestRegressor(criterion=rf_type,max_features = max_features,n_estimators=num_estimators,max_depth = max_depth, random_state=seed)\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n\n            if explain:\n                pdp = PartialDependenceDisplay.from_estimator(model, X_train, features)\n                fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n                partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n                grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n                features_importance = list(fi.importances)\n                partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n            y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance           \n        ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}predict(e){const t=this.model.predict(e);return t}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class ue extends se{constructor(e){super(),this.options=e,this.model=null,this.helpSectionId="naive_bayes_help",this.hasProbability=!0}async train(e,t,s,a,i,n,r){this.context={nb_type:"Multinomial"===this.options.type.value?0:"Gaussian"===this.options.type.value?1:2,priors:this.options.priors.value,smoothing:+this.options.laplace.value,num_classes:[...new Set(t)].length,X_train:e,y_train:t,y_test:a,explain:this.hasExplaination,X_test:s,pdpIndex:r,features:[...Array(i.length).keys()]};const o="\n            from sklearn.naive_bayes import BernoulliNB\n            from sklearn.naive_bayes import MultinomialNB\n            import matplotlib\n            matplotlib.use(\"AGG\")\n            from js import X_train,y_train,X_test,nb_type,priors,smoothing,y_test,num_classes,features,explain\n            from sklearn.naive_bayes import GaussianNB\n            from sklearn.inspection import PartialDependenceDisplay\n            from sklearn.inspection import permutation_importance\n            from sklearn.metrics import roc_auc_score\n            from sklearn.metrics import roc_curve\n            from sklearn.preprocessing import LabelBinarizer\n\n            features_importance = []\n            partial_dependence_plot_grids = []\n            partial_dependence_plot_avgs = []\n            if priors is not None and priors.strip():\n                priors = [float(x) for x in priors.split(',')]\n            else:\n                priors = None\n            print(\"priors\",priors)\n            if nb_type == 0:\n                model = MultinomialNB(class_prior=priors , alpha = smoothing)\n            if nb_type == 1:\n                model = GaussianNB(priors=priors)\n            else:\n                model = BernoulliNB(class_prior=priors , alpha = smoothing)\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n            probas = model.predict_proba(X_test)\n            tprs=[]\n            fprs=[]\n            aucs = []\n\n            label_binrize = LabelBinarizer().fit(y_train)\n            y_test_one_hot = label_binrize.transform(y_test)\n            \n            try:\n                fpr,tpr,_  = roc_curve(y_test,probas[:,1])\n                auc = roc_auc_score(y_test,probas[:,1])\n                aucs.append(auc)\n                fprs.append(fpr)\n                tprs.append(tpr)\n\n            except Exception as e:\n                print(e)\n                auc = roc_auc_score(y_test,probas,multi_class = 'ovr')\n                aucs.append(auc)\n                for i in range(num_classes):\n                    fpr,tpr,_ = roc_curve(y_test_one_hot[:,i],probas[:,i])\n                    fprs.append(fpr)\n                    tprs.append(tpr)\n\n            if explain:\n                pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n                fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n                partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n                grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n                features_importance = list(fi.importances)\n                partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n            y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance,fprs,tprs,aucs,probas\n        ";try{const{results:e,error:t}=await N(o,this.context);e?(this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.fpr=Array.from(e[4]),this.tpr=Array.from(e[5]),this.auc=Array.from(e[6]),this.probas=Array.from(e[7])):t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}return this.predictions}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r)),this.chartController.plotROC(this.id,this.fpr,this.tpr,s,this.auc),this.chartController.probabilities_boxplot(this.probas,i.inverseTransform(a),s,this.id)}}class he extends se{constructor(e){super(),this.options=e,this.hasProbability=!0,this.helpSectionId="discriminant_analysis_help"}async train(e,t,s,a,i,n,r){this.context={lda_type:this.options.type.value,priors:this.options.priors.value,X_train:e,y_train:t,X_test:s,y_test:a,pdpIndex:r,explain:this.hasExplaination,features:[...Array(i.length).keys()],num_classes:[...new Set(t)].length};const o="\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n        from js import X_train,y_train,X_test,lda_type,priors,y_test,features,explain,num_classes\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.metrics import roc_auc_score\n        from sklearn.metrics import roc_curve\n        from sklearn.preprocessing import LabelBinarizer\n\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        if priors is not None and priors.strip():\n            priors = [float(x) for x in priors.split(',')]\n        else:\n            priors = None\n        print(\"priors\",priors)\n        if lda_type == 0:\n            model = LinearDiscriminantAnalysis(priors=priors)\n        else:\n            model = QuadraticDiscriminantAnalysis(priors=priors)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        probas = model.predict_proba(X_test)\n        tprs=[]\n        fprs=[]\n        aucs = []\n        label_binrize = LabelBinarizer().fit(y_train)\n        y_test_one_hot = label_binrize.transform(y_test)\n        \n        try:\n            fpr,tpr,_  = roc_curve(y_test,probas[:,1])\n            auc = roc_auc_score(y_test,probas[:,1])\n            aucs.append(auc)\n            fprs.append(fpr)\n            tprs.append(tpr)\n\n        except Exception as e:\n            print(e)\n            auc = roc_auc_score(y_test,probas,multi_class = 'ovr')\n            aucs.append(auc)\n            for i in range(num_classes):\n                fpr,tpr,_ = roc_curve(y_test_one_hot[:,i],probas[:,i])\n                fprs.append(fpr)\n                tprs.append(tpr)\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance,fprs,tprs,aucs,probas\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.fpr=Array.from(e[4]),this.tpr=Array.from(e[5]),this.auc=Array.from(e[6]),this.probas=Array.from(e[7]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r)),this.chartController.plotROC(this.id,this.fpr,this.tpr,s,this.auc),this.chartController.probabilities_boxplot(this.probas,i.inverseTransform(a),s,this.id)}}class _e extends ie{constructor(e){super(),this.options=e,this.model=null,this.hasExplaination=!1,this.summary=null,this.model_stats_matrix=null}async train(e,t,s,a,i,n){let r="Lasso"===this.options?.regularization?.value?1:0,o=+this.options?.degree?.value;const l=window.webr;await l.init(),await l.installPackages(["jsonlite","ggplot2","plotly","tidyr","broom","dplyr","ggrepel","glmnet","modelsummary"],{quiet:!0}),await l.objs.globalEnv.bind("xx",e),await l.objs.globalEnv.bind("x_test",s),await l.objs.globalEnv.bind("random_seed",this.seed),await l.objs.globalEnv.bind("y",t),await l.objs.globalEnv.bind("degree",o),await l.objs.globalEnv.bind("names",i),await l.objs.globalEnv.bind("categorical_columns",0===n?.length?["empty"]:n),await l.objs.globalEnv.bind("is_lasso",r);const c=await l.evalR('\n                    library(plotly)\n                    library(ggplot2)\n                    library(tidyr)\n                    library(dplyr)\n                    library(broom)\n\n                    library(ggrepel)\n                    library(modelsummary)\n                    library(glmnet)\n                    set.seed(random_seed)\n\n                    # Select all columns except the first as predictors. \n                    add_powers <- function(df, degree,columns) {\n                            new_df <- df  # Copy the original data frame\n                            for (col in columns) {\n                                for (d in 2:degree){\n                                    new_col_name <- paste0(col, "_", d)\n                                    new_df[[new_col_name]] <- df[[col]]^d\n                                }\n                            }\n                            return(new_df)\n                        }\n                        \n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n                    cols_numerical <- setdiff(names, categorical_columns)\n                    df_main <- add_powers(as.data.frame(x), degree,cols_numerical)\n                    scale_df <- add_powers(as.data.frame(x), degree,cols_numerical)\n                    all_column_names <- colnames(scale_df)\n                    cols_to_scale <- setdiff(all_column_names, categorical_columns)\n                    scale_df[cols_to_scale] <- scale(scale_df[cols_to_scale])\n                    \n                    x <- as.matrix(x_test)  \n                    colnames(x) <- names\n                    df_test <- add_powers(as.data.frame(x), degree,cols_numerical)\n                    base_model = cv.glmnet(as.matrix(scale_df), y)\n                    weights <- 1 / abs(coef(base_model)[-1])\n\n                    if(is_lasso){\n                        cvfit = cv.glmnet(as.matrix(scale_df), y, alpha = 1)\n                    }else{\n                       cvfit = cv.glmnet(as.matrix(scale_df), y, alpha = 0)\n                    }\n                    betas = as.matrix(cvfit$glmnet.fit$beta)\n                    lambdas = cvfit$lambda\n                    names(lambdas) = colnames(betas)\n                    \n                    p <- as.data.frame(betas) %>% \n                      tibble::rownames_to_column("variable") %>% \n                      pivot_longer(-variable) %>% \n                      mutate(lambda=lambdas[name]) %>% \n                      mutate(variable = factor(variable, levels = sort(unique(variable)))) %>%\n\n                    ggplot(aes(x=lambda,y=value,col=variable)) + \n                      geom_line() + \n                      geom_label_repel(data=~subset(.x,lambda==min(lambda)),\n                                       aes(label=variable),nudge_x=-0.5) +\n                      geom_vline(xintercept=c(cvfit$lambda.1se,cvfit$lambda.min),\n                                linetype="dashed")+\n                      scale_x_log10() +\n                      labs(y = "Coefficient") +\n                    theme_bw()\n                    \n                    df = with(cvfit,\n                            data.frame(lambda = lambdas,MSE = cvm,MSEhi=cvup,MSElow=cvlo))\n\n                    p2<-ggplot(df,aes(x=lambda,y=MSE)) + \n                    geom_point(col="#f05454") + \n                    scale_x_log10("lambda") + \n                    geom_errorbar(aes(ymin = MSElow,ymax=MSEhi),col="#30475e") + \n                    geom_vline(xintercept=c(cvfit$lambda.1se,cvfit$lambda.min),\n                                linetype="dashed")+\n                    theme_bw()\n\n                     # Get lambda.min and lambda.1se\n                    lambda_min = cvfit$lambda.min\n                    lambda_1se = cvfit$lambda.1se\n\n                    # Get the coefficients at lambda.min and lambda.1se\n                    coef_lambda_min = coef(cvfit, s = "lambda.min")\n                    coef_lambda_1se = coef(cvfit, s = "lambda.1se")\n\n                    # Convert the sparse matrix to a regular matrix to make indexing easier\n                    coef_lambda_min_matrix = as.matrix(coef_lambda_min)\n                    coef_lambda_1se_matrix = as.matrix(coef_lambda_1se)\n                    coef_lambda_min_matrix = coef_lambda_min_matrix[-1, , drop = FALSE]\n                    coef_lambda_1se_matrix = coef_lambda_1se_matrix[-1, , drop = FALSE]\n                    # Find the non-zero features at lambda.min and lambda.1se\n                    non_zero_features_min = rownames(coef_lambda_min_matrix)[coef_lambda_min_matrix != 0]\n                    non_zero_features_1se = rownames(coef_lambda_1se_matrix)[coef_lambda_1se_matrix != 0]\n                    print(non_zero_features_min)\n                    print(non_zero_features_1se)\n                    x <- as.matrix(df_main)\n                    colnames(x) <- all_column_names\n\n                    model <- lm(y ~ ., data = as.data.frame(x))\n\n                    x <- as.matrix(df_test)  \n                    colnames(x) <- all_column_names\n\n                    predictions <- predict(model, newdata = as.data.frame(x))\n                    # Get coefficients, p-values, and standard errors\n                    coefs <- coef(model)\n                    pvals <- summary(model)$coefficients[,4]\n                    std_error <- summary(model)$coefficients[,2]\n                    aic_value <- AIC(model)\n                    bic_value <- BIC(model)\n                    rsquared <- summary(model)$r.squared\n                    residuals_ols <- resid(model)\n                    fitted_values_ols <- fitted(model)\n\n                    x <- as.matrix(df_main)  \n                    colnames(x) <- all_column_names\n                    X_reduced <- x[, non_zero_features_min]\n                    linear_model_min_features <- non_zero_features_min\n                    # Fit a linear regression model using the non-zero features\n                    print(colnames(X_reduced))\n                    linear_model_min <- lm(y ~ ., data = as.data.frame(X_reduced))\n                    coefs_min <- coef(linear_model_min)\n                    pvals_min <- summary(linear_model_min)$coefficients[,4]\n                    std_error_min <- summary(linear_model_min)$coefficients[,2]\n                    aic_min <- AIC(linear_model_min)\n                    rsquared_min <- summary(linear_model_min)$r.squared\n                    best_lambda <- cvfit$lambda.1se\n                    best_model <- glmnet(x, y, alpha =is_lasso, lambda = best_lambda)\n                    coefficients <- as.matrix(coef(best_model))\n                    residuals_min <- resid(linear_model_min)\n                    fitted_values_min <- fitted(linear_model_min)\n                    x <- as.matrix(df_test)  \n                    colnames(x) <- all_column_names\n                    predictions_min <- predict(linear_model_min, newdata = as.data.frame(x))\n\n\n\n\n\n                    x <- as.matrix(df_main)  \n                    colnames(x) <- all_column_names\n                    \n                    X_reduced <- x[, non_zero_features_1se]\n                    linear_model_1se_features <- non_zero_features_1se\n                    print(colnames(X_reduced))\n                    linear_model_1se <- lm(y ~ ., data = as.data.frame(X_reduced))\n                    coefs_1se <- coef(linear_model_1se)\n                    print(coefs_1se)\n                    pvals_1se <- summary(linear_model_1se)$coefficients[,4]\n                    aic_1se<- AIC(linear_model_1se)\n                    rsquared_1se <- summary(linear_model_1se)$r.squared\n                    std_error_1se <- summary(linear_model_1se)$coefficients[,2]\n                    residuals_1se <- resid(linear_model_1se)\n                    fitted_values_1se <- fitted(linear_model_1se)\n                    x <- as.matrix(df_test) \n                    colnames(x) <- all_column_names \n                    x <- x[, linear_model_1se_features]\n                    predictions_1se <- predict(linear_model_1se, newdata = as.data.frame(x))\n                    models <- list(\n                        "OLS" = model,\n                        "Lasso Min " = linear_model_min,\n                        "Lasso 1se " = linear_model_1se\n                        )\n\n                    z <- modelplot(models =models,coef_omit = \'Interc\')\n                    qqplot_ols <-ggplot(data.frame(residuals = residuals_ols), aes(sample = residuals_ols)) +\n                        stat_qq() +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    qqplot_1se <-ggplot(data.frame(residuals = residuals_1se), aes(sample = residuals_1se)) +\n                        stat_qq() +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    qqplot_min <-ggplot(data.frame(residuals = residuals_min), aes(sample = residuals_min)) +\n                        stat_qq() +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    list(plotly_json(p, pretty = FALSE),plotly_json(p2, pretty = FALSE),coefs,\n                    pvals,std_error,predictions,aic_value,bic_value,rsquared\n                    ,coefs_min,pvals_min,std_error_min\n                    ,coefs_1se,pvals_1se,std_error_1se,plotly_json(z, pretty = FALSE),linear_model_min_features,linear_model_1se_features\n                    ,residuals_ols,residuals_1se,residuals_min,predictions_1se,predictions_min,rsquared_1se,aic_1se,rsquared_min,aic_min\n                    ,plotly_json(qqplot_ols, pretty = FALSE)\n                    ,plotly_json(qqplot_1se, pretty = FALSE)\n                    ,plotly_json(qqplot_min, pretty = FALSE)\n                    ,all_column_names\n                    )\n                    ');let d=await c.toArray();this.summary={params:await d[2].toArray(),bse:await d[4].toArray(),pvalues:await d[3].toArray(),predictions:await d[5].toArray(),predictions1se:await d[21].toArray(),predictionsmin:await d[22].toArray(),residuals_ols:await d[18].toArray(),residuals_1se:await d[19].toArray(),residuals_min:await d[20].toArray(),aic:await d[6].toNumber(),bic:await d[7].toNumber(),r2:await d[8].toNumber(),best_fit_min:{r2:await d[25].toNumber(),aic:await d[26].toNumber(),names:await d[16].toArray(),coefs:await d[9].toArray(),bse:await d[11].toArray(),pvalues:await d[10].toArray()},best_fit_1se:{r2:await d[23].toNumber(),aic:await d[24].toNumber(),names:await d[17].toArray(),coefs:await d[12].toArray(),bse:await d[14].toArray(),pvalues:await d[13].toArray()},columnNames:await d[30].toArray()},this.model_stats_matrix=[];let m=this.summary.columnNames;m.unshift("intercept");let p=this.summary["best_fit_min"].names;p.unshift("intercept");let u=this.summary["best_fit_1se"].names;u.unshift("intercept");for(let f=0;f<m.length;f++){let e=[];e.push(m[f]),e.push(this.summary["params"][f]?.toFixed(2)??" "),e.push(this.summary["bse"][f]?.toFixed(2)??" "),e.push(this.summary["pvalues"][f]?.toFixed(2)??" ");let t=p.findIndex((e=>e===m[f]));-1!==t?(e.push(this.summary["best_fit_min"]["coefs"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_min"]["bse"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_min"]["pvalues"][t]?.toFixed(2)??" ")):(e.push(" "),e.push(" "),e.push(" ")),t=u.findIndex((e=>e===m[f])),-1!==t?(e.push(this.summary["best_fit_1se"]["coefs"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_1se"]["bse"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_1se"]["pvalues"][t]?.toFixed(2)??" ")):(e.push(" "),e.push(" "),e.push(" ")),this.model_stats_matrix.push(e)}this.model_stats_matrix=this.model_stats_matrix.sort((function(e,t){return e[0]>t[0]?1:e[0]<t[0]?-1:0})),this.model_stats_matrix.reverse();let h=JSON.parse(await d[0].toString());h.layout["showlegend"]=!0,h.layout["autosize"]=!0,h.layout["responsive"]=!0,h.layout.xaxis["side"]="top",h.layout.legend={orientation:"h",font:{size:8,color:"#000"}};let _=JSON.parse(await d[15].toString());return _.layout.legend={x:0,y:1,traceorder:"normal",font:{size:8,color:"#000"}},this.summary.coefs_plot=_,this.summary.coefs_plot.layout["autosize"]=!0,this.summary.coefs_plot.layout["responsive"]=!0,this.summary.coefs_plot.layout.xaxis.title.font={size:10},this.summary.regularization_plot=h,this.summary.errors_plot=JSON.parse(await d[1].toString()),this.summary.qqplot_ols_plot=JSON.parse(await d[27].toString()),this.summary.qqplot_1se_plot=JSON.parse(await d[28].toString()),this.summary.qqplot_min_plot=JSON.parse(await d[29].toString()),this.summary.qqplot_ols_plot.layout.height=300,this.summary.qqplot_ols_plot.layout.width=300,this.summary.qqplot_ols_plot.layout.title.font={size:10},this.summary.qqplot_ols_plot.data[0].marker.size=2,this.summary.qqplot_ols_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_ols_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_1se_plot.layout.height=300,this.summary.qqplot_1se_plot.layout.width=300,this.summary.qqplot_1se_plot.layout.title.font={size:10},this.summary.qqplot_1se_plot.data[0].marker.size=2,this.summary.qqplot_1se_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_1se_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_min_plot.layout.height=300,this.summary.qqplot_min_plot.layout.width=300,this.summary.qqplot_min_plot.layout.title.font={size:10},this.summary.qqplot_min_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_min_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_min_plot.data[0].marker.size=2,this.summary["predictions"]}async visualize(e,t,s,a,i){await super.visualize(e,t,s,a);let n=this;new DataTable("#metrics_table_"+n.id,{responsive:!1,footerCallback:function(e,t,s,a,i){var r=this.api();$(r.column(2).footer()).html("R2 : "+n.summary.r2.toFixed(2)+" AIC: "+n.summary.aic.toFixed(2)),$(r.column(5).footer()).html("R2 : "+n.summary["best_fit_min"].r2.toFixed(2)+" AIC: "+n.summary["best_fit_min"].aic.toFixed(2)),$(r.column(8).footer()).html("R2 : "+n.summary["best_fit_1se"].r2.toFixed(2)+" AIC: "+n.summary["best_fit_1se"].aic.toFixed(2))},data:n.model_stats_matrix,info:!1,search:!1,ordering:!1,searching:!1,paging:!1,bDestroy:!0,columnDefs:[{targets:3,createdCell:function(e,t,s,a,i){s[3]<=.05&&$(e).css("color","red")}},{targets:6,createdCell:function(e,t,s,a,i){s[6]<=.05&&$(e).css("color","red")}},{targets:9,createdCell:function(e,t,s,a,i){s[9]<=.05&&$(e).css("color","red")}}]}),M().newPlot("regularization_"+n.id,n.summary.regularization_plot,{autosize:!0,responsive:!0}),M().newPlot("parameters_plot_"+n.id,n.summary.coefs_plot,{autosize:!0,responsive:!0}),M().newPlot("errors_"+n.id,n.summary.errors_plot,{autosize:!0,responsive:!0}),M().newPlot("qqplot_ols_"+n.id,n.summary.qqplot_ols_plot),M().newPlot("qqplot_min_"+n.id,n.summary.qqplot_min_plot),M().newPlot("qqplot_1se_"+n.id,n.summary.qqplot_1se_plot),n.ui.yhat_plot(t,this.summary["predictions"],"regression_y_yhat_"+ +n.id,"OLS predictions"),n.ui.yhat_plot(t,this.summary["predictionsmin"],"regression_y_yhat_min_"+ +n.id,"lasso min predictions"),n.ui.yhat_plot(t,this.summary["predictions1se"],"regression_y_yhat_1se_"+ +n.id,"lasso 1se predictions"),n.ui.residual_plot(t,this.summary["residuals_ols"],"regression_residual_"+ +n.id,"OLS residuals"),n.ui.residual_plot(t,this.summary["residuals_min"],"regression_residual_min_"+ +n.id,"lasso min residuals"),n.ui.residual_plot(t,this.summary["residuals_1se"],"regression_residual_1se_"+ +n.id,"lasso 1se residuals"),this.ui.predictions_table_regression(e,t,a,this.id)}}class fe{constructor(e){this.options=e,this.model=null,this.hasExplaination=!1}async train(e,t,s,a,i){this.context={X_train:e,y_train:t,X_test:s,types:this.options.types,labels:i};const n="\n        import numpy as np\n        import statsmodels.api as sm\n        from js import X_train,y_train,X_test,labels,types\n        from statsmodels.nonparametric.kernel_regression import KernelReg\n        import pandas as pd\n\n        df_test = pd.DataFrame(X_test,columns=labels)\n        x_test = df_test.iloc[:,:]\n\n        df_train = pd.DataFrame(X_train,columns=labels)\n        x_train = df_train.iloc[:,:]\n\n        model = KernelReg(endog=np.array(y_train), exog=x_train, var_type=types)\n        \n        preds = model.fit(x_test)\n\n        \n        preds\n        ";try{const{results:e,error:t}=await N(n,this.context);if(e)return e;t&&console.log("pyodideWorker error: ",t)}catch(r){throw Error(`Error in pyodideWorker at ${r.filename}, Line: ${r.lineno}, ${r.message}`)}}predict(e){const t=this.model.predict(e);return t}}class ge extends se{constructor(e,t){super(t);let s={booster:e.booster.value??"gbtree",objective:"multi:softmax",max_depth:+e.depth.value,eta:+e.eta.value,estimators:e.estimators.value??200};this.options=s,this.helpSectionId="cart_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,objective:this.options.objective,max_depth:this.options.max_depth,eta:this.options.eta,estimators:this.options.estimators,seed:this.seed,pdpIndex:r,features:[...Array(i.length).keys()],explain:this.hasExplaination};const o="\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from js import X_train,y_train,X_test,y_test,objective,max_depth,eta,estimators,seed,features,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.ensemble import GradientBoostingClassifier\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n\n        model = GradientBoostingClassifier(learning_rate = eta,n_estimators = estimators,max_depth =max_depth,random_state = seed )\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}generatePythonCode(){let e="from sklearn.ensemble import GradientBoostingClassifier",t=`model = GradientBoostingClassifier(learning_rate = ${this.options.eta} ,n_estimators = ${this.options.estimators} ,max_depth =${this.options.max_depth} ,random_state = ${this.seed} )`;return super.generatePythonCode(e,t)}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class ye extends ie{constructor(e,t){super(t);let s={booster:e.booster.value??"gbtree",objective:"multi:softmax",max_depth:+e.depth.value,eta:+e.eta.value,estimators:e.estimators.value??200};this.options=s,this.helpSectionId="cart_help"}async train(e,t,s,a,i){this.context={X_train:e,y_train:t,X_test:s,y_test:a,objective:this.options.objective,max_depth:this.options.max_depth,eta:this.options.eta,estimators:this.options.estimators,seed:this.seed,explain:this.hasExplaination,features:[...Array(i.length).keys()]};const n="\n\n        from js import X_train,y_train,X_test,y_test,objective,max_depth,eta,estimators,seed,features,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.ensemble import GradientBoostingRegressor\n        import pandas as pd\n        import matplotlib\n        matplotlib.use(\"AGG\")\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        model = GradientBoostingRegressor(learning_rate = eta,n_estimators = estimators,max_depth =max_depth,random_state = seed)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance\n\n    ";try{const{results:e,error:t}=await N(n,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(r){throw Error(`Error in pyodideWorker at ${r.filename}, Line: ${r.lineno}, ${r.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}var be=function(){this.createModel=(e,t)=>{switch(console.log(t),e){case E.classification.logistic_regression.value:return new ae(t);case E.classification.k_nearest_neighbour.value:return new ce(t);case E.classification.random_forest.value:return new me(t);case E.classification.support_vector_machine.value:return new oe(t);case E.classification.boosting.value:return new ge(t);case E.regression.boosting.value:return new ye(t);case E.classification.discriminant_analysis.value:return new he(t);case E.classification.naive_bayes.value:return new ue(t);case E.regression.linear_regression.value:return new ne(t);case E.regression.k_nearest_neighbour.value:return new de(t);case E.regression.support_vector_machine.value:return new le(t);case E.regression.random_forest.value:return new pe(t);case E.regression.polynomial_regression.value:return new _e(t);case E.regression.kernel_regression.value:return new fe(t);case E.regression.bspline_regression.value:return new re(t);default:throw new Error("Model not supported.")}}},ve=s(67822),xe=s(94373),we={name:"SidebarComponent",setup(){const e=b();return{settings:e}},components:{UploadComponent:S},props:{msg:String},data(){return{dataScalingBehavior:!1,explainModel:!0,training:!1,tuneModel:!1,numberOfComponents:0,usePCAs:!1,seed:123,dataframe:null,configureFeatures:!1,modelOptions:E.classification,imputationOption:1,modelOption:1,featureTypeOptions:z,crossValidationOption:1,columns:[],modelTarget:null,modelConfigurations:null,imputationOptions:[{id:1,label:"Delete rows"},{id:2,label:"Mean and Mode"},{id:3,label:"Linear regression"},{id:4,label:"random forest"}],crossValidationOptions:[{id:A.SPLIT,label:"70 % training - 30 % test"},{id:A.NO,label:"No"},{id:A.KFOLD,label:"k-fold"}],featureSettings:[],modelSettings:[],modelName:""}},methods:{updateFeatures(){this.configureFeatures=!1,this.$emit("updateFeatures",!0)},toggleTraining(){this.training=!this.training;let e=this.training?"started training "+this.modelName:"Successully fitted "+this.modelName;this.$buefy.toast.open({duration:5e3,message:this.training?"started training "+this.modelName:"Successully fitted "+this.modelName,type:this.training?"is-info":"is-success"}),this.settings.addMessage({message:e,type:"info"})},getDefaultModelConfiguration(){for(const e in this.modelOptions){const t=this.modelOptions[e];if(t.id===this.modelOption){for(const e in t.options)t.options[e].value=t.options[e]?.default;this.modelConfigurations=t.options,this.modelName=t.label}}},configureModel(){this.tuneModel=!this.tuneModel,this.getDefaultModelConfiguration()},generateTargetDropdown(){this.dataframe=this.settings.getDataset,this.columns=this.dataframe.columns,this.featureSettings=this.columns.map(((e,t)=>({name:e,selected:!0,type:"string"===this.dataframe.dtypes[t]?z.Nominal.id:z.Numerical.id}))),this.modelTarget=this.dataframe.columns[this.dataframe.columns.length-1],this.settings.setTarget(this.modelTarget);let e=this.featureSettings.filter((e=>e.selected));for(let t=0;t<e.length;t++)this.settings.addFeature(e[t]);this.$emit("updateFeatures",!0)},checkmodelTask(){this.settings.setTarget(this.modelTarget);let e=this.settings.items.filter((e=>e.selected&&1===e.type)),t=this.settings.items.filter((e=>e.selected&&1!==e.type)),s=e.concat(t),a=s.find((e=>e.name==this.modelTarget));this.settings.setmodelTask(a.type!==z.Numerical.id),this.modelOptions=a.type===z.Numerical.id?E.regression:E.classification},async train(){try{this.modelConfigurations||this.getDefaultModelConfiguration();let e=this.seed;this.settings.setSeed(e);let t=[],s=null;s=this.seed!=this.settings.getSeed?await this.dataframe.sample(this.dataframe.$data.length,{seed:e}):await this.dataframe;let a=this.settings.items.filter((e=>e.selected&&e.type===z.Numerical.id)).map((e=>e.name));const i=this.settings.modelTarget;if(s=W(s),s=J(s,a,this.settings.transformationsList),this.dataScalingBehavior){let e=[];for(let t=0;t<a.length;t++)e.push({name:a[t],scaler:"1"});s=J(s,a,e)}let n=this.settings.items.filter((e=>e.selected)).map((e=>e.name));const r=n.findIndex((e=>e===i));-1===r&&n.push(i);let o=s.loc({columns:n});if(this.settings.isClassification){let e=this.settings.mergedClasses;if(e?.length>0){let t=e.map((e=>e.class)).join("");e.forEach((e=>{o.replace(e.class,t,{columns:[this.settings.modelTarget],inplace:!0})}))}}const l=o.column(i);o.drop({columns:i,inplace:!0});const c=this.crossValidationOption;let d,m,p,u;if([o,t]=V(o,this.settings.items.filter((e=>e.selected)).filter((e=>e.name!==this.settings.modelTarget)).map((e=>({name:e.name,type:e.type})))),c!==A.KFOLD||this.modelName==E.classification.logistic_regression.name&&this.modelName==E.regression.linear_regression.name)[d,m,p,u]=this.splitData(c,o,l);else{let e=[];for(let s=1;s<6;s++){[d,m,p,u]=this.kfoldSplit(o,l,s);let a,i,n,r=[...new Set(m.values)];this.settings.classificationTask?[a,i,n]=this.encodeTarget(m.values,u.values):(i=m.values,n=u.values);let c=new be,h=c.createModel(this.modelOption,this.modelConfigurations);h.hasExplaination=!1,h.id=this.settings.getCounter,this.toggleTraining();let _=await h.train(d.values,i,p.values,n,d.columns,t,0),f=await h.evaluateModel(n,_,r);f=this.settings.classificationTask?f[4]:f[0],this.training=!1,e.push(f)}}let h,_,f,g=[...new Set(m.values)];this.settings.classificationTask?[h,_,f]=this.encodeTarget(m.values,u.values):(_=m.values,f=u.values);let y=new be,b=y.createModel(this.modelOption,this.modelConfigurations);if(b.seed=e,b.id=this.settings.getCounter,this.toggleTraining(),b.hasExplaination=this.explainModel,this.usePCAs){const e=new q;let t=this.settings.items.filter((e=>e.selected&&1===e.type)).map((e=>e.name)),[s,a,i,n,r,o]=await e.predict(d.loc({columns:t}).values,this.numberOfComponents,p.loc({columns:t}).values);s=s.map((e=>[].slice.call(e))),o=o.map((e=>[].slice.call(e)));let l=s[0].map(((e,t)=>"PC_"+(t+1)));d=new ve.DataFrame(s,{columns:l}),p=new ve.DataFrame(o,{columns:l})}let v=await b.train(d.values,_,p.values,f,d.columns,t,0),x=await b.evaluateModel(f,v,g);v?.length>0&&(this.settings.addResult({id:b.id,showProbas:b.hasProbability,helpSectionId:b.helpSectionId,hasExplaination:b.hasExplaination,snapshot:{x:d.values,y:_,xt:p.values,yt:f,xFeatures:d.columns,categoricals:t,id:this.modelOption,labels:g},name:this.modelName,datasetName:this.settings.getDatasetName,modelTask:this.settings.classificationTask,metrics:x,options:JSON.parse(JSON.stringify(this.modelConfigurations)),target:i,categoricalFeatures:this.settings.items.filter((e=>e.selected&&e.type!==z.Numerical.id)).map((e=>e.name)),numericColumns:a,transformations:[...this.settings.transformationsList.filter((e=>0!=e.type))],tables:b.tables,plots:b.plots}),this.settings.setActiveTab(2),setTimeout((async()=>{this.settings.setResultActiveTab(b.id+1),window.dispatchEvent(new Event("resize"))}),100),await b.visualize(p,f,g,v,h,d.columns,t),this.settings.increaseCounter(),this.toggleTraining())}catch(e){this.training=!1;let t="Failed to fit the "+this.modelName;throw this.$buefy.toast.open({duration:3e3,message:t,type:"is-warning"}),this.settings.addMessage({message:t,type:"warning"}),e}},impute(){this.training=!0,xe.A.post("http://127.0.0.1:5000/missforest",{data:(0,ve.toJSON)(this.dataframe),categoricalFeatures:this.settings.items.filter((e=>e.selected&&e.type!==z.Numerical.id)).map((e=>e.name))}).then((e=>{let t=new ve.DataFrame(e.data);this.dataframe=t,this.settings.setDataframe(t),this.training=!1}))}},created:function(){this.splitData=function(e,t,s,a=.7){let i,n,r,o,l=t.$data.length;if(e===A.SPLIT){const e=Math.ceil(l*a),c=`0:${e}`,d=`${e}:${l}`;i=t.iloc({rows:[c]}),n=s.iloc([c]),r=t.iloc({rows:[d]}),o=s.iloc([d])}else e===A.NO&&(i=t,n=s,r=t,o=s);return[i,n,r,o]},this.kfoldSplit=function(e,t,s=1){let a,i,n,r,o=e.$data.length;const l=Math.ceil(o*(.2*(s-1))),c=Math.ceil(o*(.2*s)),d=0!=l?`:${l}`:null,m=c!=o?`${c}:`:null,p=`${l}:${c}`;let u=null!=m?e.iloc({rows:[m]}):null,h=null!=m?t.iloc([m]):null;n=e.iloc({rows:[p]}),r=t.iloc([p]);let _=null!=d?e.iloc({rows:[d]}):null,f=null!=d?t.iloc([d]):null;return _&&u?(a=(0,g.concat)({dfList:[_,u],axis:0}),i=(0,g.concat)({dfList:[f,h],axis:0})):(a=null==_?u:_,i=null==_?h:f),[a,i,n,r]},this.encodeTarget=function(e,t){let s=new g.LabelEncoder;s.fit(e),s.transform(e);let a=s.transform(e),i=s.transform(t);return[s,a,i]}},watch:{modelOption:function(){this.modelConfigurations=null}}},Ce=we,ke=(0,C.A)(Ce,r,o,!1,null,null,null),Se=ke.exports,ze=function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-10"},[t("section",[t("b-tabs",{attrs:{position:"is-centered",animated:!1,type:"success"},on:{input:function(t){return e.resize()}},model:{value:e.settings.activeTab,callback:function(t){e.$set(e.settings,"activeTab",t)},expression:"settings.activeTab"}},[t("b-tab-item",{attrs:{label:"Data Analysis",icon:"search","icon-pack":"fas"}},[this.settings.datasetShape?.count>0?t("section",[e.isActive?t("div",{staticClass:"message is-info",attrs:{closable:!1}},[t("div",{staticClass:"message-header"},[e._v("Data summary")]),t("div",{staticClass:"message-body"},[t("div",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-12 has-text-left"},[t("p",{staticClass:"title is-7"},[e._v(" Data Shape : ("+e._s(this.settings.datasetShape.count)+","+e._s(this.settings.datasetShape.columns)+")")])]),t("div",{staticClass:"column is-6"},[t("h5",{staticClass:"title is-7 has-text-left"},[e._v("Continuous Features: "),t("button",{staticClass:"button is-small",on:{click:function(t){return e.applyChanges()}}},[e._v("apply")])]),t("table",{staticClass:"table is-size-7"},[t("thead",[t("tr",[t("th"),t("th",[e._v("name")]),t("th",[e._v("Min")]),t("th",[e._v("Max")]),t("th",[e._v("Mean")]),t("th",[e._v("Median")]),t("th",[e._v("std")]),t("th",[e._v("#NAs")]),t("th",[e._v("TYPE")])])]),t("tbody",e._l(e.continuousFeaturesStats,(function(s){return t("tr",{key:s.name},[t("td",[t("b-checkbox",{model:{value:s.selected,callback:function(t){e.$set(s,"selected",t)},expression:"feature.selected"}})],1),t("td",[e._v(e._s(s.name))]),t("td",[e._v(e._s(s.min))]),t("td",[e._v(e._s(s.max))]),t("td",[e._v(e._s(s.median))]),t("td",[e._v(e._s(s.mean))]),t("td",[e._v(e._s(s.std))]),t("td",[e._v(e._s(s.missingValuesCount))]),t("td",[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:s.type,callback:function(t){e.$set(s,"type",t)},expression:"feature.type"}},e._l(e.featureTypeOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.name)+" ")])})),0)],1)])})),0)])]),t("div",{staticClass:"column is-6"},[t("h5",{staticClass:"title is-7 has-text-left"},[e._v("Categorical Features :")]),t("table",{staticClass:"table is-size-7"},[t("thead",[t("tr",[t("th"),t("th",[e._v("Name")]),t("th",[e._v("Shape")]),t("th",[e._v("Mode")]),t("th",[e._v("Mode percentage")]),t("th",[e._v("#NAs")]),t("th",[e._v("TYPE")])])]),t("tbody",e._l(e.categoricalFeaturesStats,(function(s){return t("tr",{key:s.name},[t("td",[t("b-checkbox",{model:{value:s.selected,callback:function(t){e.$set(s,"selected",t)},expression:"feature.selected"}})],1),t("td",[e._v(e._s(s.name))]),t("td",[e._v(e._s(s.shape))]),t("td",[e._v(e._s(s.mode))]),t("td",[e._v(e._s(s.percentage))]),t("td",[e._v(e._s(s.missingValuesCount))]),t("td",[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:s.type,callback:function(t){e.$set(s,"type",t)},expression:"feature.type"}},e._l(e.featureTypeOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.name)+" ")])})),0)],1)])})),0)])]),t("div",{staticClass:"column is-6"},[t("h5",{staticClass:"title is-7 has-text-left"},[e._v("Sample Data :")]),t("b-table",{staticClass:"is-size-7",attrs:{data:e.sampleData,columns:e.datasetColumns,narrowed:!0,bordered:!0,striped:!0,hoverable:!0}})],1)])])]):e._e(),t("section",[t("scatterplot-matrix-component",{ref:"splom"})],1),t("section",[t("article",{staticClass:"message is-info mt-2"},[t("div",{staticClass:"message-header"},[e._v("correlation matrix and Dendrogram "),t("b-tooltip",{attrs:{"append-to-body":"",label:"Ward method requires euclidean distance",multilined:""}},[t("b-button",{attrs:{"icon-left":"info","icon-pack":"fas",size:"is-small",type:"is-dark"}})],1)],1),t("div",{staticClass:"message-body"},[t("b-field",{attrs:{label:"Linkage method, Distance Metric"}},[t("b-select",{attrs:{placeholder:"Method"},model:{value:e.method,callback:function(t){e.method=t},expression:"method"}},[t("option",{attrs:{value:"single"}},[e._v("single")]),t("option",{attrs:{value:"complete"}},[e._v("complete")]),t("option",{attrs:{value:"average"}},[e._v("average")]),t("option",{attrs:{value:"weighted"}},[e._v("weighted")]),t("option",{attrs:{value:"centroid"}},[e._v("centroid")]),t("option",{attrs:{value:"median"}},[e._v("median")]),t("option",{attrs:{value:"ward"}},[e._v("ward")])]),t("b-select",{attrs:{placeholder:"Metric"},model:{value:e.metric,callback:function(t){e.metric=t},expression:"metric"}},[t("option",{attrs:{value:"euclidean"}},[e._v("euclidean")]),t("option",{attrs:{value:"correlation"}},[e._v("correlation")]),t("option",{attrs:{value:"mahalanobis"}},[e._v("mahalanobis")]),t("option",{attrs:{value:"cosine"}},[e._v("cosine")])]),t("p",{staticClass:"control"},[t("b-button",{staticClass:"is-success",attrs:{disabled:e.loading,loading:e.loading},on:{click:e.correlationMatrix}},[e._v("Correlation Cluster Diagram")])],1)],1),t("div",{staticClass:"columns is-multiline is-centered mb-2"},[t("div",{staticClass:"column is-5",staticStyle:{height:"400px"},attrs:{id:"correlation_matrix"}}),t("div",{staticClass:"column is-5",staticStyle:{height:"400px"},attrs:{id:"correlation_matrix_ordered"}})])],1)])])]):t("section",[t("b-message",{attrs:{type:"is-danger","has-icon":"","icon-pack":"fas"}},[e._v(" Upload a dataset or select a sample from sidebar. ")])],1)]),t("b-tab-item",{attrs:{label:"Dimensionality Reduction",icon:"compress-arrows-alt","icon-pack":"fas"}},[t("dmensionality-reduction-component",{attrs:{dataframe:this.settings.df,columns:e.selectedFeatures}})],1),t("b-tab-item",{attrs:{label:"Results Analysis",icon:"chart-pie","icon-pack":"fas"}},[t("results-component",{ref:"results"})],1),t("b-tab-item",{attrs:{label:"Methods Details",icon:"list","icon-pack":"fas"}},[t("methods-tab-component")],1),t("b-tab-item",{attrs:{label:"Help",icon:"question","icon-pack":"fas"}},[t("div",{staticClass:"content has-text-left"},[t("h4",[e._v("1. Dataset Selection")]),t("p",[e._v(" To begin, you can either select a sample dataset provided by the system or upload your own dataset. The supported file formats for datasets include .xlsx (Excel files), .csv (Comma Separated Values files), and .txt (plain text files). Ensure that your file is in one of these formats to avoid any issues during the upload process. ")]),t("figure",[t("img",{attrs:{src:"/upload.png"}}),t("figcaption",[e._v("Figure 1: Dataset Selection")])]),t("h4",[e._v("2. Data Analysis")]),t("figure",[t("img",{attrs:{src:"/stats_categorical.jpg"}}),t("figcaption",[e._v("Figure 2: Categorical features stats")])]),t("p",[e._v(" After uploading the dataset an overview of the dataset would be shhown in the Data Analysis tab. In the first window we provide you witth statistical metrics of the dataset. for canotinious features we show the mean, std, min, max, and etc. In case of categorical features information such as shape, mode and percentages of smaples with modes option, and number of missing values. ")]),t("figure",[t("img",{attrs:{src:"/stats_continious.jpg"}}),t("figcaption",[e._v("Figure 3: Categorical features stats")])]),t("p",[e._v(" In case of categorical features information such as shape, mode and percentages of smaples with modes option, and number of missing values. ")]),t("h4",[e._v("3. Feature selection")]),t("p",[e._v(" After uploading the dataset, you can customize the data by selecting specific features based on your requirements. To do this, click on the 'Select Features' button, which will open a new menu. This menu allows you to choose the features that will be used in the training process. If there is an issue with the automatic detection of feature data types, you can manually adjust the data types to ensure they are correctly categorized as ordinal, categorical, or continuous. ")]),t("h4",[e._v("3. Model Selection")]),t("figure",[t("img",{attrs:{src:"/model_selection.jpg"}}),t("figcaption",[e._v("Figure 4: Model selection and setting for knn")])]),t("p",[e._v(" Once you have selected all the required features and resolved any issues with feature data types, you can proceed to the model selection step. Use the 'Model' dropdown to choose the model for training. The options in this dropdown will be dynamically populated based on the type of data in your features: regression models will be available for continuous data, while classification models will be shown for categorical data. Additionally, you can further customize the selected model by clicking the gear icon, which allows you to adjust common settings and parameters specific to each model. ")])])]),t("b-tab-item",{attrs:{label:"Messages Log",icon:"history","icon-pack":"fas"}},e._l(this.settings.getMessages,(function(s,a){return t("b-notification",{key:a,attrs:{"aria-close-label":"Close notification","icon-pack":"fas",type:"warning"==s.type?"is-warning":"danger"==s.type?"is-danger":"is-info","has-icon":"",closable:!1}},[e._v(" "+e._s(s.message?.toLowerCase())+" "),t("br"),e._v(" "+e._s(s.date)+" ")])})),1)],1)],1)])},Ae=[],Pe=function(){var e=this,t=e._self._c;return this.settings?.items.length>2?t("section",[t("b-message",{attrs:{title:"Principle Component Analysis",type:"is-info",closable:!1}},[t("b-field",[t("p",{staticClass:"control"},[t("b-button",{attrs:{disabled:e.numberOfComponents<2||e.numberOfComponents>this.settings.items.filter((e=>e.selected&&1===e.type))?.length,size:"is-small",type:"is-info",loading:e.loadingPCA,label:"Fit PCA"},on:{click:function(t){return e.drawPCA()}}})],1)]),t("div",{staticClass:"columns is-multiline",attrs:{id:"pca_container"}},[t("div",{staticClass:"column is-6"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"scree_plot"}})]),t("div",{staticClass:"column is-6"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"correlation_circle"}})]),e.hasPCA?t("div",{staticClass:"column is-12"},[t("b-field",{attrs:{label:"Number of Components"}},[t("b-input",{attrs:{size:"is-small",type:"number",min:"2",placeholder:"Number of Components"},model:{value:e.numberOfComponents,callback:function(t){e.numberOfComponents=t},expression:"numberOfComponents"}}),t("p",{staticClass:"control"},[t("b-button",{attrs:{disabled:e.numberOfComponents<2||e.x==e.y||e.numberOfComponents>this.settings.items.filter((e=>e.selected&&1===e.type))?.length,size:"is-small",type:"is-info",loading:e.loadingPCA,label:"Draw PCA"},on:{click:function(t){return e.findPCA()}}})],1)],1)],1):e._e(),e._l(this.pcaContainers,(function(e,s){return t("div",{key:s,staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"pca_"+s}})])}))],2)],1),t("b-message",{attrs:{title:"t-distributed stochastic neighbor embedding",type:"is-info",closable:!1}},[t("b-field",{attrs:{label:"Iterations"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"number of iterations"},model:{value:e.iterationsTSNE,callback:function(t){e.iterationsTSNE=t},expression:"iterationsTSNE"}}),t("p",{staticClass:"control"},[t("b-button",{attrs:{size:"is-small",type:"is-info",loading:e.loadingTSNE,label:"Fit t-SNE"},on:{click:e.findTSNE}})],1)],1),t("div",{staticClass:"column is-6",attrs:{id:"dimensionality_reduction_panel_tsne"}},[t("div",{attrs:{id:"tsne"}})])],1),t("b-message",{attrs:{title:"Autoencoder",closable:!1,type:"is-info"}},[t("b-field",{attrs:{grouped:""}},[t("b-field",{attrs:{expanded:""}},[t("b-field",{attrs:{label:"Hidden layers size","custom-class":"is-small"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"Hidden layer size"},model:{value:e.hiddenLayerSize,callback:function(t){e.hiddenLayerSize=t},expression:"hiddenLayerSize"}})],1),t("b-field",{attrs:{label:"x axis","custom-class":"is-small"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"x axis"},model:{value:e.autoEncoderX,callback:function(t){e.autoEncoderX=t},expression:"autoEncoderX"}})],1),t("b-field",{attrs:{label:"y axis","custom-class":"is-small"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"y axis"},model:{value:e.autoEncoderY,callback:function(t){e.autoEncoderY=t},expression:"autoEncoderY"}})],1),t("b-field",{attrs:{label:"iterations","custom-class":"is-small"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"iterations"},model:{value:e.iterations,callback:function(t){e.iterations=t},expression:"iterations"}})],1),t("b-field",{attrs:{label:"encoder","custom-class":"is-small"}},[t("b-select",{attrs:{size:"is-small",placeholder:"Encoder Activation Function"},model:{value:e.encoderActivationFunction,callback:function(t){e.encoderActivationFunction=t},expression:"encoderActivationFunction"}},[t("option",{attrs:{value:"linear",id:"linear"}},[e._v(" linear ")]),t("option",{attrs:{value:"sigmoid",id:"sigmoid"}},[e._v(" sigmoid ")]),t("option",{attrs:{value:"relu",id:"relu"}},[e._v(" RELU ")])])],1),t("b-field",{attrs:{label:"decoder","custom-class":"is-small"}},[t("b-select",{attrs:{size:"is-small",placeholder:"Decoder Activation Function"},model:{value:e.decoderActivationFunction,callback:function(t){e.decoderActivationFunction=t},expression:"decoderActivationFunction"}},[t("option",{attrs:{value:"linear",id:"linear"}},[e._v(" linear ")]),t("option",{attrs:{value:"sigmoid",id:"sigmoid"}},[e._v(" sigmoid ")]),t("option",{attrs:{value:"relu",id:"relu"}},[e._v(" RELU ")])])],1),t("b-field",{attrs:{"custom-class":"is-small"}},[t("p",{staticClass:"control"},[t("b-button",{attrs:{size:"is-small",type:"is-info",loading:e.loadingAutoEncoder,label:"Fit Autoencoder"},on:{click:e.autoEncoder}})],1)])],1)],1),t("div",{staticClass:"column is-6",attrs:{id:"dimensionality_reduction_panel_tsne"}},[t("div",{staticStyle:{height:"300px"},attrs:{id:"autoencoder"}})])],1)],1):t("section",[t("b-message",{attrs:{type:"is-danger","has-icon":"","icon-pack":"fas"}},[e._v(" There is no data to show. ")])],1)},Ee=[];let Fe=new ee;var Te={name:"dmensionality-reduction-component",setup(){const e=b();return{settings:e}},props:{msg:String,dataframe:Object,columns:[]},data(){return{numberOfComponents:2,loadingPCA:!1,loadingTSNE:!1,x:1,y:2,loadingAutoEncoder:!1,hiddenLayerSize:2,iterationsTSNE:200,iterations:200,encoderActivationFunction:"linear",decoderActivationFunction:"linear",autoEncoderX:1,autoEncoderY:2,hasPCA:!1,pcaContainers:[],df:null}},methods:{prepareData(){if(this.df=new g.DataFrame(this.settings.rawData),this.df.dropNa({axis:1,inplace:!0}),this.settings.isClassification&&this.settings.mergedClasses?.length>0){let e=this.settings.mergedClasses.map((e=>e.class)).join("-");this.settings.mergedClasses.forEach((t=>{this.df.replace(t.class,e,{columns:[this.settings.modelTarget],inplace:!0})}))}},async drawPCA(){try{this.numberOfComponents=null,await this.findPCA(!0)}catch(e){throw this.loadingPCA=!1,e}},async findPCA(e=!1){try{this.prepareData(),this.loadingPCA=!0;for(let e=0;e<this.pcaContainers.length;e++)Fe.purge_charts("pca_"+e);this.pcaContainers=[];let t=this.settings.items.filter((e=>e.selected&&1===e.type)).map((e=>e.name));if(0==e){if(2==this.numberOfComponents)this.pcaContainers.push([1,2]);else if(3==this.numberOfComponents)this.pcaContainers.push([1,2],[1,3],[2,3]);else if(this.numberOfComponents>3){this.pcaContainers.push([1,2],[1,3],[2,3]);for(let e=4;e<=this.numberOfComponents;e++){let t=1;while(t<=e-1)this.pcaContainers.push([t,e]),t++}}}else this.numberOfComponents=t.length;let s=this.df.loc({columns:t}).values;await Fe.draw_pca(s,this.settings.isClassification?this.df.loc({columns:[this.settings.modelTarget]}).values:[],this.df.loc({columns:[this.settings.modelTarget]}).values,this.numberOfComponents,this.pcaContainers,t,e),this.hasPCA=!0,this.loadingPCA=!1}catch(t){throw this.loadingPCA=!1,t}},async findTSNE(){try{this.prepareData(),this.loadingTSNE=!0;let e=this.settings.items.filter((e=>e.selected&&1===e.type)).map((e=>e.name));await Fe.plot_tsne(this.df.loc({columns:e}).values,this.settings.isClassification?this.df.loc({columns:[this.settings.modelTarget]}).values:[],this.df.loc({columns:[this.settings.modelTarget]}).values,this.iterationsTSNE),this.loadingTSNE=!1}catch(e){throw this.loadingTSNE=!1,e}},async autoEncoder(){this.prepareData(),this.loadingAutoEncoder=!0;const e=g.tensorflow.sequential();let t=this.settings.items.filter((e=>e.type===z.Numerical.id)).map((e=>e.name)),s=t.length,a=this.settings.df.loc({columns:t}).values;const i=g.tensorflow.layers.dense({units:+this.hiddenLayerSize,batchInputShape:[null,s],activation:this.encoderActivationFunction,kernelInitializer:"glorotNormal",biasInitializer:"zeros"}),n=g.tensorflow.layers.dense({units:s,activation:this.decoderActivationFunction});e.add(i),e.add(n),await e.compile({optimizer:"adam",loss:"meanSquaredError"});const r=g.tensorflow.tensor2d(a);await e.fit(r,r,{epochs:+this.iterations,batchSize:64,shuffle:!1,validationSplit:.1});r.dispose();const o=g.tensorflow.tidy((()=>{const e=g.tensorflow.sequential();e.add(i);let t=g.tensorflow.tensor2d(a),s=e.predict(t);return t.dispose(),s.arraySync()}));let l=await o;Fe.drawAutoencoder(l,this.autoEncoderX-1,this.autoEncoderY-1,this.df.loc({columns:[this.settings.modelTarget]}).values,this.settings.isClassification),this.loadingAutoEncoder=!1}},errorCaptured(){}},$e=Te,Ne=(0,C.A)($e,Pe,Ee,!1,null,null,null),qe=Ne.exports,De=function(){var e=this,t=e._self._c;return t("div",[this.settings.results?.length>0?t("b-tabs",{on:{input:e.resize},model:{value:e.activeResult,callback:function(t){e.activeResult=t},expression:"activeResult"}},[t("b-tab-item",{attrs:{label:"compare"},on:{click:e.compareResults}},[t("button",{staticClass:"button is-info my-2",on:{click:e.compareResults}},[e._v(" Compare models")]),t("div",{directives:[{name:"show",rawName:"v-show",value:e.compare,expression:"compare"}],staticClass:"column is-12",staticStyle:{height:"400px"},attrs:{id:"comaprison_plot"}})]),e._l(this.settings.results,(function(s){return[t("b-tab-item",{key:s.id,attrs:{label:s.id+1+"."+s.name.toString()}},[s.modelTask?t("classification-view-component",{attrs:{result:s},on:{"delete-result":e.deleteResult}}):t("regression-view-component",{attrs:{result:s},on:{"delete-result":e.deleteResult}}),t("div",{staticClass:"column is-12"},[t("div",{staticClass:"table-container"},[t("table",{staticClass:"table is-bordered is-hoverable is-narrow display is-size-7",attrs:{id:"predictions_table_"+s.id,width:"100%"}})])])],1)]}))],2):t("b-message",{attrs:{type:"is-danger","has-icon":"","icon-pack":"fas"}},[e._v(" No result to show. ")])],1)},Me=[],Oe=function(){var e=this,t=e._self._c;return t("article",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-12 mb-1"},[t("b-message",{staticClass:"has-text-left",attrs:{type:"is-info ","has-icon":"","icon-pack":"fas"}},[t("p",{staticClass:"my-1 is-size-7"},[t("span",[e._v("Dataset Name : "+e._s(e.result.datasetName)+" , ")]),t("span",[e._v(" Target variable : "+e._s(e.result.target))])]),t("p",{staticClass:"subtitle is-6 my-1 is-size-7"},[e._v("Features :")]),t("p",{staticClass:"ml-2 my-1 subtitle is-6 is-size-7"},[e._v("Categorical Features : "),e._l(e.result.categoricalFeatures,(function(s){return t("span",{key:s},[e._v(" "+e._s(s+", ")+" ")])}))],2),t("p",{staticClass:"ml-2 my-1 subtitle is-6 is-size-7"},[e._v("Numerical Features : "),e._l(e.result.numericColumns,(function(s){return t("span",{key:s},[e._v(" "+e._s(s+", ")+" ")])}))],2),t("p",{directives:[{name:"show",rawName:"v-show",value:e.result.transformations?.length>0,expression:"result.transformations?.length > 0"}],staticClass:"ml-2 my-1 subtitle is-6 is-size-7"},[e._v("Transformations : "),e._l(e.result.transformations,(function(s){return t("span",{key:s.name},[e._v(" "+e._s(s.name+": "+s.scalerLabel+",")+" ")])}))],2),e._l(e.result.options,(function(s,a){return t("p",{key:a,staticClass:"is-size-7"},[e._v(" "+e._s(a)+": "+e._s(s["value"])+" ")])})),t("p",{staticClass:"subtitle my-1 is-size-7"},[e._v("Goodness of Fit :")]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("Accuracy : "+e._s(e.result.metrics.accuracy.toFixed(2)))]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("f1 micro : "+e._s(e.result.metrics.f1_micro.toFixed(2)))]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v(" f1 macro :"+e._s(e.result.metrics.f1_macro.toFixed(2)))]),t("button",{staticClass:"button is-danger has-text-white is-small",staticStyle:{color:"#fff !important"},on:{click:function(t){return e.deleteTab()}}},[e._v("Delete ")]),t("button",{staticClass:"button is-success is-small",on:{click:function(t){return e.toggleHelp(e.result.helpSectionId)}}},[e._v("Method description ")]),t("button",{staticClass:"button is-info is-small",on:{click:function(t){return e.downloadPythonCode()}}},[e._v("Download the code")])],2)],1),t("div",{staticClass:"column is-12"},[t("article",{staticClass:"message is-info"},[t("div",{staticClass:"message-header"},[e._v(" Confusion Matrix and PCA of predictions")]),t("div",{staticClass:"message-body mx-1"},[t("div",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-6 my-1",staticStyle:{height:"400px"},attrs:{id:"confusion_matrix_"+e.result.id}}),t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.showProbas,expression:"result.showProbas"}],staticClass:"column is-6 my-1",staticStyle:{height:"400px"},attrs:{id:"proba_plot_"+e.result.id}}),t("br"),t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.showProbas,expression:"result.showProbas"}],staticClass:"column is-6 my-1",staticStyle:{height:"400px"},attrs:{id:"roc_plot_"+e.result.id}}),t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.hasExplaination&&"Logistic Regression"!==e.result.name,expression:"result.hasExplaination && result.name !== 'Logistic Regression'"}],staticClass:"column is-6 my-1",staticStyle:{height:"400px"},attrs:{id:"pfi_boxplot_"+e.result.id}})])])])]),t("div",{directives:[{name:"show",rawName:"v-show",value:"Logistic Regression"===e.result.name,expression:"result.name === 'Logistic Regression'"}],staticClass:"column is-12"},[t("div",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-7"},[t("div",{staticClass:"table-container"},[t("table",{staticClass:"table has-text-centered nowrap is-striped is-bordered is-narrow is-hoverable is-size-7",attrs:{id:"metrics_table_"+e.result.id}},[e._m(0),e._m(1)])])]),t("div",{staticClass:"column is-5",attrs:{id:"parameters_plot_"+e.result.id}}),t("div",{staticClass:"column is-6",staticStyle:{height:"250px"},attrs:{id:"errors_"+e.result.id}}),t("div",{staticClass:"column is-6",staticStyle:{height:"250px"},attrs:{id:"regularization_"+e.result.id}})])]),t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.hasExplaination&&"Logistic Regression"!==e.result.name,expression:"result.hasExplaination && result.name !== 'Logistic Regression'"}],staticClass:"column is-12"},[t("article",{staticClass:"message is-info"},[t("div",{staticClass:"message-header"},[e._v(" Partial Dependence Plot")]),t("div",{staticClass:"message-body mx-1"},[t("div",{staticClass:"columns is-multiline"},[e.result.name.toString().includes("neighbour")?t("div",{staticClass:"column is-6",staticStyle:{height:"400px"},attrs:{id:"knn_table_"+e.result.id}}):e._e(),t("div",{attrs:{id:"pdp_containers_"+e.result.id}})]),t("br")])])])])},Ie=[function(){var e=this,t=e._self._c;return t("thead",[t("tr",[t("th",{attrs:{colspan:"1"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("OLS")]),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("lambda min")]),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("lambda 1se")])]),t("tr",[t("th",{staticClass:"has-text-centered"},[e._v("name")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")])])])},function(){var e=this,t=e._self._c;return t("tfoot",{staticClass:"has-text-centered",staticStyle:{"font-weight":"normal"}},[t("tr",[t("th"),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}})])])}],Re={setup(){const e=b();return{settings:e}},created(){this.pdpFeature=this.settings.features[0].name},data(){return{pdpFeature:null,showResult:!0}},name:"ClassificationViewComponent",methods:{toggleHelp(e){this.settings.setActiveTab(3),setTimeout((()=>{let t=document.getElementById(e);t.scrollIntoView({behavior:"smooth"})}),500)},deleteTab(){this.$emit("delete-result",this.result.id)},downloadPythonCode(){let e=new be,t=e.createModel(this.result.snapshot.id,this.result.options),s=t.generatePythonCode();const a=new Blob([s],{type:"text/plain"}),i=URL.createObjectURL(a),n=document.createElement("a");n.href=i,n.download="example.py",document.body.appendChild(n),n.click(),document.body.removeChild(n),URL.revokeObjectURL(i)},async updatePartialDependencePlot(){let e=new be,t=e.createModel(this.result.snapshot.id,this.result.options);await t.train(this.result.snapshot.x,this.result.snapshot.y,this.result.snapshot.xt,this.result.snapshot.yt,this.result.snapshot.xFeatures,this.result.snapshot.categoricals,this.result.snapshot.xFeatures.findIndex((e=>e==this.pdpFeature))),t.chartController.plotPDP(this.result.id,t.pdp_averages,t.pdp_grid,this.result.snapshot.labels,this.pdpFeature)}},props:{result:{}},errorCaptured(e,t,s){return console.log(`cat EC: ${e.toString()}\ninfo: ${s}`),!1}},Le=Re,Xe=(0,C.A)(Le,Oe,Ie,!1,null,"6d03b3fb",null),je=Xe.exports,Be=function(){var e=this,t=e._self._c;return t("div",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-12"},[t("b-message",{staticClass:"has-text-left",attrs:{type:"is-info is-size-7\t","has-icon":"","icon-pack":"fas"}},[t("p",{staticClass:"my-1"},[t("span",[e._v("Dataset Name : "+e._s(e.result.datasetName)+" , ")]),t("span",[e._v(" Target variable : "+e._s(e.result.target))])]),t("p",{staticClass:"subtitle is-size-7 my-1"},[e._v("Features :")]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("Categorical Features : "),e._l(e.result.categoricalFeatures,(function(s){return t("span",{key:s},[e._v(" "+e._s(s+", ")+" ")])}))],2),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("Numerical Features : "),e._l(e.result.numericColumns,(function(s){return t("span",{key:s},[e._v(" "+e._s(s+", ")+" ")])}))],2),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("Transformations : "),e._l(e.result.transformations,(function(s){return t("span",{key:s.name},[e._v(" "+e._s(s.name+": "+s.scaler+",")+" ")])}))],2),e._l(e.result.options,(function(s,a){return t("p",{key:a},[e._v(" "+e._s(a)+": "+e._s(s["value"])+" ")])})),t("p",{staticClass:"subtitle is-size-7 my-1"},[e._v("Goodness of Fit :")]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("MSE : "+e._s(e.result.metrics.mse.toFixed(2)))]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("R2 : "+e._s(e.result.metrics.rsquared.toFixed(2)))]),t("button",{staticClass:"button is-danger has-text-white is-small",on:{click:function(t){return e.deleteTab()}}},[e._v("Delete ")]),t("button",{staticClass:"button is-success is-small",on:{click:function(t){return e.toggleHelp(e.result.helpSectionId)}}},[e._v("Help")])],2)],1),"Linear Regression"===e.result.name||"Polynomial Regression"===e.result.name?t("div",{staticClass:"column is-12"},[t("div",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-7"},[t("div",{staticClass:"table-container"},[t("table",{staticClass:"table has-text-centered nowrap is-striped is-bordered is-narrow is-hoverable is-size-7",attrs:{id:"metrics_table_"+e.result.id}},[e._m(0),e._m(1)])])]),t("div",{staticClass:"column is-5",attrs:{id:"parameters_plot_"+e.result.id,width:"100%"}}),t("div",{staticClass:"column is-6",staticStyle:{height:"250px"},attrs:{id:"errors_"+e.result.id,width:"100%"}}),t("div",{staticClass:"column is-6",staticStyle:{height:"250px"},attrs:{id:"regularization_"+e.result.id,width:"100%"}}),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_y_yhat_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_y_yhat_min_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_y_yhat_1se_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_residual_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_residual_min_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_residual_1se_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"qqplot_ols_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"qqplot_min_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"qqplot_1se_"+e.result.id,width:"100%"}})])])]):t("div",{staticClass:"column is-12"},[t("div",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-6"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_y_yhat_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-6"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"errors_"+e.result.id,width:"100%"}})]),e.result.name.toString().includes("neighbour")?t("div",{staticClass:"column is-6",staticStyle:{height:"350px"},attrs:{id:"knn_table_"+e.result.id}}):e._e(),t("div",{staticClass:"column is-12"},[t("article",{staticClass:"message is-info"},[t("div",{staticClass:"message-header"},[e._v(" Partial Dependence Plot and Permutation Feature Importance")]),t("div",{staticClass:"message-body"},[t("div",{staticClass:"columns is-multiline"},[t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.hasExplaination,expression:"result.hasExplaination"}],staticClass:"column is-6",staticStyle:{height:"400px"},attrs:{id:"pfi_boxplot_"+e.result.id}})])])])])])])])},Ge=[function(){var e=this,t=e._self._c;return t("thead",[t("tr",[t("th",{attrs:{colspan:"1"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("OLS")]),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("lasso min")]),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("lasso 1se")])]),t("tr",[t("th",{staticClass:"has-text-centered"},[e._v("names")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")])])])},function(){var e=this,t=e._self._c;return t("tfoot",{staticStyle:{"font-weight":"normal"}},[t("tr",[t("th"),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}})])])}],Je={setup(){const e=b();return{settings:e}},name:"regression-view-component",methods:{toggleHelp(e){this.settings.setActiveTab(3),setTimeout((()=>{let t=document.getElementById(e);t.scrollIntoView({behavior:"smooth"})}),500)},deleteTab(){this.$emit("delete-result",this.result.id)},async updatePartialDependencePlot(){let e=new be,t=e.createModel(this.result.snapshot.id,this.result.options);await t.train(this.result.snapshot.x,this.result.snapshot.y,this.result.snapshot.xt,this.result.snapshot.yt,this.result.snapshot.xFeatures,this.result.snapshot.categoricals,[0,1,2]),t.chartController.plotPDPRegression(this.result.id,t.pdp_averages,t.pdp_grid,this.result.snapshot.labels,this.result.snapshot.xFeatures,this.result.snapshot.categoricals)}},created(){this.pdpFeature=this.settings.features.filter((e=>e.name!=this.settings.target))[0].name},data(){return{pdpFeature:null,showResult:!0}},props:{result:{}}},We=Je,Ue=(0,C.A)(We,Be,Ge,!1,null,"b3fd8cfa",null),Ve=Ue.exports;let He=new te(null,null);var Qe={components:{"classification-view-component":je,"regression-view-component":Ve},setup(){const e=b(),t=(0,a.EW)({get:()=>e.getResultTab,set:t=>e.setResultActiveTab(t)});return{settings:e,activeResult:t}},name:"ResultsComponent",props:{},data(){return{compare:!1,datasetName:"",isClassication:-1,comparisonMetric:"",baseMetrics:[],activeTab:null,visitedTabs:[]}},methods:{fillMetrics(){1==this.isClassication?this.baseMetrics=[{name:"accuracy",id:1},{name:"f1 micro",id:2},{name:"f1 macro",id:3}]:0==this.isClassication&&(this.baseMetrics=[{name:"R2",id:1},{name:"MSE",id:0}])},compareResults(){try{M().purge("comaprison_plot")}catch(r){console.log("no plot to remove")}let e=this.settings.getMethodResults.filter((e=>e.datasetName==this.settings.datasetName&&this.settings.classificationTask==e.modelTask));this.compare=!0;let t=[],s={},a=[];e.forEach((e=>{let a=e.metrics;t.push(e.name+"."+e.id);for(const t in e.metrics)if("precision"!=t&&"recall"!=t){const e=a[t];t in s||(s[t]=[]),s[t].push(e)}}));let i=1;for(const o in s){let e={x:t,y:s[o],name:o,xaxis:"x"+i,yaxis:"y"+i,type:"scatter",marker:{color:"rgb(158,202,225)",opacity:.6,line:{color:"rgb(8,48,107)",width:.2}}};a.push(e),i++}var n={grid:{rows:1,columns:Object.keys(s).length,pattern:"independent"},height:300,margin:{l:40,r:40,b:80,t:10,pad:10}};M().newPlot("comaprison_plot",a,n,{responsive:!0})},resize(e){0===e&&this.compareResults(),window.dispatchEvent(new Event("resize"))},deleteResult(e){let[t,s]=this.settings.getResultVisualizations(e);t.forEach((e=>{He.removeTable(e)})),s.forEach((e=>{M().purge(e)})),this.settings.removeResult(e)},showMethodDetails(e){alert(e)}}},Ke=Qe,Ye=(0,C.A)(Ke,De,Me,!1,null,"12596309",null),Ze=Ye.exports,et=function(){var e=this,t=e._self._c;return t("section",{staticStyle:{"overflow-y":"auto","overflow-x":"auto"}},[t("article",{staticClass:"message is-info"},[t("div",{staticClass:"message-header"},[e._v("Scatterplot Matrix "),t("b-tooltip",{attrs:{"append-to-body":"",label:"nrd method and guassian kernel is used for kernel density estimation.",multilined:""}},[t("b-button",{attrs:{"icon-left":"info","icon-pack":"fas",size:"is-small",type:"is-dark"}})],1)],1),t("div",{staticClass:"message-body"},[t("div",{attrs:{id:"scatterplot_mtx"}}),t("div",{staticClass:"columns my-1 ml-5 mt-5 is-multiline",style:{width:100*e.features.length+"px"}},[e._l(this.settings.items.filter((e=>e.selected)),(function(s){return t("div",{key:s.id,style:{width:e.column_width+"%"}},[1==s.type?t("b-field",{staticClass:"ml-1",attrs:{label:s.name,"label-position":"on-border"}},[t("b-select",{attrs:{size:"is-small"},on:{input:function(t){return e.scaleData()}},model:{value:s.scaler,callback:function(t){e.$set(s,"scaler",t)},expression:"feature.scaler"}},e._l(e.ScaleOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.name)+" ")])})),0)],1):t("p",{staticClass:"title is-size-7 mt-1"},[e._v(e._s(s.name))])],1)})),t("br")],2),t("div",{staticClass:"column is-12"},[t("parallel-coordinate-plot-component",{ref:"coordinate_plot"})],1),this.settings.isClassification&&e.classesInfo?.length>2?t("div",{staticClass:"column is-12"},[t("h5",{staticClass:"title is-7 has-text-left"},[e._v("Merge classes ")]),t("b-table",{staticClass:"is-size-7",attrs:{data:e.classesInfo,columns:e.classesInfoColumns,checkable:"","row-class":(e,t)=>e.mode<=.1&&"has-text-danger",narrowed:!0,"checked-rows":e.selectedClasses},on:{"update:checkedRows":function(t){e.selectedClasses=t},"update:checked-rows":function(t){e.selectedClasses=t}}}),t("button",{staticClass:"button mt-2 is-info is-small",attrs:{disabled:e.selectedClasses?.length>=e.classesInfo?.length},on:{click:function(t){return e.scaleData()}}},[e._v("Merge Classes")]),t("button",{staticClass:"button mt-2 mx-1 is-success is-small",on:{click:function(t){return e.scaleData(!0)}}},[e._v("reset")])],1):e._e(),t("b-loading",{attrs:{"is-full-page":!1},model:{value:e.isLoading,callback:function(t){e.isLoading=t},expression:"isLoading"}})],1)])])},tt=[],st=function(){var e=this;e._self._c;return e._m(0)},at=[function(){var e=this,t=e._self._c;return t("section",{staticClass:"my-1"},[t("article",{staticClass:"message"},[t("div",{staticClass:"message-header"},[e._v("Parallel Coordinate Plot")]),t("div",{staticClass:"message-body"},[t("div",{attrs:{id:"parallel_coordinate_plot"}})])])])}];let it=new ee;var nt={setup(){const e=b();return{settings:e}},name:"ParallelCoordinatePlotComponent",props:{msg:String,update:{}},data(){return{isLoading:!1,ScaleOptions:P,features:[],df:null,rawData:null}},methods:{ParallelCoordinatePlot(){this.isLoading=!0;const e=new g.DataFrame(this.settings.rawData);if(this.settings.isClassification&&this.settings.classTransformations.length>0){let t=this.settings.classTransformations.concat(),s=t.map((e=>e.class)).join("-");t.forEach((t=>{e.replace(t.class,s,{columns:[this.settings.modelTarget],inplace:!0})}))}let t=this.settings.items.filter((e=>e.selected&&1===e.type));M().purge("parallel_coordinate_plot"),J(e,t.map((e=>e.name)),t);let s=this.settings.items.filter((e=>e.selected&&1===e.type)).map((e=>e.name));it.parallelCoordinatePlot(e.loc({columns:s}).values,e.column(this.settings.modelTarget).values,s,this.settings.isClassification),this.isLoading=!1}}},rt=nt,ot=(0,C.A)(rt,st,at,!1,null,"cde8a846",null),lt=ot.exports;let ct=new ee;var dt={components:{"parallel-coordinate-plot-component":lt},setup(){const e=b();return{settings:e}},name:"ScatterplotMatrixComponent",props:{msg:String,update:{}},data(){return{isLoading:!1,ScaleOptions:P,features:[],df:null,rawData:null,classesInfo:[],selectedClasses:[],classesInfoColumns:[]}},methods:{async dispalySPLOM(e){try{this.isLoading=!0;let t=this.settings.items.filter((e=>e.selected&&1===e.type)).map((e=>e.name)),s=this.settings.items.filter((e=>e.selected&&1!==e.type)).map((e=>e.name)),a=t.concat(s);if(e.dropNa({axis:1,inplace:!0}),await ct.ScatterplotMatrix(e.loc({columns:a}).values,a,e.column(this.settings.modelTarget).values,s.length,this.settings.isClassification,t,s,this.dataframe),this.settings.isClassification){let e=this.settings.df.column(this.settings.modelTarget).values,t=e.length,s=new Set(...[e]),a=[];s.forEach((s=>{a.push({class:s,mode:+(e.filter((e=>e===s)).length/t).toFixed(2)})})),this.classesInfo=a,this.classesInfoColumns=[{field:"class",label:" class"},{field:"mode",label:"Samples in each class (%)"}]}this.$refs.coordinate_plot?.ParallelCoordinatePlot(),this.isLoading=!1}catch(t){let e="Something went wrong drawing data analysis plots";this.$buefy.toast.open(e),this.settings.addMessage({message:e,type:"warning"})}},async scaleData(e=!1){if(this.df=new g.DataFrame(this.settings.rawData),this.settings.isClassification&&this.selectedClasses?.length>0){let e=this.selectedClasses.map((e=>e.class)).join("-");this.selectedClasses.forEach((t=>{this.df.replace(t.class,e,{columns:[this.settings.modelTarget],inplace:!0})})),this.settings.setClassTransformation(this.selectedClasses);let t={message:"merged classes: "+e,type:"info"};this.$buefy.toast.open("merged classes: "+e),this.settings.addMessage(t)}e&&this.settings.setClassTransformation([]);let t=this.settings.items.filter((e=>e.selected&&1===e.type&&0!=e.scaler));if(this.isLoading=!0,M().purge("scatterplot_mtx"),J(this.df,t.map((e=>e.name)),t),await this.dispalySPLOM(this.df),this.isLoading=!1,this.selectedClasses=[],t.length>0){let e=[];t.forEach((t=>{let s=Object.keys(P).find((e=>P[e].id==t.scaler));t.scalerLabel=s,this.settings.addTransformation(t),e.push(`feature: ${t["name"]} ,scaler: ${t["scalerLabel"]} `)}));let s={message:"scaled fetures: <br> "+e.join("-"),type:"info"};this.$buefy.toast.open("scaled fetures: "+e),this.settings.addMessage(s)}else this.settings.resetTransformations();this.$emit("coordinate-plot",!0)},async initSPLOM(){this.df=new g.DataFrame(this.settings.rawData),this.df=await this.df.sample(this.df.$data.length,{seed:this.settings.getSeed}),this.df.dropNa({axis:1,inplace:!0});let e=this.settings.items.filter((e=>e.selected&&1===e.type)).map((function(e){return{name:e.name,type:e.type}})),t=this.settings.items.filter((e=>e.selected&&1!==e.type)).map((function(e){return{name:e.name,type:e.type}})),s=e.concat(t);this.features=s.map(((e,t)=>({id:t,name:e.name,type:e.type,scaler:0}))),this.dispalySPLOM(this.df)}},created:async function(){await this.initSPLOM()},computed:{column_width:{get(){return 0===this.features.length?0:100/this.features.length}}}},mt=dt,pt=(0,C.A)(mt,et,tt,!1,null,"4deee124",null),ut=pt.exports,ht=function(){var e=this,t=e._self._c;return t("section",{staticClass:"has-text-left content"},[t("h4",{staticClass:"title is-medium is-5",attrs:{id:"help"}},[e._v("Classification metrics ")]),t("p",[e._v(" In a context of a binary classification, here are the main metrics that are important to track in order to assess the performance of the model. ")]),e._m(0),t("h4",{staticClass:"title is-medium is-5"},[e._v("Regression metrics ")]),t("ul",[t("li",[e._v(" Basic metricsGiven a regression model "),t("i",[e._v("f")]),e._v(", the following metrics are commonly used to assess the performance of the model: "),t("table",{staticClass:"table is-bordered"},[e._m(1),t("tbody",[t("tr",[t("td",[t("vue-mathjax",{attrs:{formula:"$$ SS_{tot}= \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2$$"}})],1),t("td",[t("vue-mathjax",{attrs:{formula:"$$ SS_{reg}= \\sum_{i=1}^{m} (f (x_i) - \\hat{y}_i)^2$$"}})],1),t("td",[t("vue-mathjax",{attrs:{formula:"$$ SS_{res}= \\sum_{i=1}^{m} (y_i - f (x_i))^2$$"}})],1)])])])]),t("li",[e._v(" Coefficient of determination: The coefficient of determination, often noted "),t("i",[e._v("R")]),t("sup",[e._v("2")]),e._v(" , provides a measure of how well the observed outcomes are replicated by the model and is defined as follows: "),t("vue-mathjax",{attrs:{formula:"$$ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$$"}})],1),t("li",[e._v(" Main metrics: The following metrics are commonly used to assess the performance of regression models, by taking into account the number of variables n that they take into consideration: "),t("table",{staticClass:"table is-bordered"},[e._m(2),t("tbody",[t("tr",[t("td",[t("vue-mathjax",{attrs:{formula:"$$ 2[n + 2 - \\log (L)]$$"}})],1),t("td",[t("vue-mathjax",{attrs:{formula:"$$ \\log (m)(n + 2) - 2 \\log (L)$$"}})],1),t("td",[t("vue-mathjax",{attrs:{formula:"$$ 1 - \\frac{(1-R^2)(m-1)}{m-n-1}$$"}})],1)])])])])]),t("h4",{staticClass:"title is-medium is-5",attrs:{id:"1_help"}},[e._v("Model Selection ")]),t("h5",[e._v(" When selecting a model, we distinguish 3 different parts of the data that we have as follows: ")]),e._m(3),t("p",[e._v(" Once the model has been chosen, it is trained on the entire dataset and tested on the unseen test set. These are represented in the figure below:")]),t("p",[e._v(" Cross-validation, also noted CV, is a method that is used to select a model that does not rely too much on the initial training set. The different types are summed up in the table below: ")]),e._m(4),e._m(5),t("p",[e._v(" regularization: The regularization procedure aims at avoiding the model to overfit the data and thus deals with high variance issues. The following table sums up the different types of commonly used regularization techniques: ")]),t("h4",{staticClass:"title is-medium is-5"},[e._v("Supervised Learning ")]),e._m(6),t("h4",{staticClass:"title is-medium is-5",attrs:{id:"svm_help"}},[e._v("Support Vector Machine")]),t("p",[e._v(" The goal of support vector machines is to find the line that maximizes the minimum distance to the line. ")]),e._v(" Optimal margin classifier: The optimal margin classifier (h) is such that: "),t("vue-mathjax",{attrs:{formula:"$$ h(x) = sign(w^T x - b) $$"}}),e._v(" where (w,b \\in R^2) is the solution of the following optimization problem: "),t("img",{attrs:{src:"/svm-en.png",height:"150px",width:"70%"}}),t("h4",{staticClass:"title is-medium is-5",attrs:{id:"naive_bayes_help"}},[e._v("Naive Bayes")]),t("ul",[t("li",[e._v(" Assumption: The Naive Bayes model supposes that the features of each data point are all independent: "),t("vue-mathjax",{attrs:{formula:"$$ P(x | y) = P(x_1,x_2,...|y) = P(x_1 |y )  P(x_2 |y ) $$"}})],1)]),t("h4",{staticClass:"title is-medium is-5",attrs:{id:"cart_help"}},[e._v("Tree-based and ensemble methods")]),t("p",[e._v(" These methods can be used for both regression and classification problems. ")]),e._m(7),t("h4",{staticClass:"title is-medium",attrs:{id:"knn_help"}},[e._v("(k)-nearest neighbors")]),t("p",[e._v(" (k)-nearest neighbors: The (k)-nearest neighbors algorithm, commonly known as (k)-NN, is a non-parametric approach where the response of a data point is determined by the nature of its (k) neighbors from the training set. It can be used in both classification and regression settings. ")]),t("img",{staticClass:"image",attrs:{src:"/knn.png"}}),t("h4",{staticClass:"title is-medium",attrs:{id:"discriminant_analysis_help"}},[e._v(" Gaussian Discriminant Anallysis ")]),t("p",[e._v(" Gaussian Discriminant Analysis SettingThe Gaussian Discriminant Analysis assumes that (y) and (x ∣ y = 0) and (x|y = 1) are such that: "),t("vue-mathjax",{attrs:{formula:"$$ y \\sim Bernoulli(\\phi)   ,   x|y = 0 \\sim \\mathcal{N(\\mu_0,\\Sigma)}$$"}})],1),t("h4",[e._v("Partial Dependence Plot")]),t("p",[e._v(" The partial dependence plot (short PDP or PD plot) shows the marginal effect one or two features have on the predicted outcome of a machine learning model. A partial dependence plot can show whether the relationship between the target and a feature is linear, monotonic or more complex. For example, when applied to a linear regression model, partial dependence plots always show a linear relationship. The partial dependence function for regression is defined as: "),t("vue-mathjax",{attrs:{formula:"$$ f_s(x_s) = \\int{f(x_s,x_c)dP(x_c)}$$"}}),e._v(" The x"),t("sub",[e._v("s")]),e._v(" are the features for which the partial dependence function should be plotted and X"),t("sub",[e._v("c")]),e._v(" are the other features used in the machine learning model ^ f , which are here treated as random variables. Usually, there are only one or two features in the set S. The feature(s) in S are those for which we want to know the effect on the prediction. The feature vectors X"),t("sub",[e._v("s")]),e._v(" and X"),t("sub",[e._v("c")]),e._v(" combined make up the total feature space x. Partial dependence works by marginalizing the machine learning model output over the distribution of the features in set C, so that the function shows the relationship between the features in set S we are interested in and the predicted outcome. By marginalizing over the other features, we get a function that depends only on features in S, interactions with other features included. The partial function ^ f S is estimated by calculating averages in the training data, also known as Monte Carlo method: "),t("vue-mathjax",{attrs:{formula:"$$ f_s(x_s) = \\frac{1}{n} \\sum_{n = 1}^{n} f(x_s,x_c)$$"}}),e._v(" The partial function tells us for given value(s) of features S what the average marginal effect on the prediction is. In this formula, x ( i ) C are actual feature values from the dataset for the features in which we are not interested, and n is the number of instances in the dataset. An assumption of the PDP is that the features in C are not correlated with the features in S. If this assumption is violated, the averages calculated for the partial dependence plot will include data points that are very unlikely or even impossible (see disadvantages). For classification where the machine learning model outputs probabilities, the partial dependence plot displays the probability for a certain class given different values for feature(s) in S. An easy way to deal with multiple classes is to draw one line or plot per class. The partial dependence plot is a global method: The method considers all instances and gives a statement about the global relationship of a feature with the predicted outcome. ")],1),t("h4",[e._v("Categorical features")]),t("p",[e._v(" So far, we have only considered numerical features. For categorical features, the partial dependence is very easy to calculate. For each of the categories, we get a PDP estimate by forcing all data instances to have the same category. For example, if we look at the bike rental dataset and are interested in the partial dependence plot for the season, we get four numbers, one for each season. To compute the value for “summer”, we replace the season of all data instances with “summer” and average the predictions. ")])],1)},_t=[function(){var e=this,t=e._self._c;return t("ul",[t("li",[e._v(" Confusion matrix: The confusion matrix is used to have a more complete picture when assessing the performance of a model. It is defined as follows: ")]),t("li",[e._v(" Main metrics: The following metrics are commonly used to assess the performance of classification models: ")]),t("li",[e._v(" The receiver operating curve, also noted ROC, is the plot of TPR versus FPR by varying the threshold. These metrics are are summed up in the table below: ")]),t("li",[e._v(" The area under the receiving operating curve, also noted AUC or AUROC, is the area below the ROC as shown in the following figure: ")])])},function(){var e=this,t=e._self._c;return t("thead",[t("tr",[t("th",{staticClass:"is-success"},[e._v("Total sum of squares")]),t("th",{staticClass:"is-success"},[e._v("Explained sum of squares ")]),t("th",{staticClass:"is-success"},[e._v("Residual sum of squares ")])])])},function(){var e=this,t=e._self._c;return t("thead",[t("tr",[t("th",{staticClass:"is-success"},[e._v("AIC")]),t("th",{staticClass:"is-success"},[e._v("BIC")]),t("th",{staticClass:"is-success"},[e._v("Adjusted R2 ")])])])},function(){var e=this,t=e._self._c;return t("table",{staticClass:"table is-bordered"},[t("thead",[t("tr",[t("th",{staticClass:"is-success"},[e._v("Training set")]),t("th",{staticClass:"is-success"},[e._v("Validation set ")]),t("th",{staticClass:"is-success"},[e._v("Testing set ")])])]),t("tbody",[t("tr",[t("td",[t("ul",[t("li",[e._v(" Model is trained")]),t("li",[e._v(" Usually 80% of the dataset")])])]),t("td",[t("ul",[t("li",[e._v("Model is assessed")]),t("li",[e._v("Usually 20% of the dataset")]),t("li",[e._v("Also called hold-out or development set")])])]),t("td",[t("ul",[t("li",[e._v(" Model gives predictions")]),t("li",[e._v("Unseen data")])])])])])])},function(){var e=this,t=e._self._c;return t("table",{staticClass:"table is-bordered"},[t("thead",[t("tr",[t("th",{staticClass:"is-success"},[e._v("k-fold")]),t("th",{staticClass:"is-success"},[e._v("Leave-p-out")])])]),t("tbody",[t("tr",[t("td",[t("ul",[t("li",[e._v(" Model is trained")]),t("li",[e._v(" Usually 80% of the dataset")])])]),t("td",[t("ul",[t("li",[e._v("Model is assessed")]),t("li",[e._v("Usually 20% of the dataset")]),t("li",[e._v("Also called hold-out or development set")])])])])])])},function(){var e=this,t=e._self._c;return t("p",[e._v(" The most commonly used method is called k-fold cross-validation and splits the training data into k folds to validate the model on one fold while training the model on the k−1 other folds, all of this k times. The error is then averaged over the k folds and is named cross-validation error. "),t("img",{staticClass:"image",attrs:{src:"/cross-validation-en.png",alt:""}})])},function(){var e=this,t=e._self._c;return t("ul",[t("li",[e._v("Type of prediction: The different types of predictive models are summed up in the table below: "),t("table",{staticClass:"table is-bordered"},[t("thead",[t("tr",[t("th",{staticClass:"is-success"}),t("th",{staticClass:"is-success"},[e._v("Regression")]),t("th",{staticClass:"is-success"},[e._v("Classification")])])]),t("tbody",[t("tr",[t("td",[e._v("Outcome")]),t("td",[e._v("Continuous")]),t("td",[e._v("Class")])]),t("tr",[t("td",[e._v("Examples")]),t("td",[e._v("Linear regression ")]),t("td",[e._v("Logistic regression, SVM, Naive Bayes ")])])])])])])},function(){var e=this,t=e._self._c;return t("ul",[t("li",[e._v(" Classification and Regression Trees (CART), commonly known as decision trees, can be represented as binary trees. They have the advantage to be very interpretable. ")]),t("li",[e._v(" Random forestIt is a tree-based technique that uses a high number of decision trees built out of randomly selected sets of features. Contrary to the simple decision tree, it is highly uninterpretable but its generally good performance makes it a popular algorithm. ")]),t("li",[e._v(" BoostingThe idea of boosting methods is to combine several weak learners to form a stronger one. The main ones are summed up in the table below: ")]),t("li",[e._v(" Adaptive boosting Gradient boosting • High weights are put on errors to improve at the next boosting step • Known as Adaboost • Weak learners are trained on residuals • Examples include XGBoost ")])])}],ft={name:"MethodsTabComponent",data(){return{formula:"$$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$",sserror:"$$ SS_{tot}= \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2$$"}}},gt=ft,yt=(0,C.A)(gt,ht,_t,!1,null,null,null),bt=yt.exports,vt=s(42004);const xt=new Worker(new URL(s.p+s.u(167),s.b)),wt={};xt.onmessage=e=>{const{id:t,...s}=e.data,a=wt[t];delete wt[t],a(s)};const Ct=(()=>{let e=0;return(t,s)=>(e=(e+1)%Number.MAX_SAFE_INTEGER,new Promise((a=>{wt[e]=a,xt.postMessage({...s,python:t,id:e})})))})();class kt{constructor(){this.model=null}async train(e,t,s,a){this.context={X_train:e,columns:t,metric:s,method:a};const i='\n        import matplotlib\n        matplotlib.use("AGG")\n        import matplotlib.pyplot as plt\n        from js import X_train,columns,method,metric\n        import seaborn as sns\n        import pandas as pd\n\n        sns.set(font_scale=1.5)\n        df = pd.DataFrame(X_train,columns = columns)\n        plt.figure(figsize=(12, 8))\n        plot = sns.clustermap(df.corr(),cmap="YlGnBu_r",annot = True, fmt=".2f",method=method,metric=metric)\n        reordered_index = plot.dendrogram_row.reordered_ind\n        reordered_columns = plot.dendrogram_col.reordered_ind\n        clustered_corr = df.corr().iloc[reordered_index, :].iloc[:, reordered_columns]\n\n        Z = plot.dendrogram_col.linkage  \n        Z,clustered_corr.values,clustered_corr.columns.tolist()\n        ';try{const{results:e,error:t}=await Ct(i,this.context);if(e)return e;t&&console.log("pyodideWorker error: ",t)}catch(n){throw Error(`Error in pyodideWorker at ${n.filename}, Line: ${n.lineno}, ${n.message}`)}}}let St=new te(null,null),zt=new ee(null,null);var At={name:"MainComponent",components:{"dmensionality-reduction-component":qe,"results-component":Ze,"scatterplot-matrix-component":ut,"methods-tab-component":bt},setup(){const e=b();return{settings:e}},props:{msg:String,selectedFeatures:[]},errorCaptured(e,t,s){console.log(`cat EC: ${e.toString()}\ninfo: ${s}`);let a={message:"Encountered unexpected error",type:"warning"};return this.$buefy.toast.open({message:"Encountered unexpected error",type:"is-warning"}),this.settings.addMessage(a),!1},data(){return{featureTypeOptions:z,checkedRows:[],metric:"euclidean",method:"ward",img:null,continuousFeaturesStats:[],continuousFeaturesColumns:[],categoricalFeaturesStats:[],categoricalFeaturesColumns:[],sampleData:[],datasetColumns:[],isActive:!0,hasCorrelationMatrix:!1,loading:!1}},methods:{resize(){window.dispatchEvent(new Event("resize"))},async correlationMatrix(){this.loading=!0;try{let e=this.settings.items.filter((e=>e.selected&&e.type===z.Numerical.id)).map((e=>e.name)),t=this.settings.df.loc({columns:e});t=t.dropNa({axis:1}).values;let s=new vt.uq(t),a=(0,vt.BR)(s);this.hasCorrelationMatrix=!0,await zt.correlationHeatmap("correlation_matrix",a.data,e);let i=new kt,[n,r,o]=await i.train(t,e,this.metric,this.method);await zt.dendogramPlot("correlation_matrix_ordered",r,n,o,e),this.loading=!1,setTimeout((()=>{window.dispatchEvent(new Event("resize"))}),500)}catch(e){throw this.loading=!1,e}},applyChanges(){this.renderStats(!0)},renderStats(e=!1){if(this.settings.df?.columns?.length>0){let t,s;if(e){console.log(this.continuousFeaturesStats);let e=this.continuousFeaturesStats.concat(this.categoricalFeaturesStats);t=e.filter((e=>e.type===z.Numerical.id)).map((function(e){return{name:e.name,selected:e.selected,scaler:e.sclaer??0}})),s=e.filter((e=>e.type===z.Nominal.id||e.type===z.Ordinal.id)).map((function(e){return{name:e.name,selected:e.selected}}));let a=e;for(let t=0;t<a.length;t++)this.settings.addFeature(a[t]);this.$emit("check-target")}else t=this.settings.items.filter((e=>e.type===z.Numerical.id)).map((function(e){return{name:e.name,selected:!0}})),s=this.settings.items.filter((e=>e.type!==z.Numerical.id)).map((function(e){return{name:e.name,selected:!0}}));let a=new g.DataFrame(this.settings.rawData),i=St.renderDatasetStats(a,t,s);this.continuousFeaturesColumns=i[0],this.continuousFeaturesStats=i[1],this.categoricalFeaturesColumns=i[2],this.categoricalFeaturesStats=i[3],this.datasetColumns=this.settings.df.columns.map((e=>({field:e,label:e}))),this.sampleData=(0,ve.toJSON)(this.settings.df.head(5)),this.$refs.splom?.initSPLOM(),setTimeout((()=>{this.correlationMatrix()}),500)}}}},Pt=At,Et=(0,C.A)(Pt,ze,Ae,!1,null,null,null),Ft=Et.exports,Tt={name:"App",components:{SidebarComponent:Se,MainComponent:Ft},setup(){const e=b();return{settings:e}},errorCaptured(e,t,s){return console.log(`cat EC: ${e.toString()}\ninfo: ${s}`),this.$buefy.toast.open({duration:3e3,message:"Something went wrong",type:"is-danger"}),this.settings.addMessage({message:e.toString(),type:"danger"}),!1},data(){return{dataframe:null,selectedFeatures:[]}},methods:{checkTarget(){this.$refs.sidebar.checkmodelTask()},reset(){this.settings.resetDF()},updateFeatureStats(){this.$refs.main.renderStats()},setSelectedFeatures(e){this.selectedFeatures=e}}},$t=Tt,Nt=(0,C.A)($t,i,n,!1,null,null,null),qt=Nt.exports,Dt=s(60523),Mt=(s(91457),s(14862)),Ot=s(2232),It=s.n(Ot);M().setPlotConfig({autosize:!0,displaylogo:!1,modeBarButtonsToRemove:["resetScale2d","zoom2d","pan","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]}),Mt.setBackend(g.tensorflow),a.Ay.config.productionTip=!1,a.Ay.prototype.window=window,a.Ay.use(It()),a.Ay.use(Dt.Ay),a.Ay.use(y.R2);const Rt=(0,y.Ey)();new a.Ay({render:e=>e(qt),pinia:Rt}).$mount("#app")},85817:function(){},18590:function(){},70324:function(){},9807:function(){},5863:function(){},86997:function(){},50716:function(){},41234:function(){},16251:function(){},67233:function(){},29800:function(){}},t={};function s(a){var i=t[a];if(void 0!==i)return i.exports;var n=t[a]={id:a,loaded:!1,exports:{}};return e[a].call(n.exports,n,n.exports,s),n.loaded=!0,n.exports}s.m=e,function(){s.amdD=function(){throw new Error("define cannot be used indirect")}}(),function(){s.amdO={}}(),function(){var e=[];s.O=function(t,a,i,n){if(!a){var r=1/0;for(d=0;d<e.length;d++){a=e[d][0],i=e[d][1],n=e[d][2];for(var o=!0,l=0;l<a.length;l++)(!1&n||r>=n)&&Object.keys(s.O).every((function(e){return s.O[e](a[l])}))?a.splice(l--,1):(o=!1,n<r&&(r=n));if(o){e.splice(d--,1);var c=i();void 0!==c&&(t=c)}}return t}n=n||0;for(var d=e.length;d>0&&e[d-1][2]>n;d--)e[d]=e[d-1];e[d]=[a,i,n]}}(),function(){s.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return s.d(t,{a:t}),t}}(),function(){s.d=function(e,t){for(var a in t)s.o(t,a)&&!s.o(e,a)&&Object.defineProperty(e,a,{enumerable:!0,get:t[a]})}}(),function(){s.u=function(e){return"js/"+e+"."+{167:"dfe48028",221:"a23df7f3"}[e]+".js"}}(),function(){s.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"===typeof window)return window}}()}(),function(){s.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)}}(),function(){s.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})}}(),function(){s.nmd=function(e){return e.paths=[],e.children||(e.children=[]),e}}(),function(){s.p="/"}(),function(){s.b=document.baseURI||self.location.href;var e={524:0};s.O.j=function(t){return 0===e[t]};var t=function(t,a){var i,n,r=a[0],o=a[1],l=a[2],c=0;if(r.some((function(t){return 0!==e[t]}))){for(i in o)s.o(o,i)&&(s.m[i]=o[i]);if(l)var d=l(s)}for(t&&t(a);c<r.length;c++)n=r[c],s.o(e,n)&&e[n]&&e[n][0](),e[n]=0;return s.O(d)},a=self["webpackChunkmlfit"]=self["webpackChunkmlfit"]||[];a.forEach(t.bind(null,0)),a.push=t.bind(null,a.push.bind(a))}();var a=s.O(void 0,[504],(function(){return s(51300)}));a=s.O(a)})();
//# sourceMappingURL=app.29552781.js.map